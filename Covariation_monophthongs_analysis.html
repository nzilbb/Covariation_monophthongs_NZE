<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="James Brand1, Jen Hay1,2, Lynn Clark2, Kevin Watson2 &amp; Márton Sóskuthy3   1New Zealand Institute for Language, Brain and Behaviour, Univeristy of Canterbury, NZ  2Department of Linguistics, Univeristy of Canterbury, NZ 3Department of Linguistics, The University of British Columbia, CA  Corresponding author: James Brand Email: james.brand@canterbury.ac.nz Website: https://jamesbrandscience.github.io" />


<title>Systematic co-variation of monophthongs across speakers of New Zealand English</title>

<script src="libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/navigation-1.1/codefolding.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.13/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Systematic co-variation of monophthongs across speakers of New Zealand English</h1>
<h3 class="subtitle">Supplementary materials: <em>Analysis script</em></h3>
<h4 class="author">James Brand<sup>1</sup>, Jen Hay<sup>1,2</sup>, Lynn Clark<sup>2</sup>, Kevin Watson<sup>2</sup> &amp; Márton Sóskuthy<sup>3</sup><br><br/> <sup>1</sup>New Zealand Institute for Language, Brain and Behaviour, Univeristy of Canterbury, NZ<br> <sup>2</sup>Department of Linguistics, Univeristy of Canterbury, NZ<br><sup>3</sup>Department of Linguistics, The University of British Columbia, CA<br/><br/>Corresponding author: James Brand<br/>Email: <a href="mailto:james.brand@canterbury.ac.nz">james.brand@canterbury.ac.nz</a><br/>Website: <a href="https://jamesbrandscience.github.io" class="uri">https://jamesbrandscience.github.io</a></h4>
<h4 class="date">28 August, 2020</h4>

</div>


<!-- set the colour scheme of the html file -->
<style>
.list-group-item.active, .list-group-item.active:focus, .list-group-item.active:hover {
    background-color: #95A044;
}
</style>
<div id="document-outline" class="section level1">
<h1>Document outline</h1>
<p>This document provides the code used in the analyses of the Brand, Hay, Clark, Watson and Sóskuthy (2020) manuscript, submitted to the Journal of Phonetics. It contains the various analysis steps reported in the paper, as well as additional analyses that the authors completed but were not considered central to the manuscript’s core research questions, they are included here in case readers are interested.</p>
<p>Whilst every attempt has been made to make the code transparent, clear and comprehensible to all readers, regardless of your proficiency with using R or the statistical procedures applied in the analyses, if there are questions/queries/issues that do arise, please do contact the corresponding author (contact details at the top of the document).</p>
<p>Note that in the project repository, large and computationally expensive processes, such as the GAMM modelling, have been pre-run and important data stored in the <code>Data</code> folder. This has been done to ensure the compilation of this file is achieved relatively quickly and can be hosted online (i.e. via GitHub and OSF), in addition to allowing others to have quick access to all the required data. These steps are included in this file and can be run on your own computer to reproduce all the original files. When pre-run steps have been carried out, they are identifiable in the <code>.Rmd</code> file by the chunks having an <code>eval=FALSE</code> argument. If you are running these chunks, please ensure you have sufficient memory avialable (I require 13.18GB to store the <code>Analysis</code> folder, when all models are saved).</p>
<pre class="r"><code>cat(paste0(&quot;Start time:\n&quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;)))</code></pre>
<pre><code>## Start time:
## 28 August 2020, 06:57:03 pm</code></pre>
<pre class="r"><code>start_time &lt;- Sys.time()</code></pre>
</div>
<div id="analysis-steps" class="section level1">
<h1>Analysis steps</h1>
<p>The document covers a number of steps that we completed, all of which can be reproduced by using the code and data in the project repository (<strong>LINK</strong>). In order to orientate the reader, we provide a brief written outline of what the steps are.</p>
<ol style="list-style-type: decimal">
<li><p>Load in the data and provide summaries of the how it is structured.</p></li>
<li><p>Apply a new normalisation procedure (Lobanov 2.0) to the formant measurements.</p></li>
<li><p>Run a series of GAMMs that model the normalised values (per formant and per vowel), with fixed effects of speaker year of birth, gender and speech rate. These models will then be used to extract the by-speaker random intercepts, which we use as estimates of how innovative a speaker’s realisations of each vowel are in terms of F1/F2, whilst keeping the fixed effects constant.</p></li>
<li><p>Run a principal components analysis (PCA) on the speaker intercepts data. Then inspect the eigen values of each of the principal components (PCs), this will allow us to determine which PCs account for sufficient variance to be meaningfully interpreted.</p></li>
<li><p>Extract the PCA scores from the PCs, which give each individual speaker a value for each PC, the more extreme (i.e. high or low) this value, the more the speaker contributes to the PC’s formation. This will allow us to identify which speakers are representative of the PCs.</p></li>
<li><p>Assess if any of the PCs can be explained by the fixed-effects from the GAMM fitting procedure, i.e. is there a relationship between the PCA scores and factors such as year of birth or gender. We will provide examples of speaker vowel spaces to assist in the interpreation of the PCs in terms of F1/F2 space (the Shiny app allows for exploration of all speakers, so we recommend that as the optimal tool for understanding speaker variation <strong>LINK</strong>).</p></li>
<li><p>Following on from the previous inspection of the variables, our interpretation for how they co-vary together within a more theoretical framework (as explained in the paper), was driven by our understanding of the directions of change in F1/F2. To demonstrate this we will run additional GAMMs predicting F1/F2 by the PCA scores. Then visualise how these changes map onto change in New Zealand English.</p></li>
</ol>
</div>
<div id="pre-requisites" class="section level1">
<h1>Pre-requisites</h1>
<p><strong>Purpose: Install libraries and load data</strong></p>
<p>In order for the code in this document to work, the following packages are required to be installed and loaded into your R session. If you do not have any of the packages installed, you can run <code>install.packages(&quot;PACKAGE NAME&quot;)</code> which should resolve any warning messages you might get (change “PACKAGE NAME” to the required package name, e.g. <code>install.packages(&quot;tidyverse&quot;)</code>).</p>
<p>A large portion of the code in this document is written in a <em>tidy</em> way, this means that it (tries to) always use the <code>tidyverse</code> functions when possible, if you are new to using R or are more familiar with R’s <code>base</code> packages, see <a href="http://tidyverse.tidyverse.org/" class="uri">http://tidyverse.tidyverse.org/</a> for a full reference guide.</p>
<p>Similarly, if there are any functions that you are not familiar with/would like more information on (or the arguments to those functions), simply press <code>F1</code> whilst your cursor is clicked anywhere on the name of the function, this will bring up the help page in RStudio (note this will only work if you are using the <code>.rmd</code> version of this file and not the <code>.html</code>).</p>
<p>For more general information on R Markdown documents and how they work see <a href="https://rmarkdown.rstudio.com/index.html" class="uri">https://rmarkdown.rstudio.com/index.html</a></p>
<div id="libraries" class="section level2">
<h2>Libraries</h2>
<p>The following libraries are required for the document to be run.</p>
<pre class="r"><code>library(lme4) #mixed-effects models
library(rms) #fitting restricted cubic splines
library(cowplot) #plotting functions
library(tidyverse) #lots of things
library(kableExtra) #outputting nice tables
library(factoextra) #pca related things
library(ggrepel) #more plotting things
library(gganimate) #animation plotting
library(lmerTest) #p values from lmer models
library(DT) #interactive data tables
library(mgcv) #gamms
library(itsadug) #additional gamm things
library(scales) #rescale functions
library(gifski) #needed to generate gif
library(circlize) #chord diagram
library(PerformanceAnalytics) #correlation figure

#this is important for reproduction of any stochastic computations
set.seed(123)

#check information about R session, this will give details of the R setup on the authors computer at the time of running. If any of the outputs are not reproduced as in the html file produced from this markdown document (see repository), there may be differences in the package versions or setup on your computer. You can update packages by running utils::update.packages()
sessionInfo()</code></pre>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] PerformanceAnalytics_2.0.4 xts_0.12-0                
##  [3] zoo_1.8-7                  circlize_0.4.8            
##  [5] gifski_0.8.6               scales_1.1.0              
##  [7] itsadug_2.3                plotfunctions_1.3         
##  [9] mgcv_1.8-31                nlme_3.1-147              
## [11] DT_0.13                    lmerTest_3.1-2            
## [13] gganimate_1.0.5            ggrepel_0.8.2             
## [15] factoextra_1.0.7           kableExtra_1.1.0          
## [17] forcats_0.5.0              stringr_1.4.0             
## [19] dplyr_0.8.5                purrr_0.3.4               
## [21] readr_1.3.1                tidyr_1.0.2               
## [23] tibble_3.0.1               tidyverse_1.3.0           
## [25] cowplot_1.0.0              rms_5.1-4                 
## [27] SparseM_1.78               Hmisc_4.4-0               
## [29] ggplot2_3.3.0              Formula_1.2-3             
## [31] survival_3.1-12            lattice_0.20-41           
## [33] lme4_1.1-23                Matrix_1.2-18             
## 
## loaded via a namespace (and not attached):
##  [1] TH.data_1.0-10      minqa_1.2.4         colorspace_1.4-1   
##  [4] ellipsis_0.3.0      htmlTable_1.13.3    GlobalOptions_0.1.1
##  [7] base64enc_0.1-3     fs_1.4.1            rstudioapi_0.11    
## [10] farver_2.0.3        MatrixModels_0.4-1  fansi_0.4.1        
## [13] mvtnorm_1.1-0       lubridate_1.7.8     xml2_1.3.2         
## [16] codetools_0.2-16    splines_3.6.3       knitr_1.28         
## [19] jsonlite_1.6.1      nloptr_1.2.2.1      broom_0.5.6        
## [22] cluster_2.1.0       dbplyr_1.4.3        png_0.1-7          
## [25] compiler_3.6.3      httr_1.4.1          backports_1.1.6    
## [28] assertthat_0.2.1    cli_2.0.2           tweenr_1.0.1       
## [31] acepack_1.4.1       htmltools_0.4.0     quantreg_5.55      
## [34] prettyunits_1.1.1   tools_3.6.3         gtable_0.3.0       
## [37] glue_1.4.0          Rcpp_1.0.4          cellranger_1.1.0   
## [40] vctrs_0.2.4         xfun_0.13           rvest_0.3.5        
## [43] lifecycle_0.2.0     statmod_1.4.34      polspline_1.1.17   
## [46] MASS_7.3-51.6       hms_0.5.3           sandwich_2.5-1     
## [49] RColorBrewer_1.1-2  yaml_2.2.1          gridExtra_2.3      
## [52] rpart_4.1-15        latticeExtra_0.6-29 stringi_1.4.6      
## [55] checkmate_2.0.0     boot_1.3-25         shape_1.4.4        
## [58] rlang_0.4.5         pkgconfig_2.0.3     evaluate_0.14      
## [61] htmlwidgets_1.5.1   tidyselect_1.0.0    magrittr_1.5       
## [64] R6_2.4.1            generics_0.0.2      multcomp_1.4-13    
## [67] DBI_1.1.0           pillar_1.4.3        haven_2.2.0        
## [70] foreign_0.8-75      withr_2.2.0         nnet_7.3-14        
## [73] modelr_0.1.6        crayon_1.3.4        rmarkdown_2.1      
## [76] jpeg_0.1-8.1        progress_1.2.2      grid_3.6.3         
## [79] readxl_1.3.1        data.table_1.12.8   reprex_0.3.0       
## [82] digest_0.6.25       webshot_0.5.2       numDeriv_2016.8-1.1
## [85] munsell_0.5.0       viridisLite_0.3.0   quadprog_1.5-8</code></pre>
</div>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<p><strong>Purpose: Understand the structure of the dataset</strong></p>
<p>All data has been made available to reproduce the results, the data file should be located in a folder called <code>data</code> within the folder/directory this file is saved in. We will store the data as an R data frame called <code>vowels_all</code>. Note the data is saved as a <code>.rds</code> file, this is essentially the same as a normal <code>.csv</code> file, but is more efficient when working in R. If you wish to reuse the data in a different format, it is recommended that you load in the data and then export it to your preferred format, e.g. using the <code>write.csv()</code> function for <code>.csv</code> files.</p>
<pre class="r"><code>#load in the data
vowels_all &lt;- readRDS(&quot;Data/ONZE_vowels_filtered_anon.rds&quot;)</code></pre>
<p>We can inspect the data in different ways, to ensure that the correct file has been loaded and for general understanding of how the data is structured.</p>
<div id="variables" class="section level2">
<h2>Variables</h2>
<p>Let’s inspect the variables…</p>
<p>We should have <strong>10</strong> variables.</p>
<p>Definitions of each variable are given below (factors are represented as <em>fct</em> with the number of unique levels also provided e.g. <em>fct, 2</em> represents a factor with 2 unique values, numeric variables are represented as <em>num</em>, with the smallest and largest values provided, e.g. <em>num, (1857-1988)</em>):</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
Description
</th>
<th style="text-align:left;">
Class
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Speaker</span>
</td>
<td style="text-align:left;width: 30em; ">
The speaker ID (format: corpus_gender_distinctnumber, e.g. IA_f_001
</td>
<td style="text-align:left;font-style: italic;">
fct (481)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Transcript</span>
</td>
<td style="text-align:left;width: 30em; ">
The transcript number of the speaker, e.g. IA_f_001-01.trs
</td>
<td style="text-align:left;font-style: italic;">
fct (2523)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Corpus</span>
</td>
<td style="text-align:left;width: 30em; ">
The sub-corpus the data comes from, i.e. either MU, IA, Darfield or CC
</td>
<td style="text-align:left;font-style: italic;">
fct (4)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Gender</span>
</td>
<td style="text-align:left;width: 30em; ">
The gender of the speaker, i.e. either F for female or M for male
</td>
<td style="text-align:left;font-style: italic;">
fct (2)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">participant_year_of_birth</span>
</td>
<td style="text-align:left;width: 30em; ">
The year the participant was born in e.g. 1864
</td>
<td style="text-align:left;font-style: italic;">
num (1864-1982)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Word</span>
</td>
<td style="text-align:left;width: 30em; ">
The word form of the token, this is anonymised (format: word_distinctnumber, e.g. word_00002
</td>
<td style="text-align:left;font-style: italic;">
fct (14632)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Vowel</span>
</td>
<td style="text-align:left;width: 30em; ">
The vowel of the token, using Well’s notation, e.g. FLEECE
</td>
<td style="text-align:left;font-style: italic;">
fct (10)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">F1_50</span>
</td>
<td style="text-align:left;width: 30em; ">
The raw F1 of the vowel in Hz, taken at the mid-point, e.g. 500
</td>
<td style="text-align:left;font-style: italic;">
num (58-999)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">F2_50</span>
</td>
<td style="text-align:left;width: 30em; ">
The raw F2 of the vowel in Hz, taken at the mid-point, e.g. 1500
</td>
<td style="text-align:left;font-style: italic;">
num (320-3453)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style="     color: #273746 !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: #F2F3F4 !important;">Speech_rate</span>
</td>
<td style="text-align:left;width: 30em; ">
The speech rate in syllbales per second for the transcript, e.g. 1.7929
</td>
<td style="text-align:left;font-style: italic;">
num (0.1365-15.2451)
</td>
</tr>
</tbody>
</table>
<p>Next, we can generate some summary information about the dataset, the following code will reproduce the information provided in <strong>Tables XX</strong>.</p>
<div id="token-counts" class="section level3">
<h3>Token counts</h3>
<p>There are 10 different vowels in the data, a summary of the number of tokens per vowel is given below.</p>
<p>Originally, we extracted 12 vowels, comprising the 10 summarised below, but also SCHWA and FOOT, these were removed during the data cleaning stage, SCHWA was removed as we are only analysing stressed tokens and the number of speakers with low N tokens for FOOT would have led to large loss in the number of speakers in the data.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Vowel
</th>
<th style="text-align:center;">
N Tokens
</th>
<th style="text-align:center;">
%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
NURSE
</td>
<td style="text-align:center;">
16891
</td>
<td style="text-align:center;">
4.1
</td>
</tr>
<tr>
<td style="text-align:left;">
START
</td>
<td style="text-align:center;">
21217
</td>
<td style="text-align:center;">
5.1
</td>
</tr>
<tr>
<td style="text-align:left;">
GOOSE
</td>
<td style="text-align:center;">
26432
</td>
<td style="text-align:center;">
6.4
</td>
</tr>
<tr>
<td style="text-align:left;">
THOUGHT
</td>
<td style="text-align:center;">
28201
</td>
<td style="text-align:center;">
6.8
</td>
</tr>
<tr>
<td style="text-align:left;">
TRAP
</td>
<td style="text-align:center;">
32284
</td>
<td style="text-align:center;">
7.8
</td>
</tr>
<tr>
<td style="text-align:left;">
LOT
</td>
<td style="text-align:center;">
35228
</td>
<td style="text-align:center;">
8.5
</td>
</tr>
<tr>
<td style="text-align:left;">
FLEECE
</td>
<td style="text-align:center;">
49757
</td>
<td style="text-align:center;">
12.0
</td>
</tr>
<tr>
<td style="text-align:left;">
STRUT
</td>
<td style="text-align:center;">
50907
</td>
<td style="text-align:center;">
12.3
</td>
</tr>
<tr>
<td style="text-align:left;">
DRESS
</td>
<td style="text-align:center;">
69925
</td>
<td style="text-align:center;">
16.9
</td>
</tr>
<tr>
<td style="text-align:left;">
KIT
</td>
<td style="text-align:center;">
83837
</td>
<td style="text-align:center;">
20.2
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;color: black !important;">
Total
</td>
<td style="text-align:center;font-weight: bold;color: black !important;">
414679
</td>
<td style="text-align:center;font-weight: bold;color: black !important;">
100.0
</td>
</tr>
</tbody>
</table>
</div>
<div id="sub-corpora" class="section level3">
<h3>Sub-corpora</h3>
<p>The ONZE dataset comprises four different sub-corpora:</p>
<p>MU - Mobile Unit IA - Intermediate Archive Darfield - Darfield Corpus CC - Canterbury Corpus</p>
<p>Below is a summary of the demographic information for each of the sub-corpora.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Corpus
</th>
<th style="text-align:center;">
N Tokens
</th>
<th style="text-align:center;">
%
</th>
<th style="text-align:center;">
N Speakers
</th>
<th style="text-align:center;">
Female
</th>
<th style="text-align:center;">
Male
</th>
<th style="text-align:center;">
Year of Birth Range
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
MU
</td>
<td style="text-align:center;">
59059
</td>
<td style="text-align:center;">
14.2
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
1864 - 1904
</td>
</tr>
<tr>
<td style="text-align:left;">
IA
</td>
<td style="text-align:center;">
97620
</td>
<td style="text-align:center;">
23.5
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
29
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
1891 - 1963
</td>
</tr>
<tr>
<td style="text-align:left;">
Darfield
</td>
<td style="text-align:center;">
57527
</td>
<td style="text-align:center;">
13.9
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
1918 - 1980
</td>
</tr>
<tr>
<td style="text-align:left;">
CC
</td>
<td style="text-align:center;">
200473
</td>
<td style="text-align:center;">
48.3
</td>
<td style="text-align:center;">
348
</td>
<td style="text-align:center;">
169
</td>
<td style="text-align:center;">
179
</td>
<td style="text-align:center;">
1926 - 1982
</td>
</tr>
</tbody>
</table>
</div>
<div id="speakers" class="section level3">
<h3>Speakers</h3>
<p>The distribution of speakers by gender is given in the histogram below.</p>
<pre class="r"><code>#histogram of the speakers by year of birth and gender
vowels_all %&gt;%
  select(Speaker, Gender, participant_year_of_birth) %&gt;%
  distinct() %&gt;%
  ggplot(aes(x = participant_year_of_birth, fill = Gender, colour = Gender)) +
  geom_histogram(aes(position=&quot;identity&quot;),
                 binwidth=1,
                 alpha = 0.8, colour = NA) +
  geom_rug(alpha = 0.2) +
  scale_x_continuous(breaks = seq(1860, 1990, 15)) +
  scale_fill_manual(values = c(&quot;black&quot;, &quot;#7CAE00&quot;)) +
  scale_color_manual(values = c(&quot;black&quot;, &quot;#7CAE00&quot;)) +
  geom_label(data = vowels_all %&gt;% filter(participant_year_of_birth &gt; 1863 &amp; participant_year_of_birth &lt; 1983) %&gt;% select(Speaker, Gender, participant_year_of_birth) %&gt;% distinct() %&gt;% group_by(Gender) %&gt;% summarise(n = n()), aes(x = 1864, y = 20, label = paste0(&quot;N female = &quot;, n[1], &quot;\nN male = &quot;, n[2], &quot;\nN total = &quot;, sum(n), &quot;\nyob range: &quot;, min(vowels_all$participant_year_of_birth), &quot; - &quot;, max(vowels_all$participant_year_of_birth))), hjust=0, inherit.aes = FALSE) +
  theme_bw() +
  theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-7-1.png" width="2100" /></p>
<p>Below we provide summary information about each of the speakers token counts per vowel. This table comprises all speakers in the dataset and can be ordered and searched like a spreadsheet.</p>
<div id="htmlwidget-9eceb20dc2a931752ae4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-9eceb20dc2a931752ae4">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400","401","402","403","404","405","406","407","408","409","410","411","412","413","414","415","416","417","418","419","420","421","422","423","424","425","426","427","428","429","430","431","432","433","434","435","436","437","438","439","440","441","442","443","444","445","446","447","448","449","450","451","452","453","454","455","456","457","458","459","460","461","462","463","464","465","466","467","468","469","470","471","472","473","474","475","476","477","478","479","480","481"],["CC_f_007","CC_f_010","CC_f_020","CC_f_024","CC_f_025","CC_f_027","CC_f_033","CC_f_040","CC_f_051","CC_f_052","CC_f_054","CC_f_055","CC_f_057","CC_f_064","CC_f_066","CC_f_067","CC_f_074","CC_f_076","CC_f_080","CC_f_083","CC_f_084","CC_f_085","CC_f_093","CC_f_104","CC_f_105","CC_f_107","CC_f_111","CC_f_115","CC_f_117","CC_f_125","CC_f_127","CC_f_129","CC_f_130","CC_f_134","CC_f_136","CC_f_137","CC_f_146","CC_f_148","CC_f_151","CC_f_160","CC_f_161","CC_f_164","CC_f_165","CC_f_170","CC_f_172","CC_f_176","CC_f_177","CC_f_178","CC_f_185","CC_f_186","CC_f_191","CC_f_196","CC_f_198","CC_f_199","CC_f_205","CC_f_210","CC_f_212","CC_f_215","CC_f_218","CC_f_225","CC_f_234","CC_f_235","CC_f_236","CC_f_237","CC_f_238","CC_f_243","CC_f_245","CC_f_250","CC_f_253","CC_f_258","CC_f_265","CC_f_269","CC_f_270","CC_f_279","CC_f_280","CC_f_282","CC_f_285","CC_f_287","CC_f_289","CC_f_292","CC_f_295","CC_f_297","CC_f_302","CC_f_310","CC_f_317","CC_f_323","CC_f_326","CC_f_330","CC_f_339","CC_f_343","CC_f_344","CC_f_346","CC_f_347","CC_f_357","CC_f_362","CC_f_363","CC_f_368","CC_f_369","CC_f_377","CC_f_381","CC_f_386","CC_f_389","CC_f_390","CC_f_391","CC_f_398","CC_f_401","CC_f_407","CC_f_408","CC_f_413","CC_f_420","CC_f_428","CC_f_429","CC_f_440","CC_f_442","CC_f_444","CC_f_449","CC_f_450","CC_f_455","CC_f_457","CC_f_459","CC_f_465","CC_f_466","CC_f_468","CC_f_469","CC_f_477","CC_f_479","CC_f_480","CC_f_483","CC_f_484","CC_f_487","CC_f_488","CC_f_492","CC_f_495","CC_f_501","CC_f_504","CC_f_505","CC_f_509","CC_f_512","CC_f_514","CC_f_522","CC_f_523","CC_f_530","CC_f_534","CC_f_539","CC_f_545","CC_f_546","CC_f_551","CC_f_552","CC_f_554","CC_f_560","CC_f_561","CC_f_564","CC_f_570","CC_f_571","CC_f_572","CC_f_573","CC_f_577","CC_f_585","CC_f_592","CC_f_598","CC_f_599","CC_f_604","CC_f_608","CC_f_615","CC_f_620","CC_f_622","CC_f_630","CC_f_632","CC_f_636","CC_m_006","CC_m_008","CC_m_011","CC_m_012","CC_m_016","CC_m_017","CC_m_019","CC_m_028","CC_m_029","CC_m_030","CC_m_031","CC_m_037","CC_m_038","CC_m_046","CC_m_047","CC_m_050","CC_m_059","CC_m_063","CC_m_070","CC_m_078","CC_m_079","CC_m_086","CC_m_087","CC_m_088","CC_m_094","CC_m_096","CC_m_102","CC_m_103","CC_m_108","CC_m_109","CC_m_112","CC_m_114","CC_m_119","CC_m_120","CC_m_126","CC_m_128","CC_m_131","CC_m_138","CC_m_139","CC_m_149","CC_m_156","CC_m_157","CC_m_162","CC_m_167","CC_m_168","CC_m_173","CC_m_174","CC_m_175","CC_m_180","CC_m_182","CC_m_184","CC_m_190","CC_m_193","CC_m_197","CC_m_201","CC_m_202","CC_m_203","CC_m_204","CC_m_206","CC_m_207","CC_m_208","CC_m_214","CC_m_219","CC_m_227","CC_m_228","CC_m_230","CC_m_232","CC_m_240","CC_m_241","CC_m_247","CC_m_248","CC_m_249","CC_m_251","CC_m_256","CC_m_259","CC_m_261","CC_m_262","CC_m_268","CC_m_272","CC_m_273","CC_m_283","CC_m_293","CC_m_296","CC_m_301","CC_m_303","CC_m_307","CC_m_311","CC_m_315","CC_m_324","CC_m_329","CC_m_338","CC_m_340","CC_m_353","CC_m_359","CC_m_371","CC_m_375","CC_m_378","CC_m_379","CC_m_380","CC_m_385","CC_m_387","CC_m_388","CC_m_393","CC_m_394","CC_m_396","CC_m_399","CC_m_400","CC_m_403","CC_m_404","CC_m_406","CC_m_410","CC_m_411","CC_m_417","CC_m_419","CC_m_423","CC_m_425","CC_m_427","CC_m_432","CC_m_434","CC_m_435","CC_m_438","CC_m_439","CC_m_441","CC_m_443","CC_m_446","CC_m_447","CC_m_453","CC_m_454","CC_m_460","CC_m_461","CC_m_464","CC_m_467","CC_m_470","CC_m_475","CC_m_478","CC_m_481","CC_m_486","CC_m_491","CC_m_493","CC_m_499","CC_m_507","CC_m_508","CC_m_513","CC_m_515","CC_m_529","CC_m_531","CC_m_536","CC_m_538","CC_m_540","CC_m_547","CC_m_548","CC_m_549","CC_m_553","CC_m_557","CC_m_558","CC_m_562","CC_m_563","CC_m_565","CC_m_567","CC_m_576","CC_m_583","CC_m_595","CC_m_596","CC_m_597","CC_m_600","CC_m_601","CC_m_605","CC_m_606","CC_m_607","CC_m_610","CC_m_611","CC_m_613","CC_m_617","CC_m_619","CC_m_621","CC_m_628","CC_m_629","CC_m_631","CC_m_634","Darfield_f_062","Darfield_f_140","Darfield_f_147","Darfield_f_187","Darfield_f_194","Darfield_f_271","Darfield_f_274","Darfield_f_304","Darfield_f_365","Darfield_f_405","Darfield_f_445","Darfield_f_474","Darfield_f_569","Darfield_f_612","Darfield_m_022","Darfield_m_082","Darfield_m_098","Darfield_m_231","Darfield_m_351","Darfield_m_383","Darfield_m_520","Darfield_m_582","Darfield_m_587","Darfield_m_594","Darfield_m_616","IA_f_001","IA_f_003","IA_f_009","IA_f_035","IA_f_053","IA_f_065","IA_f_071","IA_f_092","IA_f_097","IA_f_099","IA_f_133","IA_f_142","IA_f_144","IA_f_169","IA_f_171","IA_f_183","IA_f_242","IA_f_246","IA_f_260","IA_f_300","IA_f_333","IA_f_341","IA_f_350","IA_f_360","IA_f_433","IA_f_437","IA_f_527","IA_f_578","IA_f_591","IA_m_044","IA_m_056","IA_m_068","IA_m_077","IA_m_181","IA_m_216","IA_m_233","IA_m_288","IA_m_322","IA_m_328","IA_m_364","IA_m_367","IA_m_451","IA_m_476","IA_m_496","IA_m_511","IA_m_517","IA_m_518","IA_m_524","IA_m_525","IA_m_542","IA_m_574","IA_m_579","IA_m_623","IA_m_624","MU_f_013","MU_f_069","MU_f_090","MU_f_211","MU_f_223","MU_f_244","MU_f_316","MU_f_426","MU_f_456","MU_f_463","MU_f_528","MU_f_590","MU_f_593","MU_m_026","MU_m_034","MU_m_039","MU_m_041","MU_m_072","MU_m_089","MU_m_091","MU_m_110","MU_m_116","MU_m_118","MU_m_121","MU_m_143","MU_m_159","MU_m_166","MU_m_179","MU_m_209","MU_m_277","MU_m_278","MU_m_286","MU_m_290","MU_m_291","MU_m_294","MU_m_299","MU_m_308","MU_m_309","MU_m_348","MU_m_373","MU_m_409","MU_m_424","MU_m_431","MU_m_490","MU_m_516","MU_m_526","MU_m_537","MU_m_555","MU_m_575","MU_m_581","MU_m_588","MU_m_602","MU_m_626","MU_m_635"],[80,73,69,54,55,71,104,43,70,52,261,49,68,81,91,62,77,76,269,95,131,67,37,50,58,53,75,83,257,44,117,68,72,72,54,142,43,142,128,146,95,59,156,50,60,382,57,88,106,108,61,75,101,106,330,73,79,110,47,285,99,70,75,69,64,74,116,79,173,62,95,77,61,56,122,93,49,49,131,88,76,80,69,68,218,87,133,168,146,388,66,88,68,49,107,63,38,89,79,64,67,127,29,147,64,72,164,59,196,67,47,80,101,61,79,68,60,88,83,52,64,56,70,54,83,93,55,57,60,90,129,61,70,84,48,44,92,130,84,55,82,44,79,93,53,88,66,114,450,48,51,111,119,92,140,230,45,104,56,65,86,70,103,71,111,65,60,163,68,59,76,212,70,50,88,54,26,67,103,335,67,59,162,299,95,105,65,147,61,232,92,137,57,54,68,90,79,61,59,107,34,75,211,32,248,64,224,63,64,93,112,47,78,199,97,163,50,275,57,40,82,46,82,128,113,54,71,40,13,60,75,46,70,74,75,48,89,61,93,73,149,76,68,85,76,63,76,175,109,157,84,98,82,67,129,100,28,76,57,69,54,61,67,54,57,33,39,36,59,63,86,37,65,73,88,288,73,131,196,43,82,50,45,84,33,50,74,56,185,108,72,69,70,231,64,57,43,72,109,54,127,81,67,30,48,55,84,61,75,54,207,67,73,74,49,59,192,90,112,47,81,50,115,74,120,53,74,80,35,79,62,55,66,143,228,30,80,72,184,54,118,165,59,58,86,115,70,115,376,577,375,178,336,344,352,398,160,375,506,342,277,463,251,624,284,637,639,404,650,491,378,344,266,270,115,452,443,369,370,127,245,402,403,354,370,124,32,409,250,450,133,246,297,137,426,47,237,229,232,588,511,140,342,132,102,223,343,474,68,211,218,448,333,391,465,412,340,412,60,205,1529,179,364,397,208,348,434,163,156,102,24,369,376,53,127,150,117,243,34,104,67,158,79,177,160,110,369,122,235,138,104,132,199,887,119,157,213,339,83,58,366,58,96,179,83,271,129,63,462,271,191,220,95,94,479,322,210,192,313,395,346],[66,64,59,44,40,49,69,33,36,38,165,61,32,77,49,32,40,49,224,70,75,43,51,38,43,42,48,65,225,25,76,42,51,40,24,95,21,116,105,190,88,49,135,44,53,324,32,38,89,67,52,65,77,83,134,62,98,51,35,176,61,93,38,54,52,59,102,55,101,39,99,74,54,36,94,65,43,78,65,57,61,42,46,57,153,72,86,99,95,334,42,70,51,36,94,34,28,48,58,50,71,140,13,128,70,78,149,50,115,61,34,61,88,58,64,51,40,51,41,33,69,40,70,24,42,47,35,58,46,80,144,69,57,68,36,32,58,84,78,50,36,51,26,54,57,62,64,77,311,57,48,66,73,62,112,193,44,55,58,56,51,39,42,49,75,86,54,71,61,39,30,177,60,38,89,62,37,52,78,268,26,44,108,242,80,78,48,88,45,104,78,152,35,38,41,48,41,55,41,71,37,65,172,29,254,41,119,51,51,90,67,29,60,164,52,112,27,172,44,24,48,22,57,100,63,40,41,46,13,66,52,26,72,46,55,55,81,56,73,50,116,65,62,50,89,64,64,111,81,130,32,58,70,25,118,68,25,54,30,68,30,35,66,39,43,53,30,39,47,75,74,34,54,47,68,248,79,143,164,32,53,66,35,81,36,30,72,34,123,125,41,44,39,139,56,76,46,26,87,42,117,79,38,32,72,49,87,44,70,98,161,63,55,66,39,73,137,48,61,62,71,36,63,77,89,43,41,51,47,53,48,65,57,97,192,12,75,52,103,34,69,116,42,42,63,52,48,75,277,378,226,111,304,265,188,341,116,237,306,181,252,276,234,461,189,508,456,353,407,355,226,327,201,133,91,262,277,238,197,54,99,245,222,244,178,58,29,264,122,434,101,124,226,89,276,35,161,125,145,395,334,99,242,74,67,225,254,284,43,142,273,318,260,328,213,325,225,259,38,149,997,165,223,275,135,217,224,57,150,41,18,270,336,16,73,141,52,136,30,59,45,84,67,109,105,59,240,77,143,63,73,94,137,739,70,146,183,283,31,46,224,18,72,137,51,198,137,42,208,152,153,139,23,36,216,163,113,140,193,172,188],[30,26,33,35,18,40,34,14,32,32,81,22,16,33,26,17,36,32,122,27,42,23,15,17,17,16,36,44,101,20,35,16,51,27,13,46,14,75,36,76,49,20,68,22,21,129,19,67,28,26,13,33,50,41,102,33,54,25,16,96,28,34,26,29,26,23,45,32,60,19,37,23,22,24,52,23,23,31,28,25,34,48,31,24,58,45,58,53,37,140,18,49,24,29,39,22,19,27,32,29,23,51,10,59,30,35,62,23,62,27,35,30,40,34,27,24,20,28,27,35,32,23,25,18,28,20,20,30,19,26,44,37,38,29,19,21,30,31,36,13,32,21,19,16,24,48,39,43,141,35,19,34,22,27,43,80,23,32,25,29,25,22,37,23,32,21,28,50,30,28,19,108,34,29,27,25,12,25,34,139,30,25,91,139,36,39,29,32,31,105,43,89,20,16,26,31,27,26,23,38,18,46,91,16,101,24,70,32,22,27,37,28,42,91,28,36,19,108,32,13,27,11,14,44,34,17,46,19,6,22,30,25,35,41,29,26,27,19,55,21,58,10,28,35,24,30,37,64,42,59,39,26,41,21,55,31,18,30,23,24,24,20,33,24,13,24,9,21,19,30,37,26,45,20,33,143,31,48,60,28,28,27,11,26,18,30,20,14,51,55,32,38,23,66,43,25,31,22,29,30,39,39,15,30,31,40,32,21,34,53,71,23,33,33,21,24,109,22,62,24,45,11,33,48,46,31,28,22,25,27,15,44,27,79,61,22,35,24,49,15,32,48,30,23,14,28,24,29,153,188,120,67,192,144,130,143,42,131,153,116,102,126,114,239,147,236,190,204,224,171,165,140,139,86,46,208,149,98,174,44,110,174,158,122,93,26,18,151,79,168,55,122,103,26,156,35,57,69,74,154,148,69,114,30,49,99,116,220,25,91,64,192,119,140,179,242,143,140,16,144,570,70,163,108,105,97,174,35,60,22,12,165,157,15,74,98,36,71,12,24,20,41,14,53,44,30,123,42,65,27,43,38,71,332,35,58,70,131,43,25,123,16,33,89,35,107,41,10,136,117,86,102,36,29,134,107,71,70,164,86,113],[94,73,56,147,52,78,178,74,115,88,442,73,126,79,125,70,65,61,655,93,181,49,52,64,45,110,83,170,297,43,231,102,66,87,106,143,67,238,233,195,161,40,177,45,98,398,55,106,196,143,71,85,126,121,236,68,149,117,70,347,85,192,107,165,104,53,204,111,239,70,238,115,113,87,110,60,74,74,193,84,100,143,133,129,190,131,162,290,228,586,61,159,86,69,124,41,62,63,118,135,122,153,43,167,114,93,186,90,183,57,107,65,220,80,76,55,67,105,53,87,88,87,92,57,134,75,55,115,112,98,289,65,103,101,29,66,84,123,91,79,66,126,46,80,134,119,95,211,514,113,49,107,112,90,181,317,49,126,67,66,134,59,94,93,108,110,130,182,147,80,55,261,58,49,134,109,60,53,112,570,70,80,173,608,129,94,132,265,104,338,133,179,59,45,80,93,158,59,57,104,49,185,481,28,277,43,236,132,36,77,90,43,88,214,167,154,118,321,79,40,119,54,48,151,191,59,163,67,20,93,163,93,93,137,144,84,178,72,121,98,202,61,64,62,119,103,86,189,86,160,87,121,151,154,290,61,44,211,74,138,95,99,121,127,93,88,67,62,57,98,180,90,120,50,99,350,106,170,199,73,149,129,44,129,68,77,119,94,333,157,84,134,94,163,57,59,82,52,129,48,148,68,60,52,94,96,116,41,146,156,170,67,179,63,71,77,169,78,158,103,84,70,87,147,170,133,115,92,55,98,88,99,123,139,239,54,146,136,133,57,113,161,91,73,139,92,96,77,347,478,387,179,441,334,298,428,138,311,374,335,273,334,307,660,518,655,701,486,597,476,320,386,348,474,147,705,336,469,325,108,592,523,397,397,386,56,42,565,209,518,232,198,511,174,402,79,392,171,189,535,907,165,374,136,98,353,387,822,105,242,221,546,470,739,389,501,237,564,113,236,1543,330,639,408,243,309,586,81,155,70,32,447,338,48,116,206,93,192,28,104,79,140,115,142,109,70,406,110,161,106,73,83,203,897,79,154,193,372,70,77,305,37,73,268,100,272,144,49,267,239,231,167,101,75,319,430,150,183,274,319,251],[58,29,32,31,30,30,36,21,42,17,111,35,38,31,51,37,45,33,223,42,76,23,25,44,23,42,36,41,150,16,64,26,26,46,31,93,21,96,83,85,57,29,90,25,25,172,12,20,45,43,44,48,63,33,63,33,52,26,17,277,32,88,33,23,24,29,56,50,101,25,74,33,27,40,78,34,26,37,49,65,28,44,56,39,75,43,74,106,94,140,27,51,49,29,69,41,21,28,62,28,28,82,16,87,43,38,81,20,60,31,37,60,57,37,54,25,39,46,25,26,68,19,36,28,33,40,40,30,24,50,91,29,25,38,30,37,72,41,31,29,34,28,24,26,31,36,51,52,258,44,28,84,66,38,94,116,32,44,24,34,38,32,55,36,44,43,28,66,100,44,26,110,64,22,53,23,26,48,60,131,45,60,114,137,49,74,46,80,38,101,49,98,19,34,57,29,22,34,24,63,25,51,114,14,147,24,112,29,25,42,50,23,42,157,64,73,33,151,11,26,45,24,37,72,53,35,55,25,9,17,67,28,52,28,57,38,31,34,71,40,118,35,33,34,44,49,40,92,85,96,44,65,57,41,73,35,20,61,36,30,29,25,50,20,26,20,18,31,38,40,41,41,42,41,36,161,59,88,99,24,38,64,33,44,32,31,53,16,128,53,33,37,18,116,29,42,38,31,87,36,70,42,48,39,36,39,59,43,52,46,121,51,44,22,28,47,71,55,71,24,42,19,35,50,77,39,39,25,15,45,44,43,44,69,167,11,46,38,89,20,58,103,38,37,30,51,49,85,228,245,200,67,190,163,147,162,89,143,245,145,197,214,143,322,148,401,269,245,364,286,172,197,136,117,59,172,205,176,111,32,42,134,163,140,132,25,12,169,87,137,63,114,121,55,169,19,105,119,127,236,198,50,189,56,50,103,196,259,34,117,81,222,176,200,133,214,152,194,25,69,815,149,147,175,108,139,198,42,85,19,8,134,158,16,73,115,46,83,10,23,19,58,26,63,50,22,176,47,102,45,48,84,111,401,37,47,118,162,63,15,211,31,37,138,50,121,91,30,185,175,143,141,49,51,156,161,68,56,168,215,144],[22,34,7,25,12,30,30,9,21,5,75,9,12,10,11,9,9,13,49,7,19,21,9,5,23,17,22,22,44,7,34,20,15,8,10,26,10,40,19,38,27,13,55,16,7,92,17,18,24,10,7,21,25,11,47,21,22,19,10,69,21,47,9,10,17,15,27,18,18,12,36,15,32,6,36,15,7,14,13,12,28,19,9,21,51,13,17,32,22,87,16,20,17,7,10,11,12,9,23,9,23,21,9,37,9,13,49,11,31,11,5,11,29,15,15,8,24,14,10,30,31,10,21,5,23,9,27,15,11,9,20,9,11,25,12,14,32,14,9,25,22,20,10,15,14,15,10,29,60,7,6,12,24,11,20,69,21,14,22,15,14,8,18,15,26,22,18,39,9,8,17,45,22,8,15,15,20,20,21,136,19,19,24,114,16,24,13,23,11,58,30,15,4,14,14,15,24,9,5,26,5,13,46,9,65,11,76,21,12,14,17,6,13,30,27,37,8,51,8,7,7,6,11,37,36,11,17,14,9,26,32,52,17,24,13,16,60,12,20,16,32,15,20,26,10,16,10,34,19,26,27,11,71,13,51,32,20,14,13,21,6,18,14,11,5,11,21,10,15,5,9,17,8,14,18,130,33,27,43,4,18,17,11,13,13,25,17,19,87,18,15,16,21,35,10,22,5,30,20,24,63,43,5,8,14,18,25,10,20,44,45,14,19,25,17,12,53,14,33,15,21,12,51,26,25,41,16,14,10,8,13,26,14,18,53,6,13,24,34,14,13,31,15,8,12,13,22,34,175,110,106,46,92,79,101,65,44,97,99,74,58,72,63,133,63,128,133,98,195,89,101,95,64,105,26,165,78,53,39,36,53,71,77,59,68,15,8,57,25,69,35,33,45,34,100,12,63,39,28,79,74,44,99,19,24,59,70,106,46,43,59,89,46,57,41,146,84,113,7,58,835,17,78,315,54,90,114,20,33,40,6,96,49,13,36,37,13,32,12,17,26,24,17,42,13,26,132,45,46,20,73,27,72,250,52,58,65,107,26,16,91,26,18,68,31,56,30,15,74,35,42,46,13,12,131,61,45,97,91,92,57],[18,14,28,9,14,12,23,16,32,12,60,10,19,26,15,18,24,26,95,30,32,17,11,20,12,15,16,16,104,16,39,10,28,14,16,34,15,39,61,34,23,19,61,9,7,75,17,30,26,20,11,21,66,30,38,29,35,23,27,72,44,19,22,23,16,14,17,33,38,22,28,19,19,15,42,26,16,11,22,16,37,24,10,20,64,28,19,47,33,111,14,22,27,11,21,7,13,13,27,11,13,50,8,34,10,25,38,20,47,20,19,18,28,17,25,17,12,18,10,13,33,27,21,17,22,26,22,9,11,16,49,15,22,31,9,10,32,15,25,10,19,22,22,7,31,14,14,25,117,13,13,44,18,24,43,59,15,29,17,15,10,8,40,27,27,16,13,18,14,18,16,49,36,20,27,18,14,38,28,130,30,34,47,85,19,39,18,23,14,52,46,83,19,36,23,21,29,24,15,27,14,26,71,8,157,13,43,26,18,26,20,9,36,72,22,53,23,78,31,15,12,14,14,46,28,6,18,33,6,8,40,18,16,32,28,14,18,17,45,11,66,30,36,18,22,21,22,76,56,45,15,41,24,11,33,17,24,22,12,16,14,29,25,16,20,17,12,7,29,26,17,15,20,24,17,58,39,31,92,8,17,14,10,25,17,25,13,13,47,32,13,17,23,67,22,24,14,31,45,30,23,22,28,18,14,27,22,12,17,22,57,20,31,23,17,20,60,26,41,10,56,16,28,18,48,27,22,24,18,11,19,16,17,43,59,13,19,10,59,12,31,70,35,27,57,40,17,23,145,145,73,45,126,103,105,86,49,105,120,96,117,87,145,232,86,252,228,167,195,132,126,158,98,85,37,168,134,108,66,43,55,130,140,110,106,25,9,99,66,115,39,45,126,33,84,18,42,48,49,137,113,43,104,67,45,127,112,115,14,79,65,125,83,169,152,162,155,128,17,78,452,50,156,111,78,164,139,44,69,22,8,96,62,8,42,86,15,48,8,48,27,47,19,85,33,28,111,32,54,53,26,42,93,327,44,54,94,104,32,33,156,20,29,55,27,74,39,17,89,63,56,82,40,23,135,94,53,74,79,66,73],[58,51,59,52,33,33,50,33,59,53,157,43,45,49,68,46,88,39,221,79,101,43,27,44,28,46,60,50,163,26,68,43,54,52,40,111,32,106,117,172,82,43,115,55,37,297,17,62,77,40,62,63,70,59,112,59,71,50,51,212,41,105,63,62,52,37,97,87,105,36,72,56,50,45,75,50,55,50,63,41,45,69,66,58,148,50,92,120,116,218,70,69,55,49,67,34,32,43,73,55,38,103,43,108,63,61,116,46,110,54,32,53,81,43,87,40,47,61,34,44,69,24,49,37,52,58,52,49,39,58,108,59,53,40,28,52,42,67,74,33,50,47,33,37,68,87,63,109,443,47,48,79,82,64,144,185,39,80,53,65,39,64,52,39,56,67,52,70,98,44,43,173,52,31,74,54,30,55,63,264,44,57,130,264,50,78,80,89,61,159,65,132,39,35,44,36,51,59,31,64,36,70,149,30,214,45,178,49,44,71,71,76,50,157,65,102,45,154,82,31,40,35,56,89,153,32,50,29,34,37,64,30,75,31,64,65,61,49,83,39,109,48,48,65,84,70,52,123,67,145,40,103,73,45,166,48,27,69,40,62,64,35,36,30,24,36,23,33,77,97,58,37,76,45,69,215,86,118,127,27,54,63,20,66,41,46,50,40,118,90,68,39,52,167,31,44,58,60,86,42,122,45,52,47,45,52,74,54,51,83,152,73,45,50,44,44,128,64,90,29,63,32,56,132,111,55,56,46,32,76,57,58,45,126,165,26,63,66,92,21,57,165,37,49,68,66,70,71,299,350,256,89,256,227,198,240,118,232,394,237,220,252,223,453,243,521,486,328,473,302,196,313,220,185,100,340,266,344,285,104,145,255,297,220,221,47,28,315,122,269,122,125,236,78,268,55,177,141,166,377,375,118,261,76,77,223,254,404,32,179,109,332,197,289,239,333,286,337,49,137,1016,158,234,272,120,222,320,59,122,35,17,308,249,31,103,120,80,235,25,73,42,73,36,110,77,51,233,91,157,60,81,87,170,639,66,114,121,263,41,47,298,33,72,151,56,215,86,39,206,168,176,193,70,83,299,207,137,155,288,228,274],[57,38,28,28,24,18,22,18,29,16,73,17,16,50,34,36,44,31,144,36,42,10,26,19,15,16,34,17,80,15,52,9,30,31,37,46,35,49,54,66,51,26,55,37,25,185,24,22,65,36,28,58,131,24,52,22,26,49,12,102,28,28,32,41,26,24,44,21,55,22,43,24,23,24,60,24,23,26,39,53,26,30,21,28,72,62,33,54,52,129,26,42,20,31,37,11,11,23,33,36,39,59,15,51,20,18,63,36,67,39,25,53,37,15,26,18,34,33,31,19,31,27,12,23,30,38,29,46,33,33,53,19,20,34,25,18,29,36,34,9,26,19,25,27,26,35,38,44,254,22,18,39,36,32,86,89,18,52,37,23,29,26,22,36,37,27,15,86,23,13,21,84,39,10,29,26,27,30,44,111,30,29,101,128,21,31,22,61,14,83,38,48,41,40,29,24,21,18,22,49,11,31,78,18,99,15,40,25,18,20,47,17,42,47,41,61,19,87,31,17,45,17,30,55,45,18,71,35,6,31,27,15,18,40,22,26,52,16,25,31,113,39,43,35,45,36,58,81,34,116,35,39,66,24,56,35,16,38,35,43,12,24,27,46,14,26,16,35,31,49,43,27,17,23,32,94,54,70,81,18,27,48,26,22,13,18,46,20,58,41,32,46,24,77,31,39,21,23,44,30,48,51,32,16,34,10,44,25,27,44,112,27,29,34,23,21,78,46,41,22,26,24,43,52,74,23,29,15,50,37,22,35,22,53,92,13,48,55,52,18,42,98,21,36,52,38,32,98,208,163,149,73,165,149,137,151,47,150,137,114,131,153,114,248,120,247,180,156,306,229,114,186,140,137,33,164,134,98,90,48,75,196,142,134,93,21,10,129,75,105,58,79,127,47,154,31,94,77,87,184,172,56,158,43,48,93,129,204,28,96,92,142,136,146,126,222,129,156,18,80,696,96,173,122,92,118,201,49,57,19,9,155,94,8,35,160,30,81,26,33,21,77,25,64,43,43,146,60,84,69,51,66,92,375,37,78,67,154,29,48,182,11,41,90,47,124,72,36,157,82,81,91,31,46,185,146,81,81,138,157,94],[48,40,30,24,21,12,34,25,42,15,90,29,21,34,35,16,29,22,147,61,65,21,18,23,21,26,38,63,131,23,60,29,21,31,19,51,19,53,49,84,66,21,84,23,36,164,14,50,38,55,37,56,68,53,93,42,45,53,14,120,45,68,15,46,33,21,30,55,62,36,50,36,21,36,91,20,22,51,50,56,23,50,35,28,101,25,57,75,38,144,45,26,41,25,51,17,38,21,45,33,38,64,22,61,23,32,78,43,95,37,23,47,30,34,48,22,37,51,24,16,37,30,38,33,42,48,14,29,17,35,63,33,31,34,20,19,42,33,36,26,33,27,13,20,32,37,16,58,215,49,18,46,47,31,71,91,29,40,25,37,27,17,43,29,32,27,19,34,38,18,36,108,27,19,58,36,15,30,55,185,14,19,97,302,27,49,31,92,23,136,57,75,24,39,41,27,28,25,35,42,11,44,120,8,173,35,79,29,22,35,85,32,35,101,54,76,14,98,29,16,29,27,35,50,31,43,32,38,15,10,47,21,37,36,31,24,48,31,44,44,76,33,31,24,28,58,41,98,57,95,43,51,68,37,92,31,27,63,38,46,20,27,67,31,28,39,20,15,34,60,35,31,31,27,29,145,53,82,70,43,36,41,20,57,22,44,60,31,71,65,42,24,35,94,37,33,40,27,51,22,91,34,27,24,43,37,33,37,38,44,92,43,54,38,27,31,80,51,60,37,42,20,33,43,82,30,37,18,21,42,33,28,17,89,87,13,49,40,41,33,42,120,23,40,64,34,51,52,185,187,131,55,153,154,126,123,86,133,238,110,160,167,139,358,150,332,247,194,402,225,166,246,159,89,61,169,143,141,94,68,54,162,171,137,132,44,14,137,82,106,56,67,273,66,88,53,75,67,94,224,146,57,180,50,60,166,147,163,45,81,86,212,160,184,139,161,122,197,28,107,648,121,178,158,133,130,159,42,67,24,8,207,111,25,55,71,49,78,5,35,38,47,26,67,56,52,200,62,90,71,56,58,113,470,72,60,125,305,46,34,191,19,51,103,71,145,130,23,133,76,170,127,55,35,237,159,63,98,136,137,129],[531,442,401,449,299,373,580,286,478,328,1515,348,393,470,505,343,457,382,2149,540,764,317,271,324,285,383,448,571,1552,235,776,365,414,408,350,787,277,954,885,1086,699,319,996,326,369,2218,264,501,694,548,386,525,777,561,1207,442,631,523,299,1756,484,744,420,522,414,349,738,541,952,343,772,472,422,369,760,410,338,421,653,497,458,549,476,472,1130,556,731,1044,861,2277,385,596,438,335,619,281,274,364,550,450,462,850,208,879,446,465,986,398,966,404,364,478,711,394,501,328,380,495,338,355,522,343,434,296,489,454,349,438,372,495,990,396,430,484,256,313,513,574,498,329,400,405,297,375,470,541,456,762,2763,435,298,622,599,471,934,1429,315,576,384,405,453,345,506,418,548,484,417,779,588,351,339,1327,462,276,594,422,267,418,598,2269,375,426,1047,2318,522,611,484,900,402,1368,631,1008,317,351,423,414,480,370,312,591,240,606,1533,192,1735,315,1177,457,312,495,596,310,486,1232,617,867,356,1495,404,229,454,256,384,772,747,315,564,346,131,370,597,354,485,489,518,396,645,367,630,423,1039,412,433,434,541,510,486,1043,636,1029,446,613,703,438,1063,458,249,638,358,517,348,373,506,398,323,347,255,289,406,543,580,355,478,364,489,1832,613,908,1131,300,502,519,255,547,293,376,524,337,1201,744,432,464,399,1155,380,421,378,374,687,358,848,504,372,296,431,423,576,348,530,644,1188,448,562,428,336,408,1077,494,729,373,531,290,544,667,842,475,457,387,308,476,401,469,432,856,1343,200,574,517,836,278,575,1077,391,393,585,529,479,659,2393,2821,2023,910,2255,1962,1782,2137,889,1914,2572,1750,1787,2144,1733,3730,1948,3917,3529,2635,3813,2756,1964,2392,1771,1681,715,2805,2165,2094,1751,664,1470,2292,2170,1917,1779,441,202,2295,1117,2371,894,1153,2065,739,2123,384,1403,1085,1191,2909,2978,841,2063,683,620,1671,2008,3051,440,1281,1268,2626,1980,2643,2076,2718,1873,2500,371,1263,9101,1335,2355,2341,1276,1834,2549,592,954,394,142,2247,1930,233,734,1184,531,1199,190,520,384,749,424,912,690,491,2136,688,1137,652,628,711,1261,5317,611,926,1249,2220,464,399,2147,269,522,1278,551,1583,899,324,1917,1378,1329,1308,513,484,2291,1850,991,1146,1844,1867,1669],[0.128,0.107,0.097,0.108,0.072,0.09,0.14,0.069,0.115,0.079,0.365,0.084,0.095,0.113,0.122,0.083,0.11,0.092,0.518,0.13,0.184,0.076,0.065,0.078,0.069,0.092,0.108,0.138,0.374,0.057,0.187,0.088,0.1,0.098,0.084,0.19,0.067,0.23,0.213,0.262,0.169,0.077,0.24,0.079,0.089,0.535,0.064,0.121,0.167,0.132,0.093,0.127,0.187,0.135,0.291,0.107,0.152,0.126,0.072,0.423,0.117,0.179,0.101,0.126,0.1,0.084,0.178,0.13,0.23,0.083,0.186,0.114,0.102,0.089,0.183,0.099,0.082,0.102,0.157,0.12,0.11,0.132,0.115,0.114,0.272,0.134,0.176,0.252,0.208,0.549,0.093,0.144,0.106,0.081,0.149,0.068,0.066,0.088,0.133,0.109,0.111,0.205,0.05,0.212,0.108,0.112,0.238,0.096,0.233,0.097,0.088,0.115,0.171,0.095,0.121,0.079,0.092,0.119,0.082,0.086,0.126,0.083,0.105,0.071,0.118,0.109,0.084,0.106,0.09,0.119,0.239,0.095,0.104,0.117,0.062,0.075,0.124,0.138,0.12,0.079,0.096,0.098,0.072,0.09,0.113,0.13,0.11,0.184,0.666,0.105,0.072,0.15,0.144,0.114,0.225,0.345,0.076,0.139,0.093,0.098,0.109,0.083,0.122,0.101,0.132,0.117,0.101,0.188,0.142,0.085,0.082,0.32,0.111,0.067,0.143,0.102,0.064,0.101,0.144,0.547,0.09,0.103,0.252,0.559,0.126,0.147,0.117,0.217,0.097,0.33,0.152,0.243,0.076,0.085,0.102,0.1,0.116,0.089,0.075,0.143,0.058,0.146,0.37,0.046,0.418,0.076,0.284,0.11,0.075,0.119,0.144,0.075,0.117,0.297,0.149,0.209,0.086,0.361,0.097,0.055,0.109,0.062,0.093,0.186,0.18,0.076,0.136,0.083,0.032,0.089,0.144,0.085,0.117,0.118,0.125,0.095,0.156,0.089,0.152,0.102,0.251,0.099,0.104,0.105,0.13,0.123,0.117,0.252,0.153,0.248,0.108,0.148,0.17,0.106,0.256,0.11,0.06,0.154,0.086,0.125,0.084,0.09,0.122,0.096,0.078,0.084,0.061,0.07,0.098,0.131,0.14,0.086,0.115,0.088,0.118,0.442,0.148,0.219,0.273,0.072,0.121,0.125,0.061,0.132,0.071,0.091,0.126,0.081,0.29,0.179,0.104,0.112,0.096,0.279,0.092,0.102,0.091,0.09,0.166,0.086,0.204,0.122,0.09,0.071,0.104,0.102,0.139,0.084,0.128,0.155,0.286,0.108,0.136,0.103,0.081,0.098,0.26,0.119,0.176,0.09,0.128,0.07,0.131,0.161,0.203,0.115,0.11,0.093,0.074,0.115,0.097,0.113,0.104,0.206,0.324,0.048,0.138,0.125,0.202,0.067,0.139,0.26,0.094,0.095,0.141,0.128,0.116,0.159,0.577,0.68,0.488,0.219,0.544,0.473,0.43,0.515,0.214,0.462,0.62,0.422,0.431,0.517,0.418,0.899,0.47,0.945,0.851,0.635,0.92,0.665,0.474,0.577,0.427,0.405,0.172,0.676,0.522,0.505,0.422,0.16,0.354,0.553,0.523,0.462,0.429,0.106,0.049,0.553,0.269,0.572,0.216,0.278,0.498,0.178,0.512,0.093,0.338,0.262,0.287,0.702,0.718,0.203,0.497,0.165,0.15,0.403,0.484,0.736,0.106,0.309,0.306,0.633,0.477,0.637,0.501,0.655,0.452,0.603,0.089,0.305,2.195,0.322,0.568,0.565,0.308,0.442,0.615,0.143,0.23,0.095,0.034,0.542,0.465,0.056,0.177,0.286,0.128,0.289,0.046,0.125,0.093,0.181,0.102,0.22,0.166,0.118,0.515,0.166,0.274,0.157,0.151,0.171,0.304,1.282,0.147,0.223,0.301,0.535,0.112,0.096,0.518,0.065,0.126,0.308,0.133,0.382,0.217,0.078,0.462,0.332,0.32,0.315,0.124,0.117,0.552,0.446,0.239,0.276,0.445,0.45,0.402]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Speaker<\/th>\n      <th>DRESS<\/th>\n      <th>FLEECE<\/th>\n      <th>GOOSE<\/th>\n      <th>KIT<\/th>\n      <th>LOT<\/th>\n      <th>NURSE<\/th>\n      <th>START<\/th>\n      <th>STRUT<\/th>\n      <th>THOUGHT<\/th>\n      <th>TRAP<\/th>\n      <th>N_tokens<\/th>\n      <th>Overall_percent<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"columnDefs":[{"className":"dt-right","targets":[2,3,4,5,6,7,8,9,10,11,12,13]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div>
<div id="normalisation" class="section level1">
<h1>Normalisation</h1>
<p>We will now normalise the raw F1 and F2 values.</p>
<p>Here, we introduce an adapted version of the Lobanov (1971) normalisation method, which we refer to as <code>Lobanov 2.0</code>. Explanations of the formula for each of the methods (Lobanov and Lobanov 2.0) are given below. Please refer to the paper for reasons why this adapted version was preferred to Lobanov’s original normalisation method.</p>
<div id="lobanov-formula" class="section level2">
<h2>Lobanov formula:</h2>
<p><span class="math display">\[
\begin{equation}
F_{lobanov_i} = \frac{(F_{raw_i}-\mu_{raw_i})}{\sigma_{raw_i}}
\end{equation}
\]</span></p>
<ul>
<li><span class="math inline">\(i\)</span> = either F1 or F2</li>
<li><span class="math inline">\(F_{lobanov_i}\)</span> = the normalised value in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(F_{raw_i}\)</span> = the raw formant measurement value in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\mu_{raw_i}\)</span> = the mean formant value calculated across all raw values in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\sigma_{raw_i}\)</span> = the standard deviation calculated across all raw values in <span class="math inline">\(i\)</span></li>
</ul>
<p>In plain English, the formula subtracts the mean formant value of a speaker from the raw individual formant value, then divides that by the standard deviation of the formant values.</p>
<p>e.g. if a speaker has a raw F1 of 400hz, a mean F1 of 500hz and a standard deviation of 70hz, this would give a Lobanov normalised value of (400-500)/70 = -1.43.</p>
</div>
<div id="lobanov-2.0-formula" class="section level2">
<h2>Lobanov 2.0 formula:</h2>
<p><span class="math display">\[
\begin{equation}
F_{lobanov2.0_i} = \frac{(F_{raw_i}-\mu_{(\mu_{vowel_1},\cdots,\mu_{vowel_n})})}{\sigma_{(\mu_{vowel_1},\cdots,\mu_{vowel_n})}}
\end{equation}
\]</span></p>
<ul>
<li><span class="math inline">\(i\)</span> = either F1 or F2</li>
<li><span class="math inline">\(F_{lobanov2.0_i}\)</span> = the normalised value in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(F_{raw_i}\)</span> = the raw formant measurement value in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\mu_{(\mu_{vowel_1},\cdots,\mu_{vowel_n})}\)</span> = the mean taken from the mean formant value calculated per vowel in <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\sigma_{(\mu_{vowel_1},\cdots,\mu_{vowel_n})}\)</span> = the standard deviation taken from the mean formant value calculated per vowel in <span class="math inline">\(i\)</span></li>
</ul>
<p>In plain English, the formula subtracts the mean of means formant value of a speaker (calculated as the mean of means, where a mean for each vowel is calculated, then the mean taken of those means) from the raw individual formant value, then divides that by the standard deviation of the mean of mean values.</p>
<p>e.g. if a speaker has a raw F1 of 400hz, a mean of means F1 of 550hz and a standard deviation (for the mean of means) of 70hz, this would give a Lobanov 2.0 normalised value of (400-550)/70 = -2.14.</p>
</div>
<div id="implementation" class="section level2">
<h2>Implementation</h2>
<p>The primary difference between the formula for this adapted version and Lobanov’s original formula, is that each of the vowels has a mean formant value calculated, then a mean of those means is taken as the mean in the formula. The motivation for doing this is that the data we are normalising contains speakers with varying numbers of tokens across the different vowels. Lobanov’s method is suited (and designed) based on balanced data, where an equal number of tokens per vowel are normalised.</p>
<p>When normalising with unbalanced numbers of tokens per vowel, the calculation of <span class="math inline">\(\mu_{raw_i}\)</span> (the mean of all the raw formant values), can be skewed by tokens that have a much larger count in a certain vowel.</p>
<p>Therefore, we first calculate means for each of the individual vowels (per speaker, per formant), then calculate the mean based on those means. This approach allows for tokens in vowel categories to be weighted equally regardless of how many tokens there are, making the normalisation more reliable for this type of dataset.</p>
<p>For visualisation purposes, we plot the normalised values for F1 and F2 against each other in the plots below (Lobanov 2.0 is on the x axis and Lobanov on the y axis, with coloured lines representing each speaker, the black line represents where the values would be if they were equal, i.e. if Lobanov 2.0 = Lobanov)</p>
<pre class="r"><code>#standard Lobanov normalisation - calculate means across all vowels per speaker
summary_vowels_all_lobanov &lt;- vowels_all %&gt;%
  group_by(Speaker) %&gt;%
  dplyr::summarise(mean_F1_lobanov = mean(F1_50),
            mean_F2_lobanov = mean(F2_50),
            sd_F1_lobanov = sd(F1_50),
            sd_F2_lobanov = sd(F2_50),
            token_count = n())

#Lobanov 2.0 - calculate means per vowel and per speaker
summary_vowels_all &lt;- vowels_all %&gt;%
  group_by(Speaker, Vowel) %&gt;%
  dplyr::summarise(mean_F1 = mean(F1_50),
            mean_F2 = mean(F2_50),
            sd_F1 = sd(F1_50),
            sd_F2 = sd(F2_50),
            token_count_vowel = n())

#get the mean_of_means and sd_of_means from the the speaker_summaries, this will give each speaker a mean caculated from the means across all vowels, as well as the standard deviation of the means
summary_mean_of_means &lt;- summary_vowels_all %&gt;%
  group_by(Speaker) %&gt;%
  dplyr::summarise(mean_of_means_F1 = mean(mean_F1),
            mean_of_means_F2 = mean(mean_F2),
            sd_of_means_F1 = sd(mean_F1),
            sd_of_means_F2 = sd(mean_F2)
            )

#combine these values with the full raw dataset, then use these values to normalise the data with both the Lobanov and the Lobanov 2.0 method
vowels_all &lt;- vowels_all %&gt;%
  #add in the data
  left_join(., summary_mean_of_means) %&gt;%
  left_join(., summary_vowels_all[, c(&quot;Speaker&quot;, &quot;Vowel&quot;, &quot;token_count_vowel&quot;)]) %&gt;%
  left_join(., summary_vowels_all_lobanov) %&gt;%
  #normalise the raw F1 and F2 values with Lobanov
  mutate(F1_lobanov = (F1_50 - mean_F1_lobanov)/sd_F1_lobanov,
         F2_lobanov = (F2_50 - mean_F2_lobanov)/sd_F2_lobanov,
  #normalise with Lobanov 2.0
         F1_lobanov_2.0 = (F1_50 - mean_of_means_F1)/sd_of_means_F1,
         F2_lobanov_2.0 = (F2_50 - mean_of_means_F2)/sd_of_means_F2) %&gt;%
  #remove the variables that are not required
  dplyr::select(-(mean_of_means_F1:sd_of_means_F2), -(mean_F1_lobanov:sd_F2_lobanov))

#remove the previous summary data frames
rm(summary_vowels_all_lobanov, summary_vowels_all, summary_mean_of_means)

#inspect the relationship between the two normalised values
vowels_all %&gt;%
  ggplot(aes(x = F1_lobanov_2.0, y = F1_lobanov, colour = Speaker)) +
  geom_smooth(method = &quot;lm&quot;, size = 0.1, show.legend = FALSE) +
  geom_abline(slope=1, intercept=0) +
  theme_bw()</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-9-1.png" width="2100" /></p>
<pre class="r"><code>vowels_all %&gt;%
  ggplot(aes(x = F2_lobanov_2.0, y = F2_lobanov, colour = Speaker)) +
  geom_smooth(method = &quot;lm&quot;, size = 0.1, show.legend = FALSE) +
  geom_abline(slope=1, intercept=0) +
  theme_bw()</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-9-2.png" width="2100" /></p>
</div>
</div>
<div id="gamm-modelling" class="section level1">
<h1>GAMM modelling</h1>
<p>In order to analyse co-variation in the dataset, we first must extract a measure of how the speakers vocalic variables differ from one another. To achieve this, we first run a series of Generalised Additive Mixed Models (GAMMs), from which we can extract the by-speaker random intercepts. This is done using the <code>mgcv</code> and <code>itsadug</code> packages, if you are unfamiliar with this form of analysis, see (Winter and Wieling, (2016))[<a href="https://academic.oup.com/jole/article/1/1/7/2281883" class="uri">https://academic.oup.com/jole/article/1/1/7/2281883</a>] or (Sóskuthy, (2017))[<a href="https://arxiv.org/abs/1703.05339" class="uri">https://arxiv.org/abs/1703.05339</a>], for further information about why we chose the by-speaker intercepts, please refer to the manuscript or see <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/6B661A6226E015A613AB22616C9C2300/S0954394512000014a.pdf/exploiting_random_intercepts_two_case_studies_in_sociophonetics.pdf">Drager and Hay (2012)</a></p>
<p>In total there will be 20 separate models (10 vowels x 2 formants) that will be fitted, each of which we will extract the random intercepts from the random effect of <code>Speaker</code>, as well as the model summary.</p>
<div id="fitting-procedure" class="section level2">
<h2>Fitting procedure</h2>
<p>Each of the models will use the data from one of the 10 vowels (in the <code>Vowel</code> variable) and will have either the <code>F1_lobanov_2.0</code> or the <code>F2_lobanov_2.0</code> variable as the dependent/predicted measure.</p>
<p>All models will be fit uniformly, i.e. with the same fixed and random effects structures.</p>
<p>The fixed effects are:</p>
<ul>
<li><p>An interaction between <code>participant_year_of_birth</code> and <code>Gender</code></p></li>
<li><p><code>participant_year_of_birth</code></p></li>
<li><p><code>Gender</code></p></li>
<li><p><code>Speech_rate</code></p></li>
</ul>
<p>The random effects are:</p>
<ul>
<li><p><code>Speaker</code></p></li>
<li><p><code>Word</code></p></li>
</ul>
<p>The <code>participant_year_of_birth</code> variable is modeled with a smooth term with 10 knots, this is to account for the non-linear ‘wiggliness’ of the effect.</p>
<p>To run the models in an efficient way and store the by-speaker intercepts, we use a <code>for</code> loop to iterate through each of the vowels, extracting the intercepts from each model and adding them to a data frame.</p>
<p>A for loop works by iterating over each value in a series, here we will loop through each value in our <code>Vowels</code> variable and extract the relevant information.</p>
<p>e.g the for loop will start with <code>DRESS</code>, run the GAMM for F1, extract the by-speaker intercepts from that model, it will then run the GAMM for F2, extract the speaker intercepts from this model, then add the 2 sets of intercepts to a data frame (<code>gam_intercepts.tmp</code>). The loop will then move on to the next vowel, <code>FLEECE</code> and do exactly the same process. The loop will finish once all vowels have been ‘looped’ through.</p>
<p>This will result in a data frame comprising:</p>
<ul>
<li><p>494 rows (one row per speaker)</p></li>
<li><p>1 column identifying the speaker name</p></li>
<li><p>20 additional columns identifying the variable being modeled (e.g. F1_DRESS), the numeric values here represent the by-speaker intercepts from that variable’s model</p></li>
</ul>
<p><strong>Note, this process takes several hours (six and half hours on my machine) to complete</strong>. The output has been stored in files in the <code>GAMM_output</code> folder, for quick reference. Please see those files or load them in to your R session for the rest of the analysis if you do not run the following code chunk.</p>
<p>The intercepts are saved as <code>gamm_intercepts.csv</code>, the model summaries can be found in the <code>model_summaries</code> sub-folder, where each model summary is stored as a <code>.rds</code> file, e.g. <code>gam_summary_F1_DRESS.rds</code> contains the model summary for F1_DRESS.</p>
<pre class="r"><code>#update the Gender variable to allow for conrast coding
vowels_all$Gender &lt;- as.ordered(vowels_all$Gender)
contrasts(vowels_all$Gender) &lt;- &quot;contr.treatment&quot;

vowels_all &lt;- vowels_all %&gt;%
  arrange(as.character(Speaker))</code></pre>
<pre class="r"><code>#create a data frame to store the intercepts from the models, this will initially contain just the speaker names
gam_intercepts.tmp &lt;- vowels_all %&gt;%
  dplyr::select(Speaker) %&gt;%
  distinct()

#loop through the vowels
cat(paste0(&quot;Start time:\n&quot;, format(Sys.time(), &quot;%d %B %Y, %r\n&quot;)))

for (i in levels(factor(vowels_all$Vowel))) {
  
  #F1 modelling
  
  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F1 for FLEECE
  gam.F1 &lt;- bam(F1_lobanov_2.0 ~
                  s(participant_year_of_birth, k=10, bs=&quot;ad&quot;, by=Gender) +
                  s(participant_year_of_birth, k=10, bs=&quot;ad&quot;) +
                  Gender +
                  s(Speech_rate) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)
  
  #extract the speaker intercepts from the model and store them in a temporary data frame
  gam.F1.intercepts.tmp &lt;- as.data.frame(get_random(gam.F1)$`s(Speaker)`)
  
  #assign the model to an object
  assign(paste0(&quot;gam_F1_&quot;, i), gam.F1)
  
  #save the model summary
  saveRDS(gam.F1, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/gam_F1_&quot;, i, &quot;.rds&quot;))
  
  cat(paste0(&quot;F1_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;)) #print the vowel the loop is up to for F1, as well as the start time for the model
  
  #F2 modelling
  
  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F2 for FLEECE
  gam.F2 &lt;- bam(F2_lobanov_2.0 ~
                  s(participant_year_of_birth, k=10, bs=&quot;ad&quot;, by=Gender) +
                  s(participant_year_of_birth, k=10, bs=&quot;ad&quot;) +
                  Gender +
                  s(Speech_rate) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)
  
  #extract the speaker intercepts again, storing them in a separate data frame
  gam.F2.intercepts.tmp &lt;- as.data.frame(get_random(gam.F2)$`s(Speaker)`)
  
  #assign the model to an object
  assign(paste0(&quot;gam_F2_&quot;, i), gam.F2)
  
  #save the model summary
  saveRDS(gam.F2, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/gam_F2_&quot;, i, &quot;.rds&quot;))

  #rename the variables so it clear which one has F1/F2, i.e. this will give F1_FLEECE, F2_FLEECE
  names(gam.F1.intercepts.tmp) &lt;- paste0(&quot;F1_&quot;, i)
  names(gam.F2.intercepts.tmp) &lt;- paste0(&quot;F2_&quot;, i)
  
  #combine the intercepts for F1 and F2 and store them in the intercepts.tmp_stress data frame
  gam_intercepts.tmp &lt;- cbind(gam_intercepts.tmp, gam.F1.intercepts.tmp, gam.F2.intercepts.tmp)
  
  cat(paste0(&quot;F2_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;)) #print the vowel the loop is up to for F2 , as well as the start time for the model
}

#save the intercepts as a .csv file
write.csv(gam_intercepts.tmp, &quot;Data/gam_intercepts_tmp_new.csv&quot;, row.names = FALSE)</code></pre>
</div>
<div id="read-in-pre-run-model-results" class="section level2">
<h2>Read in pre-run model results</h2>
<p>In order to save time running through the GAMM modelling chunk above, the results have been stored in the repository for quick loading. The below code will load the files in to your R session.</p>
<pre class="r"><code>#load in model intercepts
gam_intercepts.tmp &lt;- read.csv(&quot;Data/gam_intercepts_tmp_new.csv&quot;)</code></pre>
<pre class="r"><code>#make vector containing all .rds filenames from model_summaries folder
model_summary_files = list.files(pattern=&quot;*.rds&quot;, path = &quot;/Users/james/Documents/GitHub/model_summaries&quot;)

#load each of the files with for loop
for (i in model_summary_files) {
  cat(paste0(i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;)) 
  assign(gsub(&quot;.rds&quot;, &quot;&quot;, i), readRDS(paste0(&quot;/Users/james/Documents/GitHub/model_summaries/&quot;, i)))
}</code></pre>
</div>
<div id="understanding-the-intercepts" class="section level2">
<h2>Understanding the intercepts</h2>
<p>In order to better understand these intercepts and how they represent each speaker’s position in relation to the population, it can be helpful to visualise the speaker intercepts in relation to the vowel space.</p>
<p>We interpret the speaker intercepts in terms of how advanced the vowel productions are in relation to other speakers with similar fixed-effects - in other words, if a speaker has a <strong>large positive intercept</strong> from a model (with a fixed-effects structure as that used in our above modelling procedure), this would indicate that the speaker is producing formant values that are typically <strong>larger</strong> than other speakers <strong>with similar fixed-effects values</strong>, e.g. year of birth, gender etc. Likewise, if the intercept is <strong>negative</strong>, this would indicate that their F values are smaller, the closer the intercept is to <strong>0</strong>, the more typical the speaker is (taking into account the fixed-effects).</p>
<p>To demonstrate this, we will visualise the change in <code>F1</code> for three vowels, known to have undergone rapid change in New Zealand English (<code>TRAP</code>, <code>DRESS</code> and <code>KIT</code>). We will plot the participant year of birth on the x axis and normalised F1 on the y axis (reverse scaled to match normal vowel plot conventions). To highlight the change in the three vowels over time, we will also fit a smooth and plot the mean F1 values of each speaker for each of the vowels. Finally, we will highlight 4 speakers who all have intercepts that indicate that they are <strong>advanced</strong> in these vowel changes, i.e. have negative intercepts (smaller F1) for <code>TRAP</code> and <code>DRESS</code>, but positive intercepts (larger F1) for <code>KIT</code>.</p>
<p>The code blocks below will reproduce <strong>Figure XX</strong> in the manuscript. The first chunk calculates mean F1 values / speaker and merges this data with the speaker intercepts from the GAMMs.</p>
<p>The second chunk extracts predictions from the GAMMs for plotting smooths over year of birth. (This code block produces plots that are not included in the RMarkdown output).</p>
<pre class="r"><code>vowels_to_plot &lt;- c(&quot;KIT&quot;, &quot;DRESS&quot;, &quot;TRAP&quot;)

pred_table &lt;- function (Vowel) {
  mod_name &lt;- paste0(&quot;gam_F1_&quot;, Vowel)
  return(cbind(Vowel, 
               plot_smooth(get(mod_name), view=&quot;participant_year_of_birth&quot;, 
                           rm.ranef=T, rug=F, n.grid=119)$fv)
  )
}

gamm_preds_to_plot &lt;- lapply(vowels_to_plot, pred_table) %&gt;%
  do.call(rbind, .)

saveRDS(gamm_preds_to_plot, &quot;Data/Models/gamm_preds_to_plot.rds&quot;)</code></pre>
<pre class="r"><code>gamm_preds_to_plot &lt;- readRDS(&quot;Data/Models/gamm_preds_to_plot.rds&quot;)</code></pre>
<p>We now plot the data.</p>
<pre class="r"><code>#make a long version of the intercepts
gam_intercepts.tmp_long &lt;- gam_intercepts.tmp %&gt;%
  pivot_longer(F1_DRESS:F2_TRAP, names_to = &quot;Vowel_formant&quot;, values_to = &quot;Intercept&quot;) %&gt;%
  mutate(Formant = substr(Vowel_formant, 1, 2),
         Vowel = substr(Vowel_formant, 4, max(nchar(Vowel_formant)))) %&gt;%
  left_join(vowels_all %&gt;%
  select(Speaker, participant_year_of_birth) %&gt;% distinct()) %&gt;%
  left_join(gamm_preds_to_plot %&gt;% mutate(Formant = &quot;F1&quot;) %&gt;% select(participant_year_of_birth, Vowel, Formant, fit, ll, ul))

speakers1 &lt;- gam_intercepts.tmp_long %&gt;%
  filter(Vowel_formant %in% c(&quot;F1_KIT&quot;, &quot;F1_DRESS&quot;, &quot;F1_TRAP&quot;)) %&gt;%
  ungroup() %&gt;%
  arrange(participant_year_of_birth) %&gt;%
  filter(Speaker %in% c(&quot;MU_m_348&quot;, &quot;IA_f_341&quot;, &quot;CC_m_167&quot;, &quot;CC_f_297&quot;)) %&gt;%
  mutate(letters = c(rep(&quot;A&quot;, 3), rep(&quot;B&quot;, 3), rep(&quot;C&quot;, 3), rep(&quot;D&quot;, 3)),
         speakers1 = paste0(letters, &quot; (&quot;, round(Intercept, 2), &quot;)&quot;))

F1_speaker_intercepts &lt;- gam_intercepts.tmp_long %&gt;%
  filter(Vowel %in% c(&quot;KIT&quot;, &quot;DRESS&quot;, &quot;TRAP&quot;),
         Formant == &quot;F1&quot;) %&gt;% #choose the vowels
  mutate(Vowel = factor(Vowel, levels = c(&quot;TRAP&quot;, &quot;DRESS&quot;, &quot;KIT&quot;))) %&gt;% #order the vowels
  ggplot(aes(x = participant_year_of_birth, y = fit, colour = Vowel, fill = Vowel)) +
  geom_point(aes(x = participant_year_of_birth, y = fit + Intercept), size = 1, alpha = 0.2) +
  geom_line() +
  geom_ribbon(aes(ymin=ll, ymax=ul), colour = NA, alpha=0.2) +
  geom_point(data = speakers1 %&gt;% mutate(fit = ifelse(speakers1 %in% c(&quot;D (-0.36)&quot;), fit - 0.05, fit)), aes(x = participant_year_of_birth, y = fit + Intercept), size = 4) +
  geom_label(data = speakers1 %&gt;% mutate(fit = ifelse(speakers1 %in% c(&quot;B (0.23)&quot;), fit - 0.1, fit), fit = ifelse(speakers1 %in% c(&quot;D (-0.36)&quot;), fit - 0.1, fit)), aes(x = participant_year_of_birth - 1, y = fit + Intercept, label = speakers1), fill = &quot;white&quot;, alpha = 0.5, hjust = 1, show.legend = FALSE) +
  scale_y_reverse() +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;)) +
  scale_fill_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;)) +
  xlab(&quot;Participant year of birth&quot;) + #x axis title
  ylab(&quot;Normalised F1 (Lobanov 2.0)&quot;) + #y axis title
  theme_bw() + #general aesthetics
  theme(legend.position = c(0.8, 0.1), #legend position
        legend.direction = &quot;horizontal&quot;,
        legend.background = element_rect(colour = &quot;black&quot;),
        axis.text = element_text(size = 14), #text size
        axis.title = element_text(face = &quot;bold&quot;, size = 14), #axis text aesthetics
        legend.title = element_blank(), #legend title text size
        legend.text = element_text(size = 14)) #legend text size
 
F1_speaker_intercepts</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-16-1.png" width="2100" /></p>
<pre class="r"><code>ggsave(plot = F1_speaker_intercepts, filename = &quot;Figures/F1_speaker_intercepts.png&quot;, width = 10, height = 5, dpi = 400)

#clean up
rm(speakers, speakers1, F1_speaker_intercepts)</code></pre>
</div>
<div id="visualisation-of-intercept-correlations" class="section level2">
<h2>Visualisation of intercept correlations</h2>
<p>Understanding how the intercepts may be correlated to each other is an important first step to how they relate to each other. However, simply using correlations to gain a full understanding of how the covariation is operating, may not be sufficient. We present below an initial outline of the correlations between the intercepts.</p>
<ol style="list-style-type: decimal">
<li>Checking the distribution of the intercepts</li>
</ol>
<pre class="r"><code>gam_intercepts.tmp %&gt;%
  select(-1) %&gt;%
  pivot_longer(cols = 1:20, names_to = &quot;variable&quot;, values_to = &quot;intercept&quot;) %&gt;%
  ggplot(aes(x = intercept, y = ..density..)) +
  geom_histogram(bins = 500) +
  geom_density(outline.type = &quot;upper&quot;, colour = &quot;red&quot;, bw = &quot;SJ&quot;) +
  facet_wrap(~variable) +
  theme_bw()</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-17-1.png" width="2100" /></p>
<ol start="2" style="list-style-type: decimal">
<li>The correlations themselves</li>
</ol>
<pre class="r"><code>intercepts_cor &lt;- cor(gam_intercepts.tmp[-1] %&gt;%
             select(starts_with(&quot;F1&quot;), starts_with(&quot;F2&quot;)))

datatable(intercepts_cor) %&gt;%
  formatRound(columns = 1:20)</code></pre>
<div id="htmlwidget-f30d7598595affc4f25a" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-f30d7598595affc4f25a">{"x":{"filter":"none","data":[["F1_DRESS","F1_FLEECE","F1_GOOSE","F1_KIT","F1_LOT","F1_NURSE","F1_START","F1_STRUT","F1_THOUGHT","F1_TRAP","F2_DRESS","F2_FLEECE","F2_GOOSE","F2_KIT","F2_LOT","F2_NURSE","F2_START","F2_STRUT","F2_THOUGHT","F2_TRAP"],[1,-0.150577262605689,-0.345089699218088,-0.0878753599818823,-0.23672760644232,0.0172940435025468,-0.1046503101159,-0.0677302259816717,-0.177600111536543,0.296959763213368,-0.0991514251312525,0.131084675076392,-0.0367696357948146,0.247915874646898,0.15394948054031,-0.084673554638049,0.0972198886910256,0.124135460352217,-0.23956350706249,-0.15320544557016],[-0.150577262605689,1,0.270684089318983,0.189528692991922,-0.23410723064925,-0.348204553324547,0.379269126785242,0.0812119795417221,-0.345459779836512,-0.232337105370901,-0.0741103615157812,-0.340096635584723,0.0180272121499258,-0.273920202388462,-0.134788906365205,0.290935439292658,0.141664106303743,0.0415777943365739,-0.0490266859232344,0.211331725014072],[-0.345089699218088,0.270684089318983,1,0.00362020145027982,-0.167357939810456,-0.2358463541677,0.365331618738711,0.0879823273634769,-0.202968372462573,-0.302717254982891,-0.051142296743497,-0.203863000667145,-0.104324996533344,-0.204334164967002,-0.0198187056455555,0.221027332788623,0.123510485837624,0.0400919324414646,-0.0323584362846592,0.0757118325067108],[-0.0878753599818823,0.189528692991922,0.00362020145027982,1,-0.0772243788377938,-0.308388004681174,-0.0463202375062465,0.225702881511463,-0.146412373991007,-0.283777488258082,-0.00418931501570463,-0.261902141065607,0.121094996901765,-0.330165618472217,-0.0249066676248671,0.241168191263382,0.119737598257922,0.0649226369873936,-0.0967505394881595,0.0210004390870278],[-0.23672760644232,-0.23410723064925,-0.167357939810456,-0.0772243788377938,1,-0.196837101207949,-0.491640434021954,0.00743982037989305,0.344036954972505,-0.163666566868058,0.0156507086865703,0.0303068885398981,0.0290051391897743,0.0335549767658825,-0.0808882176639231,-0.0438237797579856,-0.174144643406338,-0.148008377886788,0.175029302403377,-0.00819131260533068],[0.0172940435025468,-0.348204553324547,-0.2358463541677,-0.308388004681174,-0.196837101207949,1,0.121719363107564,-0.198626251361231,-0.186686190594763,0.133031800926254,0.0242077019390717,0.187940327396672,0.0486979009864176,0.206094434881475,0.178158467343655,-0.276141688312294,-0.00449358264593087,0.156202510630392,-0.146320132271829,-0.0925497271423781],[-0.1046503101159,0.379269126785242,0.365331618738711,-0.0463202375062465,-0.491640434021954,0.121719363107564,1,-0.330600012322281,-0.293844171849427,-0.181897538337167,-0.0525650130938627,-0.180234630952433,0.0752079562510606,-0.0607173550942958,-0.0287195546039375,0.123049749260233,0.0853637952820863,0.0777991756487228,-0.139947779302143,0.115750234271154],[-0.0677302259816717,0.0812119795417221,0.0879823273634769,0.225702881511463,0.00743982037989305,-0.198626251361231,-0.330600012322281,1,-0.152671395241397,-0.270954330660044,0.0230679924228311,-0.0943427380952043,-0.032688946511377,-0.173369379752346,-0.108005709265382,0.137210344311722,0.100320637686243,0.0481218676921911,-0.0330257384804587,0.0620121796901523],[-0.177600111536543,-0.345459779836512,-0.202968372462573,-0.146412373991007,0.344036954972505,-0.186686190594763,-0.293844171849427,-0.152671395241397,1,-0.202807934572034,0.0681510802511974,0.179091231071787,-0.0542584825146337,-0.023239342576852,-0.283651273205374,-0.113592607497368,-0.317800867368352,-0.412519319814382,0.489425436630949,-0.00471982511883381],[0.296959763213368,-0.232337105370901,-0.302717254982891,-0.283777488258082,-0.163666566868058,0.133031800926254,-0.181897538337167,-0.270954330660044,-0.202807934572034,1,0.0550081530349359,0.194201107473885,0.00129797179289577,0.26594155382204,0.230577493243025,-0.224346113221858,0.0373791189372882,0.0153037734156169,-0.157414467973265,-0.137446132635439],[-0.0991514251312525,-0.0741103615157812,-0.051142296743497,-0.00418931501570463,0.0156507086865703,0.0242077019390717,-0.0525650130938627,0.0230679924228311,0.0681510802511974,0.0550081530349359,1,0.274187219313353,-0.372872750137775,-0.268686043308723,-0.00122627830569218,-0.387648067844393,-0.247734359031633,-0.325193937949888,0.229232442427302,0.157311065915783],[0.131084675076392,-0.340096635584723,-0.203863000667145,-0.261902141065607,0.0303068885398981,0.187940327396672,-0.180234630952433,-0.0943427380952043,0.179091231071787,0.194201107473885,0.274187219313353,1,-0.31056863737882,-0.0305401475811631,0.191140845723862,-0.576438367615427,-0.199651603787512,-0.22998407981982,0.144726629685811,-0.191844614124049],[-0.0367696357948146,0.0180272121499258,-0.104324996533344,0.121094996901765,0.0290051391897743,0.0486979009864176,0.0752079562510606,-0.032688946511377,-0.0542584825146337,0.00129797179289577,-0.372872750137775,-0.31056863737882,1,0.052327299066373,-0.0746612779249966,0.214935591568553,0.0473654174668634,0.0469786941089354,-0.210297653916714,-0.316537060432793],[0.247915874646898,-0.273920202388462,-0.204334164967002,-0.330165618472217,0.0335549767658825,0.206094434881475,-0.0607173550942958,-0.173369379752346,-0.023239342576852,0.26594155382204,-0.268686043308723,-0.0305401475811631,0.052327299066373,1,0.162871556083676,-0.0489344180369648,-0.0145177838746217,0.26672554975339,-0.210428455049288,-0.282062108121432],[0.15394948054031,-0.134788906365205,-0.0198187056455555,-0.0249066676248671,-0.0808882176639231,0.178158467343655,-0.0287195546039375,-0.108005709265382,-0.283651273205374,0.230577493243025,-0.00122627830569218,0.191140845723862,-0.0746612779249966,0.162871556083676,1,-0.170261888518389,0.133888678585901,0.316630751823917,-0.50742345183015,-0.210042710013554],[-0.084673554638049,0.290935439292658,0.221027332788623,0.241168191263382,-0.0438237797579856,-0.276141688312294,0.123049749260233,0.137210344311722,-0.113592607497368,-0.224346113221858,-0.387648067844393,-0.576438367615427,0.214935591568553,-0.0489344180369648,-0.170261888518389,1,0.0758747703878352,0.119849786666898,-0.129206553585048,-0.196566490398637],[0.0972198886910256,0.141664106303743,0.123510485837624,0.119737598257922,-0.174144643406338,-0.00449358264593087,0.0853637952820863,0.100320637686243,-0.317800867368352,0.0373791189372882,-0.247734359031633,-0.199651603787512,0.0473654174668634,-0.0145177838746217,0.133888678585901,0.0758747703878352,1,0.478065687744843,-0.540609419890753,-0.102534243833152],[0.124135460352217,0.0415777943365739,0.0400919324414646,0.0649226369873936,-0.148008377886788,0.156202510630392,0.0777991756487228,0.0481218676921911,-0.412519319814382,0.0153037734156169,-0.325193937949888,-0.22998407981982,0.0469786941089354,0.26672554975339,0.316630751823917,0.119849786666898,0.478065687744843,1,-0.580479913751471,-0.197599941138636],[-0.23956350706249,-0.0490266859232344,-0.0323584362846592,-0.0967505394881595,0.175029302403377,-0.146320132271829,-0.139947779302143,-0.0330257384804587,0.489425436630949,-0.157414467973265,0.229232442427302,0.144726629685811,-0.210297653916714,-0.210428455049288,-0.50742345183015,-0.129206553585048,-0.540609419890753,-0.580479913751471,1,0.239913449805023],[-0.15320544557016,0.211331725014072,0.0757118325067108,0.0210004390870278,-0.00819131260533068,-0.0925497271423781,0.115750234271154,0.0620121796901523,-0.00471982511883381,-0.137446132635439,0.157311065915783,-0.191844614124049,-0.316537060432793,-0.282062108121432,-0.210042710013554,-0.196566490398637,-0.102534243833152,-0.197599941138636,0.239913449805023,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>F1_DRESS<\/th>\n      <th>F1_FLEECE<\/th>\n      <th>F1_GOOSE<\/th>\n      <th>F1_KIT<\/th>\n      <th>F1_LOT<\/th>\n      <th>F1_NURSE<\/th>\n      <th>F1_START<\/th>\n      <th>F1_STRUT<\/th>\n      <th>F1_THOUGHT<\/th>\n      <th>F1_TRAP<\/th>\n      <th>F2_DRESS<\/th>\n      <th>F2_FLEECE<\/th>\n      <th>F2_GOOSE<\/th>\n      <th>F2_KIT<\/th>\n      <th>F2_LOT<\/th>\n      <th>F2_NURSE<\/th>\n      <th>F2_START<\/th>\n      <th>F2_STRUT<\/th>\n      <th>F2_THOUGHT<\/th>\n      <th>F2_TRAP<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"targets":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],"render":"function(data, type, row, meta) { return DTWidget.formatRound(data, 2, 3, \",\", \".\"); }"},{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render"],"jsHooks":[]}</script>
<ol start="3" style="list-style-type: decimal">
<li>A chord plot that visualises the correlations. This plot will give a more simplified representation of the above plot, it connects each of the variables to all the other variables via chords. The black chords indicate a positive correlation, whereas a red chord represents a negative correlation. The size and transparency of the chord indicates the strength of the correlation, with darker wider chords being used for the strongest correlations</li>
</ol>
<p>The code below adapts the code used in Zuguang Gu’s tutorial (see <a href="http://jokergoo.github.io/blog/html/large_matrix_circular.html" class="uri">http://jokergoo.github.io/blog/html/large_matrix_circular.html</a>)</p>
<pre class="r"><code>mat &lt;- cor(gam_intercepts.tmp[-1] %&gt;%
             select(starts_with(&quot;F2&quot;), starts_with(&quot;F1&quot;)))

diag(mat) = 0
mat[lower.tri(mat)] = 0
n = nrow(mat)
rn = rownames(mat)

group_size = c(rep(1, 20))
gl = lapply(1:20, function(i) {
    rownames(mat)[sum(group_size[seq_len(i-1)]) + 1:group_size[i]]
})
names(gl) = names(mat)

group_color = structure(circlize::rand_color(20), names = names(gl))
n_group = length(gl)

col_fun = colorRamp2(c(-1, 0, 1), c(&quot;red&quot;, &quot;transparent&quot;, &quot;black&quot;), transparency = 0.1)

par(mfrow=c(1,3))

# &lt; |0.2|
mat1 &lt;- ifelse(mat &lt; 0.2 &amp; mat &gt; -0.2, mat, 0)

col2 &lt;- col_fun(mat1)
col2 &lt;- ifelse(col2 == &quot;#FFFFFFE6&quot;, NA, col2)

chordDiagram(mat, col = col2, grid.col = NA, grid.border = &quot;black&quot;, 
                      annotationTrack = &quot;grid&quot;, link.largest.ontop = TRUE,
                      preAllocateTracks = list(
                        list(track.height = 0.02)
                      )
)

title(&quot;r &lt; |0.2|&quot;, cex.main = 2.5, line = -2)

circos.trackPlotRegion(track.index = 2, panel.fun = function(x, y) {
  xlim = get.cell.meta.data(&quot;xlim&quot;)
  ylim = get.cell.meta.data(&quot;ylim&quot;)
  sector.index = get.cell.meta.data(&quot;sector.index&quot;)
  circos.text(mean(xlim), mean(ylim), sector.index, col = &quot;black&quot;, cex = 0.6, 
              facing = &quot;inside&quot;, niceFacing = TRUE)
}, bg.border = NA)

# |0.2-0.3|
mat1 &lt;- ifelse(mat &gt; 0.3 | mat &lt; -0.3, 0, mat)
mat1 &lt;- ifelse(mat1 &lt; 0.2 &amp; mat1 &gt; -0.2, 0, mat1)

col2 &lt;- col_fun(mat1)
col2 &lt;- ifelse(col2 == &quot;#FFFFFFE6&quot;, NA, col2)

chordDiagram(mat, col = col2, grid.col = NA, grid.border = &quot;black&quot;, 
             annotationTrack = &quot;grid&quot;, link.largest.ontop = TRUE,
             preAllocateTracks = list(
               list(track.height = 0.02)
             )
)

title(&quot;r between |0.2 - 0.3|&quot;, cex.main = 2.5, line = -2)

circos.trackPlotRegion(track.index = 2, panel.fun = function(x, y) {
  xlim = get.cell.meta.data(&quot;xlim&quot;)
  ylim = get.cell.meta.data(&quot;ylim&quot;)
  sector.index = get.cell.meta.data(&quot;sector.index&quot;)
  circos.text(mean(xlim), mean(ylim), sector.index, col = &quot;black&quot;, cex = 0.6, 
              facing = &quot;inside&quot;, niceFacing = TRUE)
}, bg.border = NA)

# &gt; |0.3|
mat1 &lt;- ifelse(mat &gt; 0.3 | mat &lt; -0.3, mat, 0)

col2 &lt;- col_fun(mat1)
col2 &lt;- ifelse(col2 == &quot;#FFFFFFE6&quot;, NA, col2)

chordDiagram(mat, col = col2, grid.col = NA, grid.border = &quot;black&quot;, 
             annotationTrack = &quot;grid&quot;, link.largest.ontop = TRUE,
             preAllocateTracks = list(
               list(track.height = 0.02)
             )
)

title(&quot;r between |0.3 - 0.6|&quot;, cex.main = 2.5, line = -2)

circos.trackPlotRegion(track.index = 2, panel.fun = function(x, y) {
  xlim = get.cell.meta.data(&quot;xlim&quot;)
  ylim = get.cell.meta.data(&quot;ylim&quot;)
  sector.index = get.cell.meta.data(&quot;sector.index&quot;)
  circos.text(mean(xlim), mean(ylim), sector.index, col = &quot;black&quot;, cex = 0.6, 
              facing = &quot;inside&quot;, niceFacing = TRUE)
}, bg.border = NA)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-19-1.png" width="3000" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Heat map of the correlations</li>
</ol>
<pre class="r"><code>cors &lt;- function(df) { 
   # turn all three matrices (r, n, and P into a data frame)
   M &lt;- Hmisc::rcorr(as.matrix(df))
   # return the three data frames in a list return(Mdf)
   Mdf &lt;- map(M, ~data.frame(.x))
}

formatted_cors &lt;- function(df){
 cors(df) %&gt;%
 map(~rownames_to_column(.x, var=&quot;measure1&quot;)) %&gt;%
 map(~pivot_longer(.x, -measure1, &quot;measure2&quot;)) %&gt;% 
 bind_rows(.id = &quot;id&quot;) %&gt;%
 pivot_wider(names_from = id, values_from = value) %&gt;%
 mutate(sig_p = ifelse(P &lt; .05, T, F), p_if_sig = ifelse(P &lt;.05, P, NA), r_if_sig = ifelse(P &lt;.05, r, NA))
}

formatted_cors(gam_intercepts.tmp[-1]) %&gt;%
 ggplot(aes(x = measure1, y = measure2, fill = r, label=round(r_if_sig,2))) +
 geom_tile() +
 geom_text(aes(size = abs(r_if_sig)), show.legend = FALSE) +
 labs(x = NULL, y = NULL, fill = &quot;Pearson&#39;s Correlation&quot;) +
 # map a red, white and blue color scale to correspond to -1:1 sequential gradient
 scale_fill_gradient2(mid=&quot;#FBFEF9&quot;,low=&quot;#0C6291&quot;,high=&quot;#A63446&quot;, limits=c(-1,1)) +
 theme_classic() +
 # remove excess space on x and y axes
 scale_x_discrete(expand=c(0,0)) +
 scale_y_discrete(expand=c(0,0)) +
 # change global font to roboto
 theme(axis.text = element_text(size = 20, face = &quot;bold&quot;),
       axis.text.x = element_text(angle = 90, hjust = 1),
       legend.position = &quot;top&quot;,
       legend.key.width = unit(2, &quot;cm&quot;),
       legend.title = element_text(size = 20),
       legend.text = element_text(size = 20)) +
  guides(fill = guide_colourbar(title.position = &quot;top&quot;))</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-20-1.png" width="3000" /></p>
<ol start="5" style="list-style-type: decimal">
<li>Table of correlations with significance</li>
</ol>
<pre class="r"><code>formatted_cors(gam_intercepts.tmp[-1]) %&gt;%
  filter(r != 1) %&gt;%
  mutate(absolute_r = abs(r)) %&gt;%
  arrange(-absolute_r) %&gt;%
  group_by(r) %&gt;%
  mutate(id = row_number()) %&gt;%
  ungroup() %&gt;%
  filter(id == 1) %&gt;%
  datatable() %&gt;%
  formatRound(c(&quot;r&quot;, &quot;r_if_sig&quot;, &quot;P&quot;, &quot;p_if_sig&quot;, &quot;absolute_r&quot;), 3)</code></pre>
<div id="htmlwidget-b85bf888dc62471906a9" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b85bf888dc62471906a9">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190"],["F2_STRUT","F2_FLEECE","F2_START","F2_LOT","F1_LOT","F1_THOUGHT","F2_START","F2_STRUT","F2_DRESS","F1_FLEECE","F2_DRESS","F1_GOOSE","F1_FLEECE","F1_FLEECE","F1_DRESS","F1_LOT","F1_FLEECE","F1_START","F1_KIT","F2_DRESS","F2_START","F2_LOT","F2_GOOSE","F2_FLEECE","F1_KIT","F1_GOOSE","F1_DRESS","F1_START","F1_FLEECE","F1_KIT","F2_LOT","F2_KIT","F1_NURSE","F2_DRESS","F1_FLEECE","F1_STRUT","F1_FLEECE","F2_DRESS","F2_KIT","F2_KIT","F2_FLEECE","F1_DRESS","F2_DRESS","F1_KIT","F2_THOUGHT","F1_DRESS","F1_DRESS","F1_GOOSE","F1_FLEECE","F1_FLEECE","F2_LOT","F2_FLEECE","F2_DRESS","F1_KIT","F2_NURSE","F1_GOOSE","F2_GOOSE","F1_FLEECE","F2_KIT","F2_GOOSE","F2_LOT","F2_KIT","F1_GOOSE","F2_FLEECE","F1_GOOSE","F1_THOUGHT","F2_FLEECE","F1_NURSE","F2_STRUT","F1_LOT","F2_NURSE","F2_FLEECE","F2_FLEECE","F2_FLEECE","F1_FLEECE","F2_FLEECE","F1_NURSE","F1_START","F2_FLEECE","F2_FLEECE","F2_LOT","F1_DRESS","F1_LOT","F1_LOT","F2_KIT","F2_LOT","F1_GOOSE","F1_LOT","F2_KIT","F2_THOUGHT","F2_DRESS","F1_NURSE","F1_DRESS","F1_DRESS","F1_STRUT","F1_DRESS","F1_LOT","F1_KIT","F1_NURSE","F2_FLEECE","F1_FLEECE","F1_START","F1_TRAP","F2_NURSE","F1_FLEECE","F2_LOT","F1_NURSE","F1_DRESS","F2_NURSE","F1_DRESS","F1_GOOSE","F2_NURSE","F1_NURSE","F2_GOOSE","F2_NURSE","F1_KIT","F1_START","F2_NURSE","F2_LOT","F1_DRESS","F1_GOOSE","F2_START","F2_START","F1_DRESS","F1_DRESS","F1_KIT","F2_FLEECE","F1_NURSE","F1_GOOSE","F1_DRESS","F1_START","F1_DRESS","F1_FLEECE","F1_LOT","F1_START","F1_KIT","F2_NURSE","F1_GOOSE","F2_GOOSE","F2_GOOSE","F2_DRESS","F2_DRESS","F1_DRESS","F1_KIT","F1_STRUT","F2_KIT","F2_DRESS","F2_GOOSE","F2_DRESS","F2_GOOSE","F2_DRESS","F1_FLEECE","F2_KIT","F2_GOOSE","F1_STRUT","F2_GOOSE","F2_GOOSE","F1_KIT","F1_LOT","F1_FLEECE","F1_GOOSE","F2_START","F1_DRESS","F2_KIT","F1_STRUT","F2_GOOSE","F1_GOOSE","F2_FLEECE","F2_FLEECE","F2_GOOSE","F2_LOT","F1_KIT","F2_DRESS","F2_KIT","F2_DRESS","F1_KIT","F1_GOOSE","F1_FLEECE","F1_DRESS","F2_DRESS","F2_STRUT","F2_KIT","F1_LOT","F1_LOT","F1_THOUGHT","F1_NURSE","F2_DRESS","F1_GOOSE","F2_GOOSE","F2_DRESS"],["F2_THOUGHT","F2_NURSE","F2_THOUGHT","F2_THOUGHT","F1_START","F2_THOUGHT","F2_STRUT","F1_THOUGHT","F2_NURSE","F1_START","F2_GOOSE","F1_START","F1_NURSE","F1_THOUGHT","F1_GOOSE","F1_THOUGHT","F2_FLEECE","F1_STRUT","F2_KIT","F2_STRUT","F1_THOUGHT","F2_STRUT","F2_TRAP","F2_GOOSE","F1_NURSE","F1_TRAP","F1_TRAP","F1_THOUGHT","F2_NURSE","F1_TRAP","F1_THOUGHT","F2_TRAP","F2_NURSE","F2_FLEECE","F2_KIT","F1_TRAP","F1_GOOSE","F2_KIT","F2_STRUT","F1_TRAP","F1_KIT","F2_KIT","F2_START","F2_NURSE","F2_TRAP","F2_THOUGHT","F1_LOT","F1_NURSE","F1_LOT","F1_TRAP","F1_TRAP","F2_STRUT","F2_THOUGHT","F1_STRUT","F1_TRAP","F2_NURSE","F2_NURSE","F2_TRAP","F2_THOUGHT","F2_THOUGHT","F2_TRAP","F1_NURSE","F2_KIT","F1_GOOSE","F1_THOUGHT","F1_TRAP","F2_START","F1_STRUT","F2_TRAP","F1_NURSE","F2_TRAP","F1_TRAP","F2_TRAP","F2_LOT","F1_KIT","F1_NURSE","F1_THOUGHT","F1_TRAP","F1_START","F1_THOUGHT","F1_NURSE","F1_THOUGHT","F2_THOUGHT","F2_START","F1_STRUT","F2_NURSE","F1_LOT","F1_TRAP","F2_LOT","F1_TRAP","F2_TRAP","F2_STRUT","F2_LOT","F2_TRAP","F1_THOUGHT","F1_FLEECE","F2_STRUT","F1_THOUGHT","F2_THOUGHT","F2_THOUGHT","F2_START","F2_THOUGHT","F2_TRAP","F1_STRUT","F2_LOT","F2_START","F1_TRAP","F2_FLEECE","F2_THOUGHT","F2_STRUT","F2_START","F1_START","F1_START","F1_KIT","F2_STRUT","F2_START","F2_TRAP","F1_THOUGHT","F1_STRUT","F1_START","F2_GOOSE","F2_TRAP","F1_STRUT","F2_DRESS","F2_START","F2_THOUGHT","F1_STRUT","F2_TRAP","F1_STRUT","F1_KIT","F2_START","F2_NURSE","F1_STRUT","F2_LOT","F2_STRUT","F1_LOT","F2_START","F2_TRAP","F1_START","F2_LOT","F1_FLEECE","F1_THOUGHT","F1_STRUT","F2_STRUT","F2_TRAP","F1_START","F1_TRAP","F1_THOUGHT","F1_START","F2_KIT","F1_GOOSE","F2_THOUGHT","F2_NURSE","F1_NURSE","F2_STRUT","F2_START","F2_STRUT","F1_START","F2_NURSE","F2_STRUT","F2_STRUT","F1_TRAP","F2_GOOSE","F1_LOT","F2_THOUGHT","F1_STRUT","F2_THOUGHT","F2_KIT","F1_LOT","F1_LOT","F1_START","F2_LOT","F1_NURSE","F1_THOUGHT","F1_STRUT","F2_TRAP","F2_LOT","F2_GOOSE","F1_NURSE","F1_LOT","F1_TRAP","F2_START","F2_TRAP","F1_STRUT","F2_TRAP","F2_START","F1_KIT","F1_KIT","F1_TRAP","F2_LOT"],[-0.580479913751471,-0.576438367615427,-0.540609419890753,-0.50742345183015,-0.491640434021954,0.48942543663095,0.478065687744843,-0.412519319814382,-0.387648067844393,0.379269126785242,-0.372872750137774,0.365331618738711,-0.348204553324546,-0.345459779836512,-0.345089699218088,0.344036954972505,-0.340096635584723,-0.330600012322281,-0.330165618472217,-0.325193937949888,-0.317800867368352,0.316630751823917,-0.316537060432794,-0.31056863737882,-0.308388004681174,-0.302717254982891,0.296959763213368,-0.293844171849427,0.290935439292658,-0.283777488258082,-0.283651273205374,-0.282062108121432,-0.276141688312294,0.274187219313353,-0.273920202388461,-0.270954330660044,0.270684089318983,-0.268686043308723,0.26672554975339,0.26594155382204,-0.261902141065607,0.247915874646897,-0.247734359031633,0.241168191263381,0.239913449805023,-0.23956350706249,-0.236727606442321,-0.2358463541677,-0.23410723064925,-0.232337105370902,0.230577493243025,-0.22998407981982,0.229232442427302,0.225702881511463,-0.224346113221858,0.221027332788623,0.214935591568553,0.211331725014072,-0.210428455049288,-0.210297653916714,-0.210042710013554,0.206094434881475,-0.204334164967002,-0.203863000667144,-0.202968372462573,-0.202807934572034,-0.199651603787512,-0.198626251361231,-0.197599941138636,-0.196837101207949,-0.196566490398637,0.194201107473885,-0.191844614124049,0.191140845723862,0.189528692991921,0.187940327396672,-0.186686190594763,-0.181897538337167,-0.180234630952433,0.179091231071787,0.178158467343655,-0.177600111536543,0.175029302403378,-0.174144643406338,-0.173369379752346,-0.170261888518389,-0.167357939810456,-0.163666566868058,0.162871556083676,-0.157414467973265,0.157311065915783,0.156202510630392,0.15394948054031,-0.15320544557016,-0.152671395241397,-0.150577262605689,-0.148008377886788,-0.146412373991008,-0.146320132271828,0.144726629685811,0.141664106303742,-0.139947779302143,-0.137446132635439,0.137210344311722,-0.134788906365205,0.133888678585901,0.133031800926254,0.131084675076392,-0.129206553585048,0.124135460352218,0.123510485837624,0.123049749260234,0.121719363107564,0.121094996901765,0.119849786666898,0.119737598257922,0.115750234271154,-0.113592607497368,-0.108005709265382,-0.1046503101159,-0.104324996533344,-0.102534243833152,0.100320637686243,-0.0991514251312525,0.0972198886910256,-0.0967505394881595,-0.0943427380952044,-0.0925497271423781,0.0879823273634768,-0.0878753599818822,0.0853637952820863,-0.084673554638049,0.081211979541722,-0.0808882176639232,0.0777991756487228,-0.0772243788377939,0.0758747703878352,0.0757118325067109,0.0752079562510605,-0.0746612779249966,-0.0741103615157811,0.0681510802511974,-0.0677302259816717,0.0649226369873937,0.0620121796901523,-0.0607173550942958,0.0550081530349358,-0.0542584825146337,-0.0525650130938627,0.052327299066373,-0.051142296743497,-0.0490266859232344,-0.0489344180369647,0.0486979009864176,0.0481218676921912,0.0473654174668634,0.0469786941089356,-0.0463202375062465,-0.0438237797579857,0.0415777943365738,0.0400919324414647,0.0373791189372883,-0.0367696357948146,0.0335549767658825,-0.0330257384804587,-0.032688946511377,-0.0323584362846592,-0.030540147581163,0.0303068885398982,0.0290051391897743,-0.0287195546039375,-0.0249066676248671,0.0242077019390717,-0.023239342576852,0.0230679924228311,0.0210004390870278,-0.0198187056455556,0.0180272121499258,0.0172940435025468,0.0156507086865704,0.0153037734156168,-0.0145177838746217,-0.00819131260533067,0.00743982037989306,-0.0047198251188338,-0.00449358264593088,-0.00418931501570464,0.00362020145027982,0.00129797179289576,-0.0012262783056922],[481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481,481],[0,0,0,0,0,0,0,0,0,0,0,0,3.5527136788005e-15,6.21724893790088e-15,6.66133814775094e-15,8.21565038222616e-15,1.73194791841524e-14,9.9031893796564e-14,1.0724754417879e-13,2.60680366181987e-13,9.49462730659434e-13,1.16084919454806e-12,1.17994503057162e-12,3.24718030242366e-12,4.67448302288176e-12,1.18856036124271e-11,3.00341973513696e-11,4.91771068311664e-11,7.75097763749955e-11,2.32322605597801e-10,2.3679724847625e-10,3.00846014766876e-10,7.24275306396294e-10,9.63560786715334e-10,1.00170605144001e-09,1.53743817676855e-09,1.59822888257111e-09,2.1260782023802e-09,2.80675616082249e-09,3.13451287148325e-09,5.50613821204138e-09,3.60240954844215e-08,3.6886095955424e-08,8.56951121175342e-08,1.00397478997039e-07,1.04914080534257e-07,1.49492256795725e-07,1.66729867911997e-07,2.06537663860473e-07,2.56389430797199e-07,3.17324040821632e-07,3.40852440716688e-07,3.73071757486798e-07,5.67808238649548e-07,6.66097128565468e-07,9.8020315064673e-07,1.96147287123694e-06,2.92925549461032e-06,3.23550930891869e-06,3.28231834290094e-06,3.37542092276877e-06,5.18258143955563e-06,6.25776061369265e-06,6.57981439733391e-06,7.23531561241941e-06,7.35926904260609e-06,1.0251324451982e-05,1.14039674488087e-05,1.26805303204414e-05,1.37162415709824e-05,1.41026098066099e-05,1.79494799215085e-05,2.27594980968249e-05,2.44183285991184e-05,2.86608483079931e-05,3.35173420127344e-05,3.78921632711027e-05,6.00876004424045e-05,7.03292663957189e-05,7.83035485758532e-05,8.54322019179232e-05,8.99874064712591e-05,0.000114071090321577,0.000123675685663738,0.000132712432967308,0.000175535871848931,0.000226974570407101,0.000312775720440861,0.000334843758051262,0.000530207120315929,0.000534769407202651,0.000586025311780869,0.000704535579146182,0.000748310995353885,0.000781269749813074,0.000923896111646894,0.00113161306897291,0.00128151089562967,0.00129070923118313,0.00145951192447091,0.00184210647129168,0.00209473322036247,0.00251995238757985,0.00256384054911329,0.00305659971692407,0.00326074072488103,0.00346647436029723,0.00397842576898189,0.00453610774184643,0.00641127149764742,0.00668503460850145,0.0068935148135254,0.00752857064559986,0.00784425325379878,0.00850934576401441,0.00857166820235378,0.0110681330548248,0.0126714576166607,0.0178110913509653,0.0217047748770236,0.0221188937382872,0.024523283585411,0.0278046652873492,0.0296854090194274,0.0330312850696552,0.0338912742996769,0.0386090597652908,0.0424736783565418,0.0538149179327974,0.0541081422833556,0.0613840562189476,0.0635194800607506,0.0751703229415659,0.0763437060211971,0.0883038178082494,0.0906873006495625,0.0964865879101748,0.097206308852763,0.0994591096452568,0.101950033755547,0.104510092105341,0.135563761549303,0.13800041136796,0.155124963565587,0.174526612689879,0.183716831771344,0.228513855856337,0.234927843011225,0.249881683784172,0.252032674798723,0.262947161486939,0.28323211691616,0.284140223459305,0.286477004290961,0.29222219575615,0.29988324370474,0.30385095447967,0.310686237912846,0.337513095414491,0.362878861053423,0.38029671163814,0.413390892975666,0.421053440239339,0.462820695450201,0.469911183586804,0.474454336350079,0.478936033076629,0.503998989406791,0.50726338684073,0.525682306042293,0.529768268718339,0.585816006147151,0.596380559623094,0.611158040314609,0.613789656447763,0.645926917081366,0.664600859678268,0.693307162654182,0.705185889911314,0.73206890525514,0.73778782267775,0.750797354857948,0.857792368384272,0.870718654893551,0.917768452795823,0.921697223655909,0.926983913264555,0.93688078665489,0.977348955093019,0.978599777965895],[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false],[0,0,0,0,0,0,0,0,0,0,0,0,3.5527136788005e-15,6.21724893790088e-15,6.66133814775094e-15,8.21565038222616e-15,1.73194791841524e-14,9.9031893796564e-14,1.0724754417879e-13,2.60680366181987e-13,9.49462730659434e-13,1.16084919454806e-12,1.17994503057162e-12,3.24718030242366e-12,4.67448302288176e-12,1.18856036124271e-11,3.00341973513696e-11,4.91771068311664e-11,7.75097763749955e-11,2.32322605597801e-10,2.3679724847625e-10,3.00846014766876e-10,7.24275306396294e-10,9.63560786715334e-10,1.00170605144001e-09,1.53743817676855e-09,1.59822888257111e-09,2.1260782023802e-09,2.80675616082249e-09,3.13451287148325e-09,5.50613821204138e-09,3.60240954844215e-08,3.6886095955424e-08,8.56951121175342e-08,1.00397478997039e-07,1.04914080534257e-07,1.49492256795725e-07,1.66729867911997e-07,2.06537663860473e-07,2.56389430797199e-07,3.17324040821632e-07,3.40852440716688e-07,3.73071757486798e-07,5.67808238649548e-07,6.66097128565468e-07,9.8020315064673e-07,1.96147287123694e-06,2.92925549461032e-06,3.23550930891869e-06,3.28231834290094e-06,3.37542092276877e-06,5.18258143955563e-06,6.25776061369265e-06,6.57981439733391e-06,7.23531561241941e-06,7.35926904260609e-06,1.0251324451982e-05,1.14039674488087e-05,1.26805303204414e-05,1.37162415709824e-05,1.41026098066099e-05,1.79494799215085e-05,2.27594980968249e-05,2.44183285991184e-05,2.86608483079931e-05,3.35173420127344e-05,3.78921632711027e-05,6.00876004424045e-05,7.03292663957189e-05,7.83035485758532e-05,8.54322019179232e-05,8.99874064712591e-05,0.000114071090321577,0.000123675685663738,0.000132712432967308,0.000175535871848931,0.000226974570407101,0.000312775720440861,0.000334843758051262,0.000530207120315929,0.000534769407202651,0.000586025311780869,0.000704535579146182,0.000748310995353885,0.000781269749813074,0.000923896111646894,0.00113161306897291,0.00128151089562967,0.00129070923118313,0.00145951192447091,0.00184210647129168,0.00209473322036247,0.00251995238757985,0.00256384054911329,0.00305659971692407,0.00326074072488103,0.00346647436029723,0.00397842576898189,0.00453610774184643,0.00641127149764742,0.00668503460850145,0.0068935148135254,0.00752857064559986,0.00784425325379878,0.00850934576401441,0.00857166820235378,0.0110681330548248,0.0126714576166607,0.0178110913509653,0.0217047748770236,0.0221188937382872,0.024523283585411,0.0278046652873492,0.0296854090194274,0.0330312850696552,0.0338912742996769,0.0386090597652908,0.0424736783565418,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[-0.580479913751471,-0.576438367615427,-0.540609419890753,-0.50742345183015,-0.491640434021954,0.48942543663095,0.478065687744843,-0.412519319814382,-0.387648067844393,0.379269126785242,-0.372872750137774,0.365331618738711,-0.348204553324546,-0.345459779836512,-0.345089699218088,0.344036954972505,-0.340096635584723,-0.330600012322281,-0.330165618472217,-0.325193937949888,-0.317800867368352,0.316630751823917,-0.316537060432794,-0.31056863737882,-0.308388004681174,-0.302717254982891,0.296959763213368,-0.293844171849427,0.290935439292658,-0.283777488258082,-0.283651273205374,-0.282062108121432,-0.276141688312294,0.274187219313353,-0.273920202388461,-0.270954330660044,0.270684089318983,-0.268686043308723,0.26672554975339,0.26594155382204,-0.261902141065607,0.247915874646897,-0.247734359031633,0.241168191263381,0.239913449805023,-0.23956350706249,-0.236727606442321,-0.2358463541677,-0.23410723064925,-0.232337105370902,0.230577493243025,-0.22998407981982,0.229232442427302,0.225702881511463,-0.224346113221858,0.221027332788623,0.214935591568553,0.211331725014072,-0.210428455049288,-0.210297653916714,-0.210042710013554,0.206094434881475,-0.204334164967002,-0.203863000667144,-0.202968372462573,-0.202807934572034,-0.199651603787512,-0.198626251361231,-0.197599941138636,-0.196837101207949,-0.196566490398637,0.194201107473885,-0.191844614124049,0.191140845723862,0.189528692991921,0.187940327396672,-0.186686190594763,-0.181897538337167,-0.180234630952433,0.179091231071787,0.178158467343655,-0.177600111536543,0.175029302403378,-0.174144643406338,-0.173369379752346,-0.170261888518389,-0.167357939810456,-0.163666566868058,0.162871556083676,-0.157414467973265,0.157311065915783,0.156202510630392,0.15394948054031,-0.15320544557016,-0.152671395241397,-0.150577262605689,-0.148008377886788,-0.146412373991008,-0.146320132271828,0.144726629685811,0.141664106303742,-0.139947779302143,-0.137446132635439,0.137210344311722,-0.134788906365205,0.133888678585901,0.133031800926254,0.131084675076392,-0.129206553585048,0.124135460352218,0.123510485837624,0.123049749260234,0.121719363107564,0.121094996901765,0.119849786666898,0.119737598257922,0.115750234271154,-0.113592607497368,-0.108005709265382,-0.1046503101159,-0.104324996533344,-0.102534243833152,0.100320637686243,-0.0991514251312525,0.0972198886910256,-0.0967505394881595,-0.0943427380952044,-0.0925497271423781,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[0.580479913751471,0.576438367615427,0.540609419890753,0.50742345183015,0.491640434021954,0.48942543663095,0.478065687744843,0.412519319814382,0.387648067844393,0.379269126785242,0.372872750137774,0.365331618738711,0.348204553324546,0.345459779836512,0.345089699218088,0.344036954972505,0.340096635584723,0.330600012322281,0.330165618472217,0.325193937949888,0.317800867368352,0.316630751823917,0.316537060432794,0.31056863737882,0.308388004681174,0.302717254982891,0.296959763213368,0.293844171849427,0.290935439292658,0.283777488258082,0.283651273205374,0.282062108121432,0.276141688312294,0.274187219313353,0.273920202388461,0.270954330660044,0.270684089318983,0.268686043308723,0.26672554975339,0.26594155382204,0.261902141065607,0.247915874646897,0.247734359031633,0.241168191263381,0.239913449805023,0.23956350706249,0.236727606442321,0.2358463541677,0.23410723064925,0.232337105370902,0.230577493243025,0.22998407981982,0.229232442427302,0.225702881511463,0.224346113221858,0.221027332788623,0.214935591568553,0.211331725014072,0.210428455049288,0.210297653916714,0.210042710013554,0.206094434881475,0.204334164967002,0.203863000667144,0.202968372462573,0.202807934572034,0.199651603787512,0.198626251361231,0.197599941138636,0.196837101207949,0.196566490398637,0.194201107473885,0.191844614124049,0.191140845723862,0.189528692991921,0.187940327396672,0.186686190594763,0.181897538337167,0.180234630952433,0.179091231071787,0.178158467343655,0.177600111536543,0.175029302403378,0.174144643406338,0.173369379752346,0.170261888518389,0.167357939810456,0.163666566868058,0.162871556083676,0.157414467973265,0.157311065915783,0.156202510630392,0.15394948054031,0.15320544557016,0.152671395241397,0.150577262605689,0.148008377886788,0.146412373991008,0.146320132271828,0.144726629685811,0.141664106303742,0.139947779302143,0.137446132635439,0.137210344311722,0.134788906365205,0.133888678585901,0.133031800926254,0.131084675076392,0.129206553585048,0.124135460352218,0.123510485837624,0.123049749260234,0.121719363107564,0.121094996901765,0.119849786666898,0.119737598257922,0.115750234271154,0.113592607497368,0.108005709265382,0.1046503101159,0.104324996533344,0.102534243833152,0.100320637686243,0.0991514251312525,0.0972198886910256,0.0967505394881595,0.0943427380952044,0.0925497271423781,0.0879823273634768,0.0878753599818822,0.0853637952820863,0.084673554638049,0.081211979541722,0.0808882176639232,0.0777991756487228,0.0772243788377939,0.0758747703878352,0.0757118325067109,0.0752079562510605,0.0746612779249966,0.0741103615157811,0.0681510802511974,0.0677302259816717,0.0649226369873937,0.0620121796901523,0.0607173550942958,0.0550081530349358,0.0542584825146337,0.0525650130938627,0.052327299066373,0.051142296743497,0.0490266859232344,0.0489344180369647,0.0486979009864176,0.0481218676921912,0.0473654174668634,0.0469786941089356,0.0463202375062465,0.0438237797579857,0.0415777943365738,0.0400919324414647,0.0373791189372883,0.0367696357948146,0.0335549767658825,0.0330257384804587,0.032688946511377,0.0323584362846592,0.030540147581163,0.0303068885398982,0.0290051391897743,0.0287195546039375,0.0249066676248671,0.0242077019390717,0.023239342576852,0.0230679924228311,0.0210004390870278,0.0198187056455556,0.0180272121499258,0.0172940435025468,0.0156507086865704,0.0153037734156168,0.0145177838746217,0.00819131260533067,0.00743982037989306,0.0047198251188338,0.00449358264593088,0.00418931501570464,0.00362020145027982,0.00129797179289576,0.0012262783056922],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>measure1<\/th>\n      <th>measure2<\/th>\n      <th>r<\/th>\n      <th>n<\/th>\n      <th>P<\/th>\n      <th>sig_p<\/th>\n      <th>p_if_sig<\/th>\n      <th>r_if_sig<\/th>\n      <th>absolute_r<\/th>\n      <th>id<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"targets":[3,8,5,7,9],"render":"function(data, type, row, meta) { return DTWidget.formatRound(data, 3, 3, \",\", \".\"); }"},{"className":"dt-right","targets":[3,4,5,7,8,9,10]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render"],"jsHooks":[]}</script>
<ol start="6" style="list-style-type: decimal">
<li>Permutation of correlations</li>
</ol>
<p>This is the plot we include in the manuscript.</p>
<p>We show the distribution of correlation co-efficients across the intercepts (plotted in red), highlighting that there are a range of positive/negative correlations, some stronger than others.</p>
<p>We permute the correlations 100 times (which is a process of shuffling the values around to remove any underlying structure). This distribution is plotted in blue and shows that the random correlations are generally between |1.5|. Thus, the correlations in the ONZE dataset are likely to represent actual co-variation between the variables.</p>
<pre class="r"><code>correlations_permuted &lt;- gam_intercepts.tmp[-1] %&gt;%
  formatted_cors(.) %&gt;%
  mutate(intercepts = &quot;ONZE&quot;)

for (i in 1:100) {
  permuted &lt;- formatted_cors(apply(gam_intercepts.tmp[-1], 2L, sample)) %&gt;% mutate(intercepts = i)
  
  correlations_permuted &lt;&lt;- rbind(correlations_permuted, permuted)
}

correlations_permuted &lt;- correlations_permuted %&gt;%
  mutate(Data = ifelse(intercepts == &quot;ONZE&quot;, &quot;ONZE&quot;, &quot;Permuted&quot;)) %&gt;%
  filter(r &lt; 1)

correlations_permuted_plot &lt;- ggplot(correlations_permuted, aes(x = r, y = ..density.., colour = Data, group = intercepts)) +
  # geom_histogram(alpha = 0.1, bins = 481) +
  geom_line(aes(x = r, y = P),size = 0) +
  geom_density(aes(colour = Data), adjust = 0.2, size = 0.01, alpha = 1, show.legend = FALSE) +
  geom_density(data = correlations_permuted %&gt;% filter(intercepts == &quot;ONZE&quot;), adjust = 0.2, colour = &quot;#F8766D&quot;, size = 1, show.legend = FALSE) +
  scale_x_continuous(limits = c(-0.6, 0.6)) +
  xlab(&quot;Pearson&#39;s correlation co-efficient (r)&quot;) +
  # facet_grid(~intercepts) +
  theme_bw() +
  theme(legend.position = &quot;top&quot;,
        legend.title = element_blank(),
        axis.title = element_text(size = 14, face = &quot;bold&quot;),
        legend.text = element_text(size = 14, face = &quot;bold&quot;)) +
  guides(colour = guide_legend(override.aes = list(size=1)))

positive_correlations &lt;- ggplot(correlations_permuted, aes(x = r, y = ..density.., colour = Data, group = intercepts)) +
  geom_density(size = 0) +
  annotate(&quot;rect&quot;, xmin = -1, xmax = 0.57, ymin = 2, ymax = 10, fill = &quot;cornsilk&quot;, colour = &quot;black&quot;) +
  annotate(&quot;text&quot;, label = &quot;Top 5 positive correlations:&quot;, fontface = 2, x = -0.95, y = 9.5, hjust = 0, vjust = 1, size = 4) +
  annotate(&quot;text&quot;, label = &quot;F1 THOUGHT ~ F2 THOUGHT (r = .49)\nF2 START ~ F2 STRUT (r = .48)\nF1 FLEECE ~ F1 START (r = .38)\nF1 GOOSE ~ F1 START (r = 0.37)\nF1 LOT ~ F1 THOUGHT (r = 0.34)&quot;, x = -0.95, y = 7.5, hjust = 0, vjust = 1, size = 4) +
  theme_nothing()

negative_correlations &lt;- ggplot(correlations_permuted, aes(x = r, y = ..density.., colour = Data, group = intercepts)) +
  geom_density(size = 0) +
  annotate(&quot;rect&quot;, xmin = -1, xmax = 0.57, ymin = 2, ymax = 10, fill = &quot;cornsilk&quot;, colour = &quot;black&quot;) +
  annotate(&quot;text&quot;, label = &quot;Top 5 negative correlations:&quot;, fontface = 2, x = -0.95, y = 9.5, hjust = 0, vjust = 1, size = 4) +
  annotate(&quot;text&quot;, label = &quot;F2 STRUT ~ F2 THOUGHT (r = -.58)\nF2 FLEECE ~ F2 NURSE (r = -.58)\nF2 START ~ F2 THOUGHT (r = -.54)\nF2 LOT ~ F2 THOUGHT (r = -.51)\nF1 LOT ~ F1 START (r = -.49)&quot;, x = -0.95, y = 7.5, hjust = 0, vjust = 1, size = 4) +
  theme_nothing()

correlations_permuted_plot1 &lt;- plot_grid(correlations_permuted_plot, plot_grid(negative_correlations, positive_correlations, nrow = 1, ncol = 2), rel_heights = c(0.8, 0.4),  nrow = 2, ncol = 1)

correlations_permuted_plot1</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-22-1.png" width="2100" /></p>
<pre class="r"><code>ggsave(plot = correlations_permuted_plot1, filename = &quot;Figures/correlations_permuted_plot.png&quot;, width = 7, height = 7, dpi = 400)</code></pre>
<!-- ```{r eval=FALSE} -->
<!-- gam.F1 <- bam(F1_lobanov_2.0 ~ -->
<!--                   s(participant_year_of_birth, k=10, bs="ad", by=Gender) + -->
<!--                   s(participant_year_of_birth, k=10, bs="ad") + -->
<!--                   Gender + -->
<!--                   s(Speech_rate) + -->
<!--                   s(Speaker, bs="re") + -->
<!--                   s(Word, bs="re"), -->
<!--                 data=vowels_all %>% filter(Vowel == "NURSE"), -->
<!--                 discrete=T, nthreads=2) -->
<!-- deriv(gam.F1) -->
<!-- library(gratia) -->
<!-- fderiv(gam.F1, term = "participant_year_of_birth") -->
<!-- my_prediction <- function(data,eps = EPS,unconditional = UNCONDITIONAL){ -->
<!--   # mod = gam(EVI ~ s(Day), data = data) -->
<!--   days <- tibble(vowels_all %>% select(participant_year_of_birth) %>% distinct) -->
<!--   fd <- fderiv(gam.F1, eps = EPS, unconditional = UNCONDITIONAL) -->
<!--   tibble(Day = days$Day,pred = as.numeric(fd$deriv$participant_year_of_birth$deriv)) -->
<!-- } -->
<!-- UNCONDITIONAL <- FALSE # unconditional or conditional on estimating smooth params? -->
<!-- EPS <- 1e-07           # finite difference -->
<!-- df_model <- vowels_all %>%  -->
<!--   nest(-c(,Year)) %>%  -->
<!--   mutate(pred = map(data,my_prediction)) -->
<!-- df_model %>%  -->
<!--   unnest(pred) %>%  -->
<!--   ggplot(aes(Day,pred,col = as.factor(Year))) + geom_line() + -->
<!--   theme_bw() + -->
<!--   facet_wrap(c('NestID')) -->
<!-- ``` -->
</div>
</div>
<div id="principal-components-analysis-pca" class="section level1">
<h1>Principal Components Analysis (PCA)</h1>
<p>In the following section we will run a PCA on the <code>gam_intercepts.tmp</code> data frame, i.e. the by-speaker intercepts from each of the 20 GAMMs.</p>
<p>PCA offers a neat analysis solution to assessing whether there is underlying structure in the dataset, by highlighting which variables co-vary together - these are called principal components (PCs). Moreover, it also allows us to explore the data at the by-speaker level, providing us with insights into <em>who</em> is on the margins of these PCs.</p>
<div id="running-the-pca" class="section level2">
<h2>Running the PCA</h2>
<pre class="r"><code>#run the PCA on the intercepts data frame, note the intercepts are in columns 2:21 as column 1 is the speaker name
intercepts.pca &lt;- princomp(gam_intercepts.tmp[, 2:ncol(gam_intercepts.tmp)],cor=TRUE)

#print a summary of the PCA, this will give the variance explained by each PC
summary(intercepts.pca)</code></pre>
<pre><code>## Importance of components:
##                           Comp.1    Comp.2    Comp.3     Comp.4     Comp.5
## Standard deviation     1.8568236 1.7761654 1.4218609 1.27801065 1.11351321
## Proportion of Variance 0.1723897 0.1577382 0.1010844 0.08166556 0.06199558
## Cumulative Proportion  0.1723897 0.3301279 0.4312123 0.51287786 0.57487344
##                           Comp.6     Comp.7     Comp.8     Comp.9    Comp.10
## Standard deviation     1.0424970 1.00352469 0.95546926 0.90696297 0.87916274
## Proportion of Variance 0.0543400 0.05035309 0.04564608 0.04112909 0.03864636
## Cumulative Proportion  0.6292134 0.67956653 0.72521261 0.76634170 0.80498805
##                           Comp.11    Comp.12    Comp.13    Comp.14    Comp.15
## Standard deviation     0.80953378 0.77331213 0.73748412 0.72788478 0.67193061
## Proportion of Variance 0.03276725 0.02990058 0.02719414 0.02649081 0.02257454
## Cumulative Proportion  0.83775530 0.86765588 0.89485002 0.92134084 0.94391538
##                           Comp.16    Comp.17    Comp.18     Comp.19    Comp.20
## Standard deviation     0.61321385 0.55845231 0.47851298 0.372962769 0.25635209
## Proportion of Variance 0.01880156 0.01559345 0.01144873 0.006955061 0.00328582
## Cumulative Proportion  0.96271694 0.97831039 0.98975912 0.996714180 1.00000000</code></pre>
<pre class="r"><code>#view eigen values, this will visualise the variance explained by each PC
fviz_eig(intercepts.pca, addlabels = TRUE)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-23-1.png" width="2100" /></p>
<pre class="r"><code>#create objects containing the loadings for each of the 3 main PCs
PC1_loadings &lt;- intercepts.pca$loadings[,1]
PC2_loadings &lt;- intercepts.pca$loadings[,2]
PC3_loadings &lt;- intercepts.pca$loadings[,3]</code></pre>
<p>We can also permute the data again and run the PCA to compare how the ONZE intercepts compare to permuted intercepts. We can see a clear difference between the two data sets. The 4th PC from the ONZE intercepts does appear to explain more variance than the permuted intercepts, but we chose to focus on the first 3 PCs as each explains &gt; 10% of the variance in the analysis (dashed horizontal line), which is commonly taken as a threshold for meaningfully interpretable PCs.</p>
<pre class="r"><code>PCA_variance_permuted &lt;- get_eigenvalue(intercepts.pca)[1:10, 2] %&gt;%
  data.frame() %&gt;%
  rename(Variance = 1) %&gt;%
  mutate(PC = paste0(1:10),
         Permutation = &quot;ONZE&quot;,
         Data = &quot;ONZE&quot;) %&gt;%
  select(PC, Variance, Permutation, Data)

for (i in 1:100) {
  permuted &lt;- apply(gam_intercepts.tmp[-1], 2L, sample)
  
  permuted_pca &lt;- princomp(permuted, cor = TRUE)
  
  PCA_variance &lt;- get_eigenvalue(permuted_pca)[1:10, 2] %&gt;%
  data.frame() %&gt;%
  rename(Variance = 1) %&gt;%
  mutate(PC = paste0(1:10),
         Permutation = i,
         Data = &quot;Permuted&quot;) %&gt;%
  select(PC, Variance, Permutation, Data)
  
  PCA_variance_permuted &lt;&lt;- rbind(PCA_variance_permuted, PCA_variance)
}

PCA_variance_permuted_plot &lt;- PCA_variance_permuted %&gt;%
  group_by(Data, PC) %&gt;%
  summarise(mean_variance = mean(Variance),
            sd = sd(Variance)) %&gt;%
  arrange(PC) %&gt;%
  mutate(PC = factor(PC, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)),
         sd = ifelse(is.na(sd), 0, sd)) %&gt;%
  ggplot(aes(x = PC, y = mean_variance, colour = Data, group = Data)) +
  geom_point(data = PCA_variance_permuted %&gt;%
  mutate(PC = factor(PC, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))), aes(x = PC, y = Variance), size = 0.1, alpha = 0.1) +
  geom_errorbar(aes(ymin=mean_variance-sd, ymax=mean_variance+sd), width=.1, position=position_dodge(0.1)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 10, colour = &quot;black&quot;, linetype = &quot;dashed&quot;) +
  # geom_label_repel(aes(label = paste0(round(mean_variance, 2), &quot;%&quot;)), show.legend = FALSE) +
  scale_y_continuous(limits = c(0, 20)) +
  facet_grid(~Data) +
  theme_bw()+
  theme(legend.position = &quot;none&quot;)

PCA_variance_permuted_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-24-1.png" width="2100" /></p>
<pre class="r"><code>ggsave(plot = PCA_variance_permuted_plot, filename = &quot;Figures/PCA_scree.png&quot;, width = 7, height = 5, dpi = 300)</code></pre>
<pre class="r"><code>#store these in a data frame for ease of plotting
PC1_loadings &lt;- PC1_loadings %&gt;%
  as.data.frame() %&gt;%#convert to a data frame
  dplyr::rename(Loading = 1) %&gt;% #rename the variable
  mutate(variable = row.names(.), #add variable to identify which intercepts are representing each row
         highlight = ifelse(Loading &gt; 0.225 | Loading &lt; -0.225 , &quot;black&quot;, &quot;gray&quot;), #for plotting reasons, we want to highlight the variables that contribute the most to the PC, so if the loading is &gt; |0.2| it will plotted in black, if not it will be gray)
         PC1_loadings_abs = abs(Loading), #make the loadings absolute so they are comparable when plotting
         direction = ifelse(Loading &lt; 0, &quot;red&quot;, &quot;black&quot;), #define which direction the loading sign was, i.e. red if negative, black if positive
         PC = &quot;PC1&quot;,
         Vowel = substr(variable, 4, 10)) %&gt;% #add variable to identify which PC the data is from
  arrange(PC1_loadings_abs) #order the variables based on absolute loading value

#repeat this process for PC2
PC2_loadings &lt;- PC2_loadings %&gt;%
  as.data.frame() %&gt;%
  dplyr::rename(Loading = 1) %&gt;%
  mutate(variable = row.names(.),
         highlight = ifelse(Loading &gt; 0.225 | Loading &lt; -0.225 , &quot;black&quot;, &quot;gray&quot;),
         PC2_loadings_abs = abs(Loading),
         direction = ifelse(Loading &lt; 0, &quot;red&quot;, &quot;black&quot;),
         PC = &quot;PC2&quot;,
         Vowel = substr(variable, 4, 10)) %&gt;%
  arrange(PC2_loadings_abs)

#repeat this process for PC3
PC3_loadings &lt;- PC3_loadings %&gt;%
  as.data.frame() %&gt;%
  dplyr::rename(Loading = 1) %&gt;%
  mutate(variable = row.names(.),
         highlight = ifelse(Loading &gt; 0.225 | Loading &lt; -0.225 , &quot;black&quot;, &quot;gray&quot;),
         PC3_loadings_abs = abs(Loading),
         direction = ifelse(Loading &lt; 0, &quot;red&quot;, &quot;black&quot;),
         PC = &quot;PC3&quot;,
         Vowel = substr(variable, 4, 10)) %&gt;%
  arrange(PC3_loadings_abs)</code></pre>
</div>
<div id="pcs-by-contribution" class="section level2">
<h2>PCs by Contribution</h2>
<p>To visualise how the different variables contribute to the formation of the PC, we can look at their contribution values. These are simply the variable loading squared and then multiplied by 100, giving a value that is interpretable by means of a percent.</p>
<p>The red dashed line in these plots divides the variables on the basis of cumulative variance explained, whereby those variables to the right of the line collectively account for &gt; 50% of the total variance. Thus, our (least arbitrary) way to define a cut-off point for ‘importance’ of the variables is to focus on those contributing &gt; 50%.</p>
The colour and sign of the dots in these plots is defined by the direction of the loadings in the PCA, i.e.
<p style="color:red">
-
</p>
<p>= negative and + = positive.</p>
<p>First we will wrangle the data from the PCA.</p>
<pre class="r"><code>PC_loadings_contrib &lt;- intercepts.pca$loadings[,1:3] %&gt;% #get the loadings for PC1, PC2 and PC3
  as.data.frame() %&gt;%
  cbind(get_pca(intercepts.pca, &quot;var&quot;)$contrib[,1:3]) %&gt;% #get the contributions
  dplyr::rename(Loading.PC1 = Comp.1,
         Loading.PC2 = Comp.2,
         Loading.PC3 = Comp.3,
         Contribution.PC1 = Dim.1,
         Contribution.PC2 = Dim.2,
         Contribution.PC3 = Dim.3) %&gt;%
  mutate(Variable = row.names(.),
         Vowel = substr(Variable, 4, nchar(Variable))) %&gt;%
  dplyr::select(Variable, Vowel, Loading.PC1:Contribution.PC3) %&gt;%
  pivot_longer(Loading.PC1:Loading.PC3, names_to = &quot;PC&quot;, values_to = &quot;Loading&quot;) %&gt;%
  arrange(Vowel, Variable, PC) %&gt;%
  mutate(direction = ifelse(Loading &lt; 0, &quot;red&quot;, &quot;black&quot;)) #define direction of the loadings</code></pre>
<p><strong>PC1</strong></p>
<pre class="r"><code>PC1_contrib &lt;- PC_loadings_contrib %&gt;%
  select(-Contribution.PC2, -Contribution.PC3) %&gt;%
  filter(PC == &quot;Loading.PC1&quot;) %&gt;%
  arrange(Contribution.PC1) %&gt;%
  mutate(Loading_abs = abs(Loading),
         cumsum_PC1 = round(cumsum(Contribution.PC1), 4),
         highlight = ifelse(cumsum_PC1 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC1 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))
  
PC1_contrib_plot &lt;- ggplot(PC1_contrib, aes(x=reorder(Variable, Contribution.PC1), y=Contribution.PC1)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC1_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC1_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) + 
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC1 contribution (%)&quot;) +
  geom_vline(xintercept = 16.5, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC1_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC1_contrib_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-27-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC1_contrib_plot, filename = &quot;Figures/PC1_contrib_plot.png&quot;, width = 8, height = 5, dpi = 300)</code></pre>
<p><strong>PC2</strong></p>
<pre class="r"><code>PC2_contrib &lt;- PC_loadings_contrib %&gt;%
  select(-Contribution.PC1, -Contribution.PC3) %&gt;%
  filter(PC == &quot;Loading.PC2&quot;) %&gt;%
  arrange(Contribution.PC2) %&gt;%
  mutate(Loading_abs = abs(Loading),
         cumsum_PC2 = round(cumsum(Contribution.PC2), 4),
         highlight = ifelse(cumsum_PC2 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC2 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))
  
PC2_contrib_plot &lt;- ggplot(PC2_contrib, aes(x=reorder(Variable, Contribution.PC2), y=Contribution.PC2)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC2_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC2_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) + #add the dots to the plot, with the colour
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC2 contribution (%)&quot;) +
  geom_vline(xintercept = 14.5, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC2_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC2_contrib_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-28-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC2_contrib_plot, filename = &quot;Figures/PC2_contrib_plot.png&quot;, width = 8, height = 5, dpi = 300)</code></pre>
<p><strong>PC3</strong></p>
<pre class="r"><code>PC3_contrib &lt;- PC_loadings_contrib %&gt;%
  select(-Contribution.PC1, -Contribution.PC2) %&gt;%
  filter(PC == &quot;Loading.PC3&quot;) %&gt;%
  arrange(Contribution.PC3) %&gt;%
  mutate(Loading_abs = abs(Loading),
         cumsum_PC3 = round(cumsum(Contribution.PC3), 4),
         highlight = ifelse(cumsum_PC3 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC3 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))
  
PC3_contrib_plot &lt;- ggplot(PC3_contrib, aes(x=reorder(Variable, Contribution.PC3), y=Contribution.PC3)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC3_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC3_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) + 
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC3 contribution (%)&quot;) +
  geom_vline(xintercept = 16.5, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC3_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC3_contrib_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-29-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC3_contrib_plot, filename = &quot;Figures/PC3_contrib_plot.png&quot;, width = 8, height = 5, dpi = 300)</code></pre>
</div>
</div>
<div id="visualisation-in-vowel-space" class="section level1">
<h1>Visualisation in vowel space</h1>
<p>In order to understand how these variables are co-varying together, we can re-interpret the dot plots in terms of F1/F2 vowel space. This will allow us to explore our theoretically motivated interpretation that these PCs represent changes in F1/F2 over time, thus demonstrating that the PCs may be representing ‘leaders’ and ‘laggers’ of sound change.</p>
<ol style="list-style-type: decimal">
<li><p>We will plot how the vowel space in New Zealand English has changed over the course of the dataset (defined by year of birth), based on the GAMM modelling performed in earlier models.</p></li>
<li><p>We then visualise how the vowel spaces of the speakers in PC1, PC2 and PC3 also change (defined by the PCA scores), this interpretation will be driven by the weighting of the variable loadings on each PC (as shown in the dot plots). This will done in 3 different ways:</p></li>
</ol>
<ul>
<li><p>GAM smooths</p></li>
<li><p>Vowel plots</p></li>
<li><p>Animations</p></li>
</ul>
<p>In order to generate these plots, we have to run more GAMMs predicting either F1 or F2 (normalised), by the PCA scores, this will provide us with predicted model values, that show the trajectories based on the PCA scores (i.e. going from negative to positive values).</p>
<p>Note, the direction of the PCA scores (for PC1, PC2 and PC3) have been reversed in the figures, i.e. negative scores are switched to positive and vice versa. This is purely for visualisation purposes as it helps the interpretation in terms of change over time. This does not affect any underlying importance of the actual scores, the direction (+/-) is arbitrary in PCA and remains the same as long as all values are switched, which they have been.</p>
</div>
<div id="sound-change" class="section level1">
<h1>Sound change</h1>
<div id="visualisation-by-gam-smooth" class="section level2">
<h2>Visualisation by GAM smooth</h2>
<p>Plotting change in normalised (Lobanov 2.0) F1 (red lines) and F2 (blue lines)</p>
<ul>
<li><p>x axis = year of birth</p></li>
<li><p>y axis = normalised F1/F2</p></li>
<li><p>smoothed lines = GAM fit</p></li>
</ul>
<p><strong>year of birth</strong></p>
<p>Load in the models and get the predicted values.</p>
<p>These steps are pre-run (they are big objects in R), but the resulting data can be found in the <code>Data &gt; Models</code> folder, saved as <code>mod_pred_yob_values.rds</code> and <code>mod_pred_yobgender_values.rds</code></p>
<pre class="r"><code>mod_pred_yob_values &lt;-  readRDS(&quot;Data/Models/mod_pred_yob_values.rds&quot;)</code></pre>
<pre class="r"><code>#make a long version of the intercepts
gam_intercepts.tmp_long &lt;- gam_intercepts.tmp %&gt;%
  pivot_longer(F1_DRESS:F2_TRAP, names_to = &quot;Vowel_formant&quot;, values_to = &quot;Intercept&quot;) %&gt;%
  mutate(Formant = substr(Vowel_formant, 1, 2),
         Vowel = substr(Vowel_formant, 4, max(nchar(Vowel_formant)))) %&gt;%
  left_join(vowels_all %&gt;%
  select(Speaker, participant_year_of_birth, Gender) %&gt;% distinct()) %&gt;%
  left_join(mod_pred_yob_values %&gt;% select(participant_year_of_birth, Vowel, Formant, fit, ll, ul))

#plot the gam smooths predicting F1/F2 per vowel and add the speaker intercepts values
sound_change_plot_smooth &lt;- mod_pred_yob_values %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = participant_year_of_birth, y = fit, colour = Formant, fill = Formant)) +
  geom_point(data = gam_intercepts.tmp_long %&gt;% mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), aes(x = participant_year_of_birth, y = fit + Intercept), size = 0.25, alpha = 0.1) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.2, colour = NA) +
  scale_x_continuous(breaks = c(1900, 1950)) +
  xlab(&quot;Year of birth&quot;) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

sound_change_plot_smooth</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-32-1.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = sound_change_plot_smooth, filename = &quot;Figures/sound_change_gam.png&quot;, width = 12, height = 5, dpi = 600)</code></pre>
<p><strong>year of birth and gender</strong></p>
<pre class="r"><code>mod_pred_yobgender_values &lt;- readRDS(&quot;Data/Models/mod_pred_yobgender_values.rds&quot;)</code></pre>
<pre class="r"><code>#plot the gam smooths predicting F1/F2 per vowel and add the per speaker mean values with F or M as the text
sound_change_plot_smooth_gender &lt;- mod_pred_yobgender_values %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = participant_year_of_birth, y = fit, colour = Formant, linetype = Gender, label = Gender, fill = Formant)) +
  geom_text(data = gam_intercepts.tmp_long %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), aes(x = participant_year_of_birth, y = fit + Intercept), size = 1, alpha = 0.5) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.2, colour = NA) +
  scale_x_continuous(breaks = c(1900, 1950)) +
  xlab(&quot;Year of birth&quot;) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;top&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

sound_change_plot_smooth_gender</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-35-1.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = sound_change_plot_smooth_gender, filename = &quot;Figures/sound_change_gam_gender.png&quot;, width = 10, height = 5, dpi = 600)</code></pre>
<div id="visualisation-in-f1f2-space" class="section level3">
<h3>Visualisation in F1/F2 space</h3>
<p>We can convert the data from the above plot in (Lobanov 2.0 normalised) F1/F2 space, to see the changes in a more conventional vowel space plot</p>
<ul>
<li><p>x axis = F2</p></li>
<li><p>y axis = F1</p></li>
<li><p>colours = lexical set of vowel</p></li>
<li><p>lines = trajectory of the F1/F2 in terms of year of birth (1857 - 1988)</p></li>
<li><p>vowel labels = start point of the vowel trajectory (oldest year of birth: 1857)</p></li>
<li><p>arrows = end point of the trajectory (youngest year of birth: 1988)</p></li>
</ul>
<pre class="r"><code>#transform data so there are separate columns for F1 and F2
sound_change_plot_data &lt;- mod_pred_yob_values %&gt;%
  select(participant_year_of_birth, fit, Vowel, Formant) %&gt;%
  pivot_wider(names_from = Formant, values_from = fit) #transform the data to wide format so there are separate F1 and F2 variables

#make data frame to plot starting point, this will give the vowel labels based on the smallest year of birth coordinates
sound_change_labels1 &lt;- sound_change_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  filter(participant_year_of_birth == min(participant_year_of_birth))

#make data frame to plot end point, this will give the arrow at the end of the paths based on the largest year of birth coordinates
sound_change_labels2 &lt;- sound_change_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  top_n(wt = participant_year_of_birth, n = 2)

#plot
sound_change_plot &lt;- sound_change_plot_data %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, alpha = participant_year_of_birth, group = Vowel)) +
  #add year of birth change trajectories
  geom_path(size = 0.5, show.legend = FALSE) +
  #add end points (this gives the arrows)
  geom_path(data = sound_change_labels2, aes(x = F2, y = F1, colour = Vowel, group = Vowel),
            arrow = arrow(ends = &quot;last&quot;, type = &quot;closed&quot;, length = unit(0.2, &quot;cm&quot;)),
            inherit.aes = FALSE, show.legend = FALSE) +
  #plot the vowel labels
  geom_text(data = sound_change_labels1, aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel), inherit.aes = FALSE, show.legend = FALSE) +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #scale the size so the path is not too wide
  scale_size_continuous(range = c(0.2,1)) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #add a title
  # labs(title = &quot;A) Change over time\n     &quot;) +
  #set the theme
  theme_bw() +
  #make title bold
  theme(plot.title = element_text(face=&quot;bold&quot;))

sound_change_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-36-1.png" width="1200" /></p>
<pre class="r"><code>ggsave(plot = sound_change_plot, filename = &quot;Figures/sound_change_static.png&quot;, width = 5.5, height = 5.5, dpi = 300)</code></pre>
</div>
<div id="visualisation-by-animation" class="section level3">
<h3>Visualisation by animation</h3>
<p>We can also recreate the above plot in 3 dimensional space, where the trajectories are animated.</p>
<ul>
<li><p>x axis = F2</p></li>
<li><p>y axis = F1</p></li>
<li><p>colours = lexical set of vowel</p></li>
<li><p>movement = trajectory of the F1/F2 in terms of year of birth (1857 - 1988)</p></li>
<li><p>trails = the previous positions of the vowels</p></li>
</ul>
<pre class="r"><code>sound_change_plot_animation &lt;- sound_change_plot_data %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel)) +
  geom_text(aes(fontface = 2), size = 5, show.legend = FALSE) +
  # geom_point() +
  geom_path() +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #add a title
  labs(caption = &#39;Year of birth: {round(frame_along, 0)}&#39;) +
  #set the theme
  theme_bw() +
  #make text more visible
  theme(axis.title = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.x = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;, angle = 270),
        axis.ticks = element_blank(),
        plot.caption = element_text(size = 30, hjust = 0),
        legend.position = &quot;none&quot;) +
  #set the variable for the animation transition i.e. the time dimension
  transition_reveal(participant_year_of_birth) +
  #add in a trail to see the path
  # shadow_trail(max_frames = 100, alpha = 0.1) +
  ease_aes(&#39;linear&#39;)

sound_change_plot_animation &lt;- animate(sound_change_plot_animation, nframes = 200, fps = 5, rewind = FALSE, start_pause = 10, end_pause = 10, duration = 20)

# animate(sound_change_plot_animation, nframes = 200, fps = 5, rewind = FALSE, start_pause = 10, end_pause = 10, duration = 20, height = 800, width =800)

anim_save(sound_change_plot_animation, filename = &quot;Figures/sound_change_animation.gif&quot;)

sound_change_plot_animation</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-37-1.gif" /><!-- --></p>
</div>
</div>
</div>
<div id="pc-scores" class="section level1">
<h1>PC scores</h1>
<p>To understand how the PCs vary in terms of the co-variation between the vowel-formants, we want to inspect the PC scores. Within each of the PCs, there will be speakers who typify the co-variation seen in the dot plots. This is shown through the PC scores, with each speaker assigned a different score for each of the PCs. These scores can be interpreted in a similar way to the loadings - the larger your score (either +/-), the more that speaker contributes to the co-variation.</p>
<p>We can explore the PC scores to:</p>
<ul>
<li><p>Assess the relationship between the scores and the intercepts</p></li>
<li><p>Visualise the vowel spaces of speakers with +/- scores</p></li>
<li><p>Understand how these speakers differ in terms of F1~F2 space for the vowel-formants contributing most to each PC</p></li>
<li><p>Inspect the relationship between the PC scores and directions of sound change</p></li>
<li><p>Test if the PC scores are independent of the socio-demographic variables included in the sound change GAMMs</p></li>
</ul>
<p>Each speaker has a PC score within each of the PCs (which can be found in <code>intercepts.pca$scores</code>), thus we need to extract this information and combine it with the speaker’s social information (which can be found in <code>vowels_all</code>).</p>
<div id="relationship-between-intercepts-and-pc-scores" class="section level2">
<h2>Relationship between intercepts and PC scores</h2>
<p>First let’s visualise the relationship between the PC scores and the speaker intercepts. This will show us if speakers with +/- scores have +/- intercepts. Our prediction is that those with the largest PC scores will have large intercepts. When we are referring to ‘large’ here, we are talking about absolute values, where + and - values are important.</p>
<p>The vowel-formants that contribute most to a PC (highlighted by the yellow boxes in the plot below) are those we are most interested in and should show a clear slope in the regression fits.</p>
<pre class="r"><code>#extract the PCA scores for the first 3 PCs from the PCA
PC_speaker_loadings &lt;- as.data.frame(intercepts.pca$scores[,1:3]) %&gt;% #the loadings are stored in the scores part of the intercepts.pca object
  mutate(Speaker = gam_intercepts.tmp$Speaker) #create a Speaker variable with the speaker names

#get speaker&#39;s social information and combine it with the speaker intercepts and then the PC loadings
PC_speaker_loadings &lt;-  vowels_all %&gt;%
  dplyr::select(Speaker, Corpus, Gender, participant_year_of_birth) %&gt;% #choose the variables of interest from vowels_all
  distinct() %&gt;% #make one row for each speaker
  left_join(., gam_intercepts.tmp, by = &quot;Speaker&quot;) %&gt;% #combine the social information with the intercepts
  left_join(., PC_speaker_loadings, by = &quot;Speaker&quot;) #combine this with the PC loadings

#add the PCA scores from PC1, PC2 and PC3
vowels_all &lt;- vowels_all %&gt;%
  left_join(PC_speaker_loadings[, c(&quot;Speaker&quot;, &quot;Comp.1&quot;, &quot;Comp.2&quot;, &quot;Comp.3&quot;)])

PC_variable_loadings &lt;- data.frame(intercepts.pca$loadings[,1:3]) %&gt;%
  mutate(name = row.names(.),
         Formant = substr(name, 1, 2), #add extra variables
         Vowel = substr(name, 4, max(nchar(name)))) %&gt;%
  rename(PC1_loading = 1,
         PC2_loading = 2,
         PC3_loading = 3)

#extract the PCA scores for the first 3 PCs from the PCA
PC_speaker_loadings1 &lt;- as.data.frame(intercepts.pca$scores[,1:3]) %&gt;% #the loadings are stored in the scores part of the intercepts.pca object
  mutate(Speaker = gam_intercepts.tmp$Speaker) %&gt;%
  left_join(vowels_all %&gt;% select(Speaker, participant_year_of_birth, Gender) %&gt;% distinct())

PC = c(1:3)

gam_intercepts.tmp_long1 &lt;- intercepts.pca$scores[,PC] %*% t(intercepts.pca$loadings[,PC]) %&gt;%
  data.frame() %&gt;%
  mutate(Speaker = gam_intercepts.tmp$Speaker) %&gt;% #add speaker names
  select(Speaker, 1:ncol(.)-1) %&gt;% #reorder the variables
  pivot_longer(F1_DRESS:F2_TRAP) %&gt;% #make data long
  left_join(gam_intercepts.tmp %&gt;% pivot_longer(F1_DRESS:F2_TRAP, values_to = &quot;intercepts&quot;)) %&gt;% #add the original intercepts
  mutate(Formant = substr(name, 1, 2), #add extra variables
         Vowel = substr(name, 4, max(nchar(name))),
         mod = paste0(Formant, &quot;_intercepts&quot;)) %&gt;%
  left_join(PC_speaker_loadings %&gt;% select(Speaker:participant_year_of_birth, Gender, Comp.1, Comp.2, Comp.3)) %&gt;%
  left_join(mod_pred_yob_values %&gt;% select(participant_year_of_birth, fit, ll, ul, Vowel, Formant)) %&gt;%
  left_join(PC_variable_loadings) %&gt;%
  left_join(PC_variable_loadings %&gt;% group_by(Vowel) %&gt;% summarise(PC1_loading_max = max(abs(PC1_loading)), PC2_loading_max = max(abs(PC2_loading)), PC3_loading_max = max(abs(PC3_loading)))) %&gt;%
  mutate(intercepts1 = intercepts + fit,
         Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;), ordered = TRUE))

gam_intercepts.tmp_long1_test &lt;- gam_intercepts.tmp_long1 %&gt;%
  pivot_longer(Comp.1:Comp.3, names_to = &quot;Comp&quot;, values_to = &quot;Comp_score&quot;) %&gt;%
  left_join(., rbind(PC1_contrib %&gt;% ungroup() %&gt;% select(Variable, PC, highlight),
      PC2_contrib %&gt;% ungroup() %&gt;% select(Variable, PC, highlight),
      PC3_contrib %&gt;% ungroup() %&gt;% select(Variable, PC, highlight)) %&gt;%
        rename(name = Variable,
               Comp = PC) %&gt;%
        mutate(Comp = gsub(x = Comp, &quot;Loading.PC&quot;, &quot;Comp.&quot;)))

ggplot(data = gam_intercepts.tmp_long1_test, aes(x = -Comp_score, y = intercepts, colour = Comp)) +
  geom_point(size = 0.5, alpha = 0.1, colour = &quot;black&quot;) +
  # geom_point(aes(x = Comp_score, y = intercepts1), colour = &quot;red&quot;, size = 0.2, alpha = 0.1) +
  geom_smooth(method = &quot;lm&quot;) +
  # geom_smooth(aes(x = intercepts, y = intercepts1), colour = &quot;red&quot;, method = &quot;lm&quot;) +
  geom_abline(slope = 0, linetype = 2) +
  geom_rect(data = gam_intercepts.tmp_long1_test %&gt;% filter(highlight == &quot;black&quot;), aes(xmin = -7, xmax = 7, ymin = -1.2, ymax = 1.2), alpha = 0, colour = &quot;yellow&quot;) +
  # scale_colour_viridis_c() +
  xlab(&quot;PC score&quot;) +
  facet_grid(Comp+Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-38-1.png" width="2100" /></p>
</div>
<div id="regression-models-for-intercepts-pc-score" class="section level2">
<h2>Regression models for intercepts ~ PC score</h2>
<p>As the above plot is just a visualisation, we want to now run the regressions.</p>
<p>For each PC, we will run a regression for each vowel-formant, where we predict the speaker intercept by the speaker PC scores. We are not necessarily interested in the p values of these models as they are mainly for visualisation of the relationship.</p>
<pre class="r"><code>mod_pred_PC1_values &lt;- data.frame(intercepts = numeric(),
                                  Comp.1 = numeric(),
                                  residuals = numeric(),
                                  fitted.values = numeric(),
                                  residuals1 = numeric(),
                                  fitted.values1 = numeric(),
                                  mod = character())

for (i in levels(factor(gam_intercepts.tmp_long1$name))) {
  lm1 &lt;- lm(intercepts ~ Comp.1, data = gam_intercepts.tmp_long1, subset = name == i)
  lm1_values &lt;- cbind(lm1[[&quot;model&quot;]], lm1[[&quot;residuals&quot;]], lm1[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals = 3, fitted.values = 4) %&gt;%
    mutate(diff = residuals + fitted.values,
           mod = i,
           Formant = substr(i, 1, 2),
           Vowel = substr(i, 4, nchar(i)))

  lm2 &lt;- lm(intercepts1 ~ Comp.1, data = gam_intercepts.tmp_long1, subset = name == i)
  lm2_values &lt;- cbind(lm2[[&quot;model&quot;]], lm2[[&quot;residuals&quot;]], lm2[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals1 = 3, fitted.values1 = 4) %&gt;%
    mutate(diff1 = residuals1 + fitted.values1)

  lm1_values &lt;- lm1_values %&gt;%
    left_join(lm2_values)

  mod_pred_PC1_values &lt;&lt;- rbind(mod_pred_PC1_values, lm1_values)
}

mod_pred_PC1_values_plot &lt;- mod_pred_PC1_values %&gt;%
  select(Vowel, Formant, Comp.1, intercepts, fitted.values, intercepts1, fitted.values1) %&gt;%
  pivot_wider(names_from = Formant, values_from = c(intercepts, fitted.values, intercepts1, fitted.values1)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(id = 1:481) %&gt;%
  left_join(gam_intercepts.tmp_long1 %&gt;%
              select(Speaker, Vowel, Formant, PC1_loading, PC1_loading_max, fit, intercepts, intercepts1, participant_year_of_birth) %&gt;%
              pivot_wider(names_from = Formant, values_from = c(fit, intercepts, intercepts1, PC1_loading)) %&gt;%
              distinct())

mod_pred_PC2_values &lt;- data.frame(intercepts = numeric(),
                                  Comp.2 = numeric(),
                                  residuals = numeric(),
                                  fitted.values = numeric(),
                                  residuals1 = numeric(),
                                  fitted.values1 = numeric(),
                                  mod = character())

for (i in levels(factor(gam_intercepts.tmp_long1$name))) {
  lm1 &lt;- lm(intercepts ~ Comp.2, data = gam_intercepts.tmp_long1, subset = name == i)
  lm1_values &lt;- cbind(lm1[[&quot;model&quot;]], lm1[[&quot;residuals&quot;]], lm1[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals = 3, fitted.values = 4) %&gt;%
    mutate(diff = residuals + fitted.values,
           mod = i,
           Formant = substr(i, 1, 2),
           Vowel = substr(i, 4, nchar(i)))

  lm2 &lt;- lm(intercepts1 ~ Comp.2, data = gam_intercepts.tmp_long1, subset = name == i)
  lm2_values &lt;- cbind(lm2[[&quot;model&quot;]], lm2[[&quot;residuals&quot;]], lm2[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals1 = 3, fitted.values1 = 4) %&gt;%
    mutate(diff1 = residuals1 + fitted.values1)

  lm1_values &lt;- lm1_values %&gt;%
    left_join(lm2_values)

  mod_pred_PC2_values &lt;&lt;- rbind(mod_pred_PC2_values, lm1_values)
}

mod_pred_PC2_values_plot &lt;- mod_pred_PC2_values %&gt;%
  select(Vowel, Formant, Comp.2, intercepts, fitted.values, intercepts1, fitted.values1) %&gt;%
  pivot_wider(names_from = Formant, values_from = c(intercepts, fitted.values, intercepts1, fitted.values1)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(id = 1:481) %&gt;%
  left_join(gam_intercepts.tmp_long1 %&gt;%
              select(Speaker, Vowel, Formant, PC2_loading, PC2_loading_max, fit, intercepts, intercepts1, participant_year_of_birth) %&gt;%
              pivot_wider(names_from = Formant, values_from = c(fit, intercepts, intercepts1, PC2_loading)) %&gt;%
              distinct())

mod_pred_PC3_values &lt;- data.frame(intercepts = numeric(),
                                  Comp.3 = numeric(),
                                  residuals = numeric(),
                                  fitted.values = numeric(),
                                  residuals1 = numeric(),
                                  fitted.values1 = numeric(),
                                  mod = character())

for (i in levels(factor(gam_intercepts.tmp_long1$name))) {
  lm1 &lt;- lm(intercepts ~ Comp.3, data = gam_intercepts.tmp_long1, subset = name == i)
  lm1_values &lt;- cbind(lm1[[&quot;model&quot;]], lm1[[&quot;residuals&quot;]], lm1[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals = 3, fitted.values = 4) %&gt;%
    mutate(diff = residuals + fitted.values,
           mod = i,
           Formant = substr(i, 1, 2),
           Vowel = substr(i, 4, nchar(i)))

  lm2 &lt;- lm(intercepts1 ~ Comp.3, data = gam_intercepts.tmp_long1, subset = name == i)
  lm2_values &lt;- cbind(lm2[[&quot;model&quot;]], lm2[[&quot;residuals&quot;]], lm2[[&quot;fitted.values&quot;]]) %&gt;%
    rename(residuals1 = 3, fitted.values1 = 4) %&gt;%
    mutate(diff1 = residuals1 + fitted.values1)

  lm1_values &lt;- lm1_values %&gt;%
    left_join(lm2_values)

  mod_pred_PC3_values &lt;&lt;- rbind(mod_pred_PC3_values, lm1_values)
}

mod_pred_PC3_values_plot &lt;- mod_pred_PC3_values %&gt;%
  select(Vowel, Formant, Comp.3, intercepts, fitted.values, intercepts1, fitted.values1) %&gt;%
  pivot_wider(names_from = Formant, values_from = c(intercepts, fitted.values, intercepts1, fitted.values1)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(id = 1:481) %&gt;%
  left_join(gam_intercepts.tmp_long1 %&gt;%
              select(Speaker, Vowel, Formant, PC3_loading, PC3_loading_max, fit, intercepts, intercepts1, participant_year_of_birth) %&gt;%
              pivot_wider(names_from = Formant, values_from = c(fit, intercepts, intercepts1, PC3_loading)) %&gt;%
              distinct())

mod_pred_PC_values &lt;- cbind(mod_pred_PC1_values_plot %&gt;%
          select(Comp.1, Vowel, fitted.values1_F1, fitted.values1_F2) %&gt;%
          dplyr::rename(F1_PC1 = fitted.values1_F1,
                F2_PC1 = fitted.values1_F2),
          mod_pred_PC2_values_plot %&gt;%
          select(Comp.2, Vowel, fitted.values1_F1, fitted.values1_F2) %&gt;%
          dplyr::rename(F1_PC2 = fitted.values1_F1,
                F2_PC2 = fitted.values1_F2),
          mod_pred_PC3_values_plot %&gt;%
          select(Comp.3, Vowel, fitted.values1_F1, fitted.values1_F2) %&gt;%
          dplyr::rename(F1_PC3 = fitted.values1_F1,
                F2_PC3 = fitted.values1_F2))</code></pre>
</div>
<div id="visualisation-in-f1f2-space-1" class="section level2">
<h2>Visualisation in F1~F2 space</h2>
<p>Now we have the predicted values from the regression models, we can transform that data to visualise it in terms of F1~F2 space.</p>
<p>In the plots below, there is a vowel space plotted for each of the 3 PCs. The plots show:</p>
<ul>
<li><p>The location of the speaker intercepts (calculated by adding them to the GAMM model predictions for year of birth). These are plotted as the points and coloured by the speaker PC score (+ = green, - = black)</p></li>
<li><p>The direction of the regression model predictions. Plotted as the green to black trajectories. The wider and larger the trajectories, the more important the vowel is to the PC</p></li>
<li><p>The vowel label. Plotted as text, the size and yellowness indicates the importance of the vowel to the PC (large and yellow labels account for more variance in the PC). The position is based on the point where the regression trajectory is for the speakers with smallest negative PC score</p></li>
</ul>
<p>The plots can be used to interpret the directionality of the vowel-formants in the PC, providing a schematic of where speakers with +/- PC scores are in terms of F1~F2 space.</p>
<pre class="r"><code>mod_pred_PC1_values_vowel_plot &lt;- mod_pred_PC1_values_plot %&gt;%
  ggplot(aes(x = fitted.values1_F2, y = fitted.values1_F1, colour = -Comp.1, size = PC1_loading_max, group = Vowel)) +
  geom_point(aes(x = intercepts1_F2, y = intercepts1_F1), size = 0.4, alpha = 0.5) +
  # geom_path(data = mod_pred_PC3_values_plot %&gt;% arrange(Vowel, participant_year_of_birth), aes(x = fit_F2, y = fit_F1, group = Vowel), size = 1, colour = &quot;red&quot;) +
  geom_line() +
  geom_label(data = mod_pred_PC1_values_plot %&gt;%
  mutate(fitted.values2_F1 = ifelse(Vowel %in% c(&quot;FLEECE&quot;, &quot;DRESS&quot;, &quot;GOOSE&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;THOUGHT&quot;, &quot;LOT&quot;), 0, 0.5)),
         fitted.values2_F2 = ifelse(Vowel %in% c(&quot;STRUT&quot;, &quot;START&quot;, &quot;NURSE&quot;, &quot;GOOSE&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;DRESS&quot;, &quot;FLEECE&quot;), 0, 0.5))) %&gt;%
               filter(-Comp.1 == min(-Comp.1)), aes(label = Vowel, fill = rescale(PC1_loading_max^2, to = c(0, 1)), vjust = fitted.values2_F1, hjust = fitted.values2_F2), label.padding = unit(0.1, &quot;lines&quot;), colour = &quot;black&quot;, show.legend = FALSE) +
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  scale_x_reverse(position = &quot;top&quot;, limits = c(2.4, -3)) +
  scale_y_reverse(position = &quot;right&quot;) +
  scale_colour_gradient2(name = &quot;PC1 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;, guide = &quot;none&quot;) +
  scale_size_continuous(range = c(1, 5), guide = &quot;none&quot;) +
  # facet_wrap(~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;bottom&quot;, axis.title = element_text(size = 14, face = &quot;bold&quot;), legend.title = element_text(size = 14, face = &quot;bold&quot;))

mod_pred_PC1_values_vowel_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-40-1.png" width="1500" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC1_values_vowel_plot, filename = &quot;Figures/mod_pred_PC1_values_vowel_plot.png&quot;, width = 7, height = 7, dpi = 400)

mod_pred_PC2_values_vowel_plot &lt;- mod_pred_PC2_values_plot %&gt;%
  ggplot(aes(x = fitted.values1_F2, y = fitted.values1_F1, colour = -Comp.2, size = PC2_loading_max, group = Vowel)) +
  geom_point(aes(x = intercepts1_F2, y = intercepts1_F1), size = 0.4, alpha = 0.5) +
  # geom_path(data = mod_pred_PC3_values_plot %&gt;% arrange(Vowel, participant_year_of_birth), aes(x = fit_F2, y = fit_F1, group = Vowel), size = 1, colour = &quot;red&quot;) +
  geom_line() +
  geom_label(data = mod_pred_PC2_values_plot %&gt;%
  mutate(fitted.values2_F1 = ifelse(Vowel %in% c(&quot;TRAP&quot;, &quot;DRESS&quot;, &quot;NURSE&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;FLEECE&quot;, &quot;KIT&quot;, &quot;GOOSE&quot;, &quot;STRUT&quot;), 0, 0.5)),
         fitted.values2_F2 = ifelse(Vowel %in% c(&quot;LOT&quot;, &quot;KIT&quot;, &quot;FLEECE&quot;, &quot;STRUT&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;NURSE&quot;, &quot;THOUGHT&quot;), 0, 0.5))) %&gt;%
               filter(-Comp.2 == min(-Comp.2)), aes(label = Vowel, fill = rescale(PC2_loading_max^2, to = c(0, 1)), vjust = fitted.values2_F1, hjust = fitted.values2_F2), label.padding = unit(0.1, &quot;lines&quot;), colour = &quot;black&quot;, show.legend = FALSE) +
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  scale_x_reverse(position = &quot;top&quot;, limits = c(2.4, -3)) +
  scale_y_reverse(position = &quot;right&quot;) +
  scale_colour_gradient2(name = &quot;PC2 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;, guide = &quot;none&quot;) +
  scale_size_continuous(range = c(1, 5), guide = &quot;none&quot;) +
  # facet_wrap(~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;bottom&quot;, axis.title = element_text(size = 14, face = &quot;bold&quot;), legend.title = element_text(size = 14, face = &quot;bold&quot;))

mod_pred_PC2_values_vowel_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-40-2.png" width="1500" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC2_values_vowel_plot, filename = &quot;Figures/mod_pred_PC2_values_vowel_plot.png&quot;, width = 7, height = 7, dpi = 400)

mod_pred_PC3_values_vowel_plot &lt;- mod_pred_PC3_values_plot %&gt;%
  ggplot(aes(x = fitted.values1_F2, y = fitted.values1_F1, colour = -Comp.3, size = PC3_loading_max, group = Vowel)) +
  geom_point(aes(x = intercepts1_F2, y = intercepts1_F1), size = 0.4, alpha = 0.5) +
  # geom_path(data = mod_pred_PC3_values_plot %&gt;% arrange(Vowel, participant_year_of_birth), aes(x = fit_F2, y = fit_F1, group = Vowel), size = 1, colour = &quot;red&quot;) +
  geom_line() +
  geom_label(data = mod_pred_PC3_values_plot %&gt;%
  mutate(fitted.values2_F1 = ifelse(Vowel %in% c(&quot;STRUT&quot;, &quot;LOT&quot;, &quot;THOUGHT&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;GOOSE&quot;, &quot;START&quot;), 0, 0.5)),
         fitted.values2_F2 = ifelse(Vowel %in% c(&quot;GOOSE&quot;, &quot;NURSE&quot;, &quot;KIT&quot;), 1,
                                    ifelse(Vowel %in% c(&quot;FLEECE&quot;, &quot;DRESS&quot;, &quot;TRAP&quot;), 0, 0.5))) %&gt;%
               filter(-Comp.3 == min(-Comp.3)), aes(label = Vowel, fill = rescale(PC3_loading_max^2, to = c(0, 1)), vjust = fitted.values2_F1, hjust = fitted.values2_F2), label.padding = unit(0.1, &quot;lines&quot;), colour = &quot;black&quot;, show.legend = FALSE) +
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  scale_x_reverse(position = &quot;top&quot;, limits = c(2.4, -3)) +
  scale_y_reverse(position = &quot;right&quot;) +
  scale_colour_gradient2(name = &quot;PC3 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;, guide = &quot;none&quot;) +
  scale_size_continuous(range = c(1, 5), guide = &quot;none&quot;) +
  # facet_wrap(~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;bottom&quot;, axis.title = element_text(size = 14, face = &quot;bold&quot;), legend.title = element_text(size = 14, face = &quot;bold&quot;))

mod_pred_PC3_values_vowel_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-40-3.png" width="1500" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC3_values_vowel_plot, filename = &quot;Figures/mod_pred_PC3_values_vowel_plot.png&quot;, width = 7, height = 7, dpi = 400)</code></pre>
</div>
<div id="relationship-to-sound-change" class="section level2">
<h2>Relationship to sound change</h2>
<p>Finally, we also want to see how the speaker intercepts and PC scores relate to sound change.</p>
<pre class="r"><code>mod_pred_PC1_values_grid_plot &lt;- mod_pred_PC1_values_plot %&gt;%
           ungroup() %&gt;%
  pivot_longer(intercepts_F1:intercepts_F2, names_to = &quot;Formant&quot;, values_to = &quot;intercepts&quot;) %&gt;%
  mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant))) %&gt;%
  left_join(mod_pred_PC1_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2) %&gt;%
              pivot_longer(fit_F1:fit_F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  left_join(mod_pred_PC1_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2, -fit_F1, -fit_F2) %&gt;%
              pivot_longer(fitted.values_F1:fitted.values_F2, names_to = &quot;Formant&quot;, values_to = &quot;fitted.values&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  arrange(Vowel, abs(-Comp.1)) %&gt;%
  ggplot(aes(x = participant_year_of_birth, colour = -Comp.1)) +
  geom_point(aes(y = intercepts + fit, size = abs(-Comp.1))) +
  # geom_point(aes(y = intercepts + fit), size = 1) +
  geom_path(data = gam_intercepts.tmp_long1 %&gt;% arrange(Vowel, participant_year_of_birth), aes(y = fit, group = Vowel), size = 1, colour = &quot;red&quot;) +
  geom_label(data = gam_intercepts.tmp_long1 %&gt;% select(Vowel, Formant, PC1_loading) %&gt;% distinct(), aes(x = ((max(vowels_all$participant_year_of_birth)-min(vowels_all$participant_year_of_birth))/2)+min(vowels_all$participant_year_of_birth), y = 2.7, label = paste0(round(PC1_loading^2, 3)*100, &quot;%&quot;), fill = rescale(PC1_loading^2, to = c(0, 1))), hjust = 0.5, inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = &quot;Participant year of birth&quot;, breaks = c(1900, 1950), limits = c(1856, 1990)) +
  scale_y_continuous(name = &quot;Normalised formant value&quot;, breaks = c(-2, -1, 0, 1, 2), limits = c(-2.7, 3)) +
  # ylab(&quot;Normalised formant value&quot;) +
  scale_size_continuous(range = c(0.5, 1), guide = NULL) +
  scale_colour_gradient2(name = &quot;PC1 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;) +
  geom_rect(data = gam_intercepts.tmp_long1_test %&gt;% filter(Comp == &quot;Comp.1&quot; &amp; highlight == &quot;black&quot;), aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), size = 5, alpha = 0, colour = &quot;yellow&quot;) +
  facet_grid(factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;), ordered = TRUE)~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

mod_pred_PC1_values_grid_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-41-1.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC1_values_grid_plot, filename = &quot;Figures/mod_pred_PC1_values_grid_plot.png&quot;, width = 12, height = 7, dpi = 400)

mod_pred_PC2_values_grid_plot &lt;- mod_pred_PC2_values_plot %&gt;%
           ungroup() %&gt;%
  pivot_longer(intercepts_F1:intercepts_F2, names_to = &quot;Formant&quot;, values_to = &quot;intercepts&quot;) %&gt;%
  mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant))) %&gt;%
  left_join(mod_pred_PC2_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2) %&gt;%
              pivot_longer(fit_F1:fit_F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  left_join(mod_pred_PC2_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2, -fit_F1, -fit_F2) %&gt;%
              pivot_longer(fitted.values_F1:fitted.values_F2, names_to = &quot;Formant&quot;, values_to = &quot;fitted.values&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  arrange(Vowel, abs(-Comp.2)) %&gt;%
  ggplot(aes(x = participant_year_of_birth, colour = -Comp.2)) +
  geom_point(aes(y = intercepts + fit, size = abs(-Comp.2))) +
  # geom_point(aes(y = intercepts + fit), size = 1) +
  geom_path(data = gam_intercepts.tmp_long1 %&gt;% arrange(Vowel, participant_year_of_birth), aes(y = fit, group = Vowel), size = 1, colour = &quot;red&quot;) +
  geom_label(data = gam_intercepts.tmp_long1 %&gt;% select(Vowel, Formant, PC2_loading) %&gt;% distinct(), aes(x = ((max(vowels_all$participant_year_of_birth)-min(vowels_all$participant_year_of_birth))/2)+min(vowels_all$participant_year_of_birth), y = 2.7, label = paste0(round(PC2_loading^2, 3)*100, &quot;%&quot;), fill = rescale(PC2_loading^2, to = c(0, 1))), hjust = 0.5, inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = &quot;Participant year of birth&quot;, breaks = c(1900, 1950), limits = c(1856, 1990)) +
  scale_y_continuous(name = &quot;Normalised formant value&quot;, breaks = c(-2, -1, 0, 1, 2), limits = c(-2.7, 3)) +
  # ylab(&quot;Normalised formant value&quot;) +
  scale_size_continuous(range = c(0.5, 1), guide = NULL) +
  scale_colour_gradient2(name = &quot;PC2 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;) +
  geom_rect(data = gam_intercepts.tmp_long1_test %&gt;% filter(Comp == &quot;Comp.2&quot; &amp; highlight == &quot;black&quot;), aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), size = 5, alpha = 0, colour = &quot;yellow&quot;) +
  facet_grid(factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;), ordered = TRUE)~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

mod_pred_PC2_values_grid_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-41-2.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC2_values_grid_plot, filename = &quot;Figures/mod_pred_PC2_values_grid_plot.png&quot;, width = 12, height = 7, dpi = 400)

mod_pred_PC3_values_grid_plot &lt;- mod_pred_PC3_values_plot %&gt;%
           ungroup() %&gt;%
  pivot_longer(intercepts_F1:intercepts_F2, names_to = &quot;Formant&quot;, values_to = &quot;intercepts&quot;) %&gt;%
  mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant))) %&gt;%
  left_join(mod_pred_PC3_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2) %&gt;%
              pivot_longer(fit_F1:fit_F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  left_join(mod_pred_PC3_values_plot %&gt;%
              select(-intercepts_F1, -intercepts_F2, -fit_F1, -fit_F2) %&gt;%
              pivot_longer(fitted.values_F1:fitted.values_F2, names_to = &quot;Formant&quot;, values_to = &quot;fitted.values&quot;) %&gt;%
              mutate(Formant = substr(Formant, nchar(Formant)-1, nchar(Formant)))) %&gt;%
  arrange(Vowel, abs(-Comp.3)) %&gt;%
  ggplot(aes(x = participant_year_of_birth, colour = -Comp.3)) +
  geom_point(aes(y = intercepts + fit, size = abs(-Comp.3))) +
  # geom_point(aes(y = intercepts + fit), size = 1) +
  geom_path(data = gam_intercepts.tmp_long1 %&gt;% arrange(Vowel, participant_year_of_birth), aes(y = fit, group = Vowel), size = 1, colour = &quot;red&quot;) +
  # geom_smooth(aes(x = rescale(-Comp.3, to = c(min(participant_year_of_birth), max(participant_year_of_birth))), y = intercepts), method = &quot;lm&quot;) +
  geom_label(data = gam_intercepts.tmp_long1 %&gt;% select(Vowel, Formant, PC3_loading) %&gt;% distinct(), aes(x = ((max(vowels_all$participant_year_of_birth)-min(vowels_all$participant_year_of_birth))/2)+min(vowels_all$participant_year_of_birth), y = 2.7, label = paste0(round(PC3_loading^2, 3)*100, &quot;%&quot;), fill = rescale(PC3_loading^2, to = c(0, 1))), hjust = 0.5, inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = &quot;Participant year of birth&quot;, breaks = c(1900, 1950), limits = c(1856, 1990)) +
  scale_y_continuous(name = &quot;Normalised formant value&quot;, breaks = c(-2, -1, 0, 1, 2), limits = c(-2.7, 3)) +
  # ylab(&quot;Normalised formant value&quot;) +
  scale_size_continuous(range = c(0.5, 1), guide = NULL) +
  scale_colour_gradient2(name = &quot;PC3 score&quot;, low = &quot;black&quot;, mid = &quot;white&quot; , high = &quot;#7CAE00&quot;,
                         midpoint=0, breaks = c(-3, 0, 3)) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;yellow&quot;) +
  geom_rect(data = gam_intercepts.tmp_long1_test %&gt;% filter(Comp == &quot;Comp.3&quot; &amp; highlight == &quot;black&quot;), aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), size = 5, alpha = 0, colour = &quot;yellow&quot;) +
  facet_grid(factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;), ordered = TRUE)~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

mod_pred_PC3_values_grid_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-41-3.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = mod_pred_PC3_values_grid_plot, filename = &quot;Figures/mod_pred_PC3_values_grid_plot.png&quot;, width = 12, height = 7, dpi = 400)</code></pre>
</div>
<div id="combine-the-plots" class="section level2">
<h2>Combine the plots</h2>
<pre class="r"><code>PC1_variables_combined_plot1 &lt;- plot_grid(PC1_contrib_plot, NULL, rel_heights = c(1, 0.1), nrow = 2, ncol = 1)

PC1_variables_combined_plot &lt;- plot_grid(NULL, plot_grid(NULL, NULL, labels = c(&quot;A&quot;, &quot;B&quot;), label_size = 25), plot_grid(PC1_variables_combined_plot1, mod_pred_PC1_values_vowel_plot, align = &quot;vh&quot;, axis = &quot;t&quot;), nrow = 3, rel_heights = c(0.1, 0.08, 1), labels = c(&quot;PC1&quot;, &quot;&quot;, &quot;&quot;), label_size = 25, label_x = -0.015, align = &quot;hv&quot;)

# ggsave(plot = PC1_variables_combined_plot, filename = &quot;Figures/PC1_plot_variables_combined.png&quot;, width = 14, height = 7, dpi = 600)

PC2_variables_combined_plot1 &lt;- plot_grid(PC2_contrib_plot, NULL, rel_heights = c(1, 0.1), nrow = 2, ncol = 1)

PC2_variables_combined_plot &lt;- plot_grid(NULL, plot_grid(NULL, NULL, labels = c(&quot;A&quot;, &quot;B&quot;), label_size = 25), plot_grid(PC2_variables_combined_plot1, mod_pred_PC2_values_vowel_plot, align = &quot;vh&quot;, axis = &quot;t&quot;), nrow = 3, rel_heights = c(0.1, 0.08, 1), labels = c(&quot;PC2&quot;, &quot;&quot;, &quot;&quot;), label_size = 25, label_x = -0.015, align = &quot;hv&quot;)

# ggsave(plot = PC2_variables_combined_plot, filename = &quot;Figures/PC2_plot_variables_combined.png&quot;, width = 14, height = 7, dpi = 600)

PC3_variables_combined_plot1 &lt;- plot_grid(PC3_contrib_plot, NULL, rel_heights = c(1, 0.1), nrow = 2, ncol = 1)

PC3_variables_combined_plot &lt;- plot_grid(NULL, plot_grid(NULL, NULL, labels = c(&quot;A&quot;, &quot;B&quot;), label_size = 25), plot_grid(PC3_variables_combined_plot1, mod_pred_PC3_values_vowel_plot, align = &quot;vh&quot;, axis = &quot;t&quot;), nrow = 3, rel_heights = c(0.1, 0.08, 1), labels = c(&quot;PC3&quot;, &quot;&quot;, &quot;&quot;), label_size = 25, label_x = -0.015, align = &quot;hv&quot;)

# ggsave(plot = PC3_variables_combined_plot, filename = &quot;Figures/PC3_plot_variables_combined.png&quot;, width = 14, height = 7, dpi = 600)

PC1_plot_combined &lt;- plot_grid(PC1_variables_combined_plot, NULL, mod_pred_PC1_values_grid_plot, rel_heights = c(1, 0.08, 1), labels = c(&quot;&quot;, &quot;C&quot;, &quot;&quot;), label_size = 25, nrow = 3)

PC1_plot_combined</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-42-1.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = PC1_plot_combined, filename = &quot;Figures/PC1_plot.png&quot;, width = 15, height = 15, dpi = 600)

PC2_plot_combined &lt;- plot_grid(PC2_variables_combined_plot, mod_pred_PC2_values_grid_plot, labels = c(&quot;&quot;, &quot;C&quot;), label_size = 25, nrow = 2)

PC2_plot_combined</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-42-2.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = PC2_plot_combined, filename = &quot;Figures/PC2_plot.png&quot;, width = 15, height = 15, dpi = 600)

PC3_plot_combined &lt;- plot_grid(PC3_variables_combined_plot, mod_pred_PC3_values_grid_plot, labels = c(&quot;&quot;, &quot;C&quot;), label_size = 25, nrow = 2)

PC3_plot_combined</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-42-3.png" width="3000" /></p>
<pre class="r"><code>ggsave(plot = PC3_plot_combined, filename = &quot;Figures/PC3_plot.png&quot;, width = 15, height = 15, dpi = 600)</code></pre>
</div>
<div id="pcs-combined" class="section level2">
<h2>PCs combined</h2>
<p>To understand which variables are linked to each other in terms of vowel space, we can visualise all 3 PCs on one plot, connecting the variables together by lines depending on which PC the variable is linked to. This highlights the point that no vowel is independent of others within the system.</p>
<pre class="r"><code>#transform data so there are separate columns for F1 and F2
sound_change_plot_data1 &lt;- mod_pred_yob_values %&gt;%
  select(participant_year_of_birth, fit, Vowel, Formant) %&gt;%
  pivot_wider(names_from = Formant, values_from = fit) %&gt;% #transform the data to wide format so there are separate F1 and F2 variables
  mutate(PC1 = ifelse(Vowel %in% c(&quot;START&quot;, &quot;STRUT&quot;, &quot;THOUGHT&quot;), TRUE, FALSE),
         PC2 = ifelse(Vowel %in% c(&quot;DRESS&quot;, &quot;LOT&quot;, &quot;NURSE&quot;, &quot;FLEECE&quot;, &quot;KIT&quot;, &quot;TRAP&quot;), TRUE, FALSE),
         PC3 = ifelse(Vowel %in% c(&quot;DRESS&quot;, &quot;GOOSE&quot;, &quot;LOT&quot;, &quot;START&quot;), TRUE, FALSE))

#make data frame to plot starting point, this will give the vowel labels based on the smallest year of birth coordinates
sound_change_labels1 &lt;- sound_change_plot_data1 %&gt;%
  group_by(Vowel) %&gt;%
  filter(participant_year_of_birth == min(participant_year_of_birth)) %&gt;%
  mutate(F2 = ifelse(Vowel == &quot;DRESS&quot;, 1.25,
                     ifelse(Vowel == &quot;LOT&quot;, -1.5,
                            ifelse(Vowel == &quot;KIT&quot;, F2 - 0.25, F2))),
         F1 = ifelse(Vowel %in% c(&quot;DRESS&quot;, &quot;NURSE&quot;, &quot;THOUGHT&quot;, &quot;LOT&quot;, &quot;STRUT&quot;), F1 - 0.4,
                     ifelse(Vowel == &quot;TRAP&quot;, F1 - 0.6,
                            ifelse(Vowel == &quot;KIT&quot;, F1 -0.2,
                                   ifelse(Vowel == &quot;START&quot;, F1 + 0.02, F1))))) %&gt;%
  ungroup()

hull_PC1 &lt;- sound_change_labels1 %&gt;%
  filter(PC1 == TRUE) %&gt;%
  # select(Vowel, F2, F1) %&gt;%
  distinct() %&gt;%
  slice(chull(F1, F2)) %&gt;%
  mutate(PC = &quot;PC1&quot;) %&gt;%
  as.data.frame()

hull_PC2 &lt;- sound_change_labels1 %&gt;%
  filter(PC2 == TRUE) %&gt;%
  distinct() %&gt;%
  slice(chull(F1, F2)) %&gt;%
  mutate(PC = &quot;PC2&quot;) %&gt;%
  as.data.frame()

hull_PC3 &lt;- sound_change_labels1 %&gt;%
  filter(PC3 == TRUE) %&gt;%
  # select(Vowel, F2, F1) %&gt;%
  distinct() %&gt;%
  slice(chull(F1, F2)) %&gt;%
  mutate(PC = &quot;PC3&quot;) %&gt;%
  as.data.frame()

hulls &lt;- rbind(hull_PC1, head(hull_PC1, 1), hull_PC2, head(hull_PC2, 1), hull_PC3, head(hull_PC3, 1)) %&gt;%
  left_join(sound_change_labels1 %&gt;% rename(F1_label = F1, F2_label = F2))

#plot
PC_hull_plot &lt;- hulls %&gt;%
  ggplot() +
  geom_path(aes(x = F2, y = F1, linetype = PC), colour = &quot;black&quot;, alpha = 1, fill=NA, show.legend = TRUE) +
  geom_label(aes(x = F2_label, y = F1_label, label = Vowel), colour = &quot;white&quot;, fill = &quot;white&quot;, lwd = NA, show.legend = FALSE) +
  geom_text(aes(x = F2_label, y = F1_label, colour = Vowel, label = Vowel), show.legend = FALSE) +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #scale the size so the path is not too wide
  scale_size_continuous(range = c(0.2,1)) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_linetype_manual(values = c(1, 5, 3)) +
  #set the theme
  theme_bw() +
  #make title bold
  theme(plot.title = element_text(face=&quot;bold&quot;),
        legend.position = c(0.87, 0.9),
        # legend.background = element_rect(colour = &#39;black&#39;, fill = &#39;white&#39;, linetype=&#39;solid&#39;),
        legend.title = element_blank()) +
  guides(linetype=guide_legend(keywidth = 2.5, keyheight = 1, label.position = &quot;left&quot;),
         colour=guide_colorbar(&quot;none&quot;))

PC_hull_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-43-1.png" width="1500" /></p>
<pre class="r"><code>ggsave(plot = PC_hull_plot, filename = &quot;Figures/summary_PC.png&quot;, width = 5.5, height = 5.5, dpi = 300)</code></pre>
</div>
<div id="pc-scores-and-year-of-birth" class="section level2">
<h2>PC scores and year of birth</h2>
<p>Next, our analyses will inspect whether the PC scores within each of the 3 PCs are independent of social information, i.e. year of birth and gender.</p>
<p>We will begin by running GAMs to see if any of the socio-demographic variables can predict the PC scores significantly.</p>
<p>We hypothesise that our initial GAMMs had these variables included in the fixed-effects structure, so, none of the subsequent models should show significant results. If there are no significant effects, then we have confidence in our modelling procedure and that the speaker intercepts are representative of variation independent of the known predictors of change in F1/F2.</p>
<p>In order to statistically assess whether the PC scores are reliably predicted by any of the social variables, we will run a series of GAMs, predicting the PC scores in each of the 3 PCs by each of the social variables. We will also provide visualisations of the results (reproducing <strong>Figure XX</strong>).</p>
<p><strong>PC1</strong></p>
<pre class="r"><code>#run a GAM to predict the PCA score on PC1 by the social information
# (entering Gender as a factor here (not ordered!), which generates
#  completely separate smooths for each Gender)
gam_PC1 = bam(-Comp.1 ~
             s(participant_year_of_birth, k=10, by=Gender) +
             Gender +
             Corpus,
           data=PC_speaker_loadings)

summary(gam_PC1)</code></pre>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## -Comp.1 ~ s(participant_year_of_birth, k = 10, by = Gender) + 
##     Gender + Corpus
## 
## Parametric coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)     0.04203    0.13690   0.307  0.75899   
## GenderM        -0.04773    0.17182  -0.278  0.78129   
## CorpusDarfield -1.09406    0.38502  -2.842  0.00468 **
## CorpusIA        0.03169    0.29025   0.109  0.91311   
## CorpusMU        0.38015    0.41250   0.922  0.35722   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                      edf Ref.df     F p-value
## s(participant_year_of_birth):GenderM   1      1 0.482   0.488
## 
## R-sq.(adj) =  0.00986   Deviance explained = 2.02%
## fREML = 979.42  Scale est. = 3.4209    n = 481</code></pre>
<pre class="r"><code># extract predictions
gam_PC1_preds &lt;- plot_smooth(gam_PC1, view=&quot;participant_year_of_birth&quot;, plot_all=&quot;Gender&quot;)$fv</code></pre>
<pre><code>## Summary:
##  * Gender : factor; set to the value(s): F, M. 
##  * Corpus : factor; set to the value(s): CC. 
##  * participant_year_of_birth : numeric predictor; with 30 values ranging from 1864.000000 to 1982.000000.</code></pre>
<pre class="r"><code>PC1_speaker_loadings &lt;- ggplot(PC_speaker_loadings, aes(x = participant_year_of_birth, y = -Comp.1, #plot year of birth on the x axis and PC2 score on the y axis
                                label = Gender, color = Gender)) + #make the colours and data points represent Gender
  geom_point(size = 0, stroke = 0, show.legend = FALSE) + #add an empty data point for plotting
  geom_text(show.legend = FALSE) + #add text label i.e. F/M
  geom_ribbon(data=gam_PC1_preds, aes(ymin=-ll, ymax=-ul, y=NULL, group = Gender), col=&quot;grey&quot;, alpha = 0.2) +
  geom_line(data=gam_PC1_preds, aes(y=-fit), size = 1.25) +
  scale_y_continuous(breaks = seq(-6,6,2), limits = c(-7,7)) +
  scale_color_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;Female&quot;, &quot;Male&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;)) + #update the legend and colour scheme where F = black letters, M = green letters
  scale_fill_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;), guide=F) + #update the legend and colour scheme where F = black letters, M = green letters
  xlab(&quot;Year of birth&quot;) + #label x axis
  ylab(&quot;PC1 score&quot;) + #label y axis
  theme_bw() + #general aesthetics
  theme(axis.text = element_text(face = &quot;bold&quot;, size = 14), axis.title = element_text(face = &quot;bold&quot;, size = 14), legend.position = &quot;none&quot;) #make the text bold and larger on the axes

PC1_speaker_loadings</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-45-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC1_speaker_loadings, filename = &quot;Figures/PC1_speaker_loadings.png&quot;, width = 7, height = 3, dpi = 300)</code></pre>
<p><strong>PC2</strong></p>
<pre class="r"><code>#run a GAM to predict the PCA score on PC1 by the social information
# (entering Gender as a factor here (not ordered!), which generates
#  completely separate smooths for each Gender)
gam_PC2 = bam(-Comp.2 ~
             s(participant_year_of_birth, k=10, by=Gender) +
             Gender +
             Corpus,
           data=PC_speaker_loadings)

summary(gam_PC2)</code></pre>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## -Comp.2 ~ s(participant_year_of_birth, k = 10, by = Gender) + 
##     Gender + Corpus
## 
## Parametric coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)     0.06671    0.13198   0.505    0.613
## GenderM         0.01742    0.16565   0.105    0.916
## CorpusDarfield -0.45667    0.37118  -1.230    0.219
## CorpusIA       -0.11459    0.27981  -0.410    0.682
## CorpusMU       -0.40713    0.39768  -1.024    0.306
## 
## Approximate significance of smooth terms:
##                                      edf Ref.df     F p-value
## s(participant_year_of_birth):GenderM   1      1 0.579   0.447
## 
## R-sq.(adj) =  -0.00572   Deviance explained = 0.476%
## fREML = 962.04  Scale est. = 3.1794    n = 481</code></pre>
<pre class="r"><code># extract predictions
gam_PC2_preds &lt;- plot_smooth(gam_PC2, view=&quot;participant_year_of_birth&quot;, plot_all=&quot;Gender&quot;)$fv</code></pre>
<pre><code>## Summary:
##  * Gender : factor; set to the value(s): F, M. 
##  * Corpus : factor; set to the value(s): CC. 
##  * participant_year_of_birth : numeric predictor; with 30 values ranging from 1864.000000 to 1982.000000.</code></pre>
<pre class="r"><code>#this code repeats the same process as in PC1, but for PC2
PC2_speaker_loadings &lt;- ggplot(PC_speaker_loadings, aes(x = participant_year_of_birth, y = -Comp.2, #plot year of birth on the x axis and PC2 score on the y axis
                                label = Gender, color = Gender)) + #make the colours and data points represent Gender
  geom_point(size = 0, stroke = 0, show.legend = FALSE) + #add an empty data point for plotting
  geom_text(show.legend = FALSE) + #add text label i.e. F/M
  geom_ribbon(data=gam_PC2_preds, aes(ymin=-ll, ymax=-ul, y=NULL, group = Gender), col=&quot;grey&quot;, alpha = 0.2) +
  geom_line(data=gam_PC2_preds, aes(y=-fit), size = 1.25) +
  scale_y_continuous(breaks = seq(-6,6,2), limits = c(-7,7)) +
  scale_color_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;Female&quot;, &quot;Male&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;)) + #update the legend and colour scheme where F = black letters, M = green letters
  scale_fill_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;), guide=F) + #update the legend and colour scheme where F = black letters, M = green letters
  xlab(&quot;Year of birth&quot;) + #label x axis
  ylab(&quot;PC2 score&quot;) + #label y axis
  theme_bw() + #general aesthetics
  theme(axis.text = element_text(face = &quot;bold&quot;, size = 14), axis.title = element_text(face = &quot;bold&quot;, size = 14), legend.position = &quot;none&quot;) #make the text bold and larger on the axes

PC2_speaker_loadings</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-47-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC2_speaker_loadings, filename = &quot;Figures/PC2_speaker_loadings.png&quot;, width = 7, height = 3, dpi = 300)</code></pre>
<p><strong>PC3</strong></p>
<pre class="r"><code>#run a GAM to predict the PCA score on PC1 by the social information
# (entering Gender as a factor here (not ordered!), which generates
#  completely separate smooths for each Gender)
gam_PC3 = bam(-Comp.3 ~
             s(participant_year_of_birth, k=10, by=Gender) +
             Gender +
             Corpus,
           data=PC_speaker_loadings)

summary(gam_PC3)</code></pre>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## -Comp.3 ~ s(participant_year_of_birth, k = 10, by = Gender) + 
##     Gender + Corpus
## 
## Parametric coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -0.153924   0.099162  -1.552    0.121    
## GenderM         0.026154   0.124460   0.210    0.834    
## CorpusDarfield  2.261643   0.278891   8.109 4.37e-15 ***
## CorpusIA        0.002837   0.210242   0.013    0.989    
## CorpusMU        0.222118   0.298801   0.743    0.458    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                      edf Ref.df     F p-value
## s(participant_year_of_birth):GenderM   1      1 0.201   0.654
## 
## R-sq.(adj) =  0.114   Deviance explained = 12.3%
## fREML = 826.25  Scale est. = 1.7949    n = 481</code></pre>
<pre class="r"><code># extract predictions
gam_PC3_preds &lt;- plot_smooth(gam_PC3, view=&quot;participant_year_of_birth&quot;, plot_all=&quot;Gender&quot;)$fv</code></pre>
<pre><code>## Summary:
##  * Gender : factor; set to the value(s): F, M. 
##  * Corpus : factor; set to the value(s): CC. 
##  * participant_year_of_birth : numeric predictor; with 30 values ranging from 1864.000000 to 1982.000000.</code></pre>
<pre class="r"><code>#this code repeats the same process as in PC1, but for PC2
PC3_speaker_loadings &lt;- ggplot(PC_speaker_loadings, aes(x = participant_year_of_birth, y = -Comp.3, #plot year of birth on the x axis and PC3 score on the y axis
                                label = Gender, color = Gender)) + #make the colours and data points represent Gender
  geom_point(size = 0, stroke = 0, show.legend = FALSE) + #add an empty data point for plotting
  geom_text(show.legend = FALSE) + #add text label i.e. F/M
  geom_ribbon(data=gam_PC3_preds, aes(ymin=-ll, ymax=-ul, y=NULL, group = Gender), col=&quot;grey&quot;, alpha = 0.2) +
  geom_line(data=gam_PC3_preds, aes(y=-fit), size = 1.25) +
  scale_y_continuous(breaks = seq(-6,6,2), limits = c(-7,7)) +
  scale_color_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;Female&quot;, &quot;Male&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;)) + #update the legend and colour scheme where F = black letters, M = green letters
  scale_fill_manual(breaks = c(&quot;F&quot;, &quot;M&quot;), values = c(&quot;black&quot;, &quot;#7CAE00&quot;), guide=F) + #update the legend and colour scheme where F = black letters, M = green letters
  xlab(&quot;Year of birth&quot;) + #label x axis
  ylab(&quot;PC3 score&quot;) + #label y axis
  theme_bw() + #general aesthetics
  theme(axis.text = element_text(face = &quot;bold&quot;, size = 14), axis.title = element_text(face = &quot;bold&quot;, size = 14), legend.position = &quot;none&quot;) #make the text bold and larger on the axes

PC3_speaker_loadings</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-49-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC3_speaker_loadings, filename = &quot;Figures/PC3_speaker_loadings.png&quot;, width = 7, height = 3, dpi = 300)</code></pre>
<p><strong>Relationship between the PC scores</strong></p>
<p>It may be of interest to inspect the how the PC scores correlate with each other, i.e. checking that if you have a high score on one PC does that predict a high score on the other PCs? The correlations below show that there is no strong trends to support this, demonstrating that the PC scores and the PCs are independent.</p>
<p>Note however, there does seem to be a slight trend for speakers with high PC1 to have high PC3.</p>
<pre class="r"><code>chart.Correlation(PC_speaker_loadings %&gt;% select(Comp.1:Comp.3), histogram = FALSE, pch=19)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-50-1.png" width="2100" /></p>
<!-- Another way to combine the dot plots and the vowel plots would be: -->
<!-- ```{r fig.width=8, fig.height=4} -->
<!-- top_row <- plot_grid(NULL) -->
<!-- #PC1 -->
<!-- PC1_variables_combined_plot1 <- plot_grid(NULL, plot_grid(top_row, PC1_contrib_plot, nrow = 2, rel_heights = c(0.065, 1)), NULL, mod_pred_PC1_values_vowel_plot, rel_widths = c(0.03, 0.6, 0.03, 0.6), rel_heights = c(0.03, 0.6, 0.03, 0.4), labels = c("A", "", "B", ""), label_size = 25, nrow = 1, ncol = 5) -->
<!-- PC1_variables_combined_plot <- plot_grid(top_row, PC1_variables_combined_plot1, rel_heights = c(0.1, 1), rel_widths = c(1, 1), labels = c("PC1 (17.2% of total variance)", ""), label_size = 25, label_x = -0.15, align = "hv", nrow = 2) -->
<!-- PC1_variables_combined_plot -->
<!-- ggsave(plot = PC1_variables_combined_plot, filename = "Figures/PC1_plot_variables_combined.png", width = 15, height = 7, dpi = 600) -->
<!-- #PC2 -->
<!-- PC2_variables_combined_plot1 <- plot_grid(NULL, plot_grid(top_row, PC2_contrib_plot, nrow = 2, rel_heights = c(0.065, 1)), NULL, mod_pred_PC2_values_vowel_plot, rel_widths = c(0.03, 0.6, 0.03, 0.6), rel_heights = c(0.03, 0.6, 0.03, 0.4), labels = c("A", "", "B", ""), label_size = 25, nrow = 1, ncol = 5) -->
<!-- PC2_variables_combined_plot <- plot_grid(top_row, PC2_variables_combined_plot1, rel_heights = c(0.1, 1), rel_widths = c(1, 1), labels = c("PC2 (15.8% of total variance)", ""), label_size = 25, label_x = -0.15, align = "hv", nrow = 2) -->
<!-- PC2_variables_combined_plot -->
<!-- ggsave(plot = PC2_variables_combined_plot, filename = "Figures/PC2_plot_variables_combined.png", width = 15, height = 7, dpi = 600) -->
<!-- #PC3 -->
<!-- PC3_variables_combined_plot1 <- plot_grid(NULL, plot_grid(top_row, PC3_contrib_plot, nrow = 2, rel_heights = c(0.065, 1)), NULL, mod_pred_PC3_values_vowel_plot, rel_widths = c(0.03, 0.6, 0.03, 0.6), rel_heights = c(0.03, 0.6, 0.03, 0.4), labels = c("A", "", "B", ""), label_size = 25, nrow = 1, ncol = 5) -->
<!-- PC3_variables_combined_plot <- plot_grid(top_row, PC3_variables_combined_plot1, rel_heights = c(0.1, 1), rel_widths = c(1, 1), labels = c("PC3 (10.1% of total variance)", ""), label_size = 25, label_x = -0.15, align = "hv", nrow = 2) -->
<!-- PC3_variables_combined_plot -->
<!-- ggsave(plot = PC3_variables_combined_plot, filename = "Figures/PC3_plot_variables_combined.png", width = 15, height = 7, dpi = 600) -->
<!-- ``` -->
</div>
</div>
<div id="additional-analyses" class="section level1">
<h1>Additional analyses</h1>
<div id="mixed-effects-modelling" class="section level2">
<h2>Mixed-effects modelling</h2>
<p>An alternative approach to obtaining the speaker intercepts would be to use linear mixed-effects modelling. This is done using the <code>lme4</code> package, if you are unfamiliar with this form of regression analysis, an introductory tutorial <a href="https://arxiv.org/abs/1308.5499">Winter, 2013</a> can be found <a href="http://www.bodowinter.com/tutorial/bw_LME_tutorial1.pdf">here for part 1</a> and <a href="http://www.bodowinter.com/tutorial/bw_LME_tutorial2.pdf">here for part 2</a>, for further information about why we chose the by-speaker intercepts, please refer to the manuscript or see <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/6B661A6226E015A613AB22616C9C2300/S0954394512000014a.pdf/exploiting_random_intercepts_two_case_studies_in_sociophonetics.pdf">Drager and Hay (2012)</a></p>
<p>We will generate the intercepts and visually see if there is a strong linear relationship between the intercepts generated from the GAMMs.</p>
<p>Note, this was our original approach taken to the analysis, we decided however that the GAMMs were the most suitable approach given our dataset. We include the following code below for those interested in using linear mixed-effects models.</p>
<div id="fitting-procedure-1" class="section level3">
<h3>Fitting procedure</h3>
<p>The fitting procedure is identical to that used in the GAMMs analysis.</p>
<p>All models will be fit uniformly, i.e. with the same fixed and random effects structures (note, we model the year of birth variable non-linearly, this is done with a restricted cubic spline with 4 knots, see <a href="https://towardsdatascience.com/restricted-cubic-splines-c0617b07b9a5">here</a> for more information about what this means).</p>
<p>Note this process takes ~4 minutes to complete.</p>
<pre class="r"><code>#create a data frame to store the intercepts from the models, this will initially contain just the speaker names
lmer_intercepts.tmp &lt;- vowels_all %&gt;%
  select(Speaker) %&gt;%
  arrange(Speaker) %&gt;%
  distinct()

#loop through the vowels

for (i in levels(factor(vowels_all$Vowel))) {

  cat(paste0(i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F1 for FLEECE
  lmer.F1 &lt;- lmer(F1_lobanov_2.0 ~
                  scale(rcs(participant_year_of_birth, 4))*Gender +
                  Speech_rate +
                  (1|Speaker) +
                  (1|Word),
                data = vowels_all,
                subset = Vowel == i)

  #extract the speaker intercepts from the model and store them in a temporary data frame
  lmer.F1.intercepts.tmp &lt;- ranef(lmer.F1)[[&quot;Speaker&quot;]]

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F2 for FLEECE
  lmer.F2 &lt;- lmer(F2_lobanov_2.0 ~
                  scale(rcs(participant_year_of_birth, 4))*Gender +
                  Speech_rate +
                  (1|Speaker) +
                  (1|Word),
                data = vowels_all,
                subset = Vowel == i)

  #extract the speaker intercepts again, storing them in a separate data frame
  lmer.F2.intercepts.tmp &lt;- ranef(lmer.F2)[[&quot;Speaker&quot;]]

  #rename the variables so it clear which one has F1/F2, i.e. this will give F1_FLEECE, F2_FLEECE
  names(lmer.F1.intercepts.tmp) &lt;- paste0(&quot;F1_&quot;, i)
  names(lmer.F2.intercepts.tmp) &lt;- paste0(&quot;F2_&quot;, i)

  #combine the intercepts for F1 and F2 and store them in the intercepts.tmp_stress data frame
  lmer_intercepts.tmp &lt;- cbind(lmer_intercepts.tmp, lmer.F1.intercepts.tmp, lmer.F2.intercepts.tmp)
}

write.csv(lmer_intercepts.tmp, &quot;Data/lmer_intercepts.csv&quot;, row.names = FALSE)</code></pre>
<p>Load in the lmer intercepts</p>
<pre class="r"><code>lmer_intercepts.tmp &lt;- read.csv(&quot;Data/lmer_intercepts.csv&quot;)</code></pre>
</div>
<div id="comparison-with-gamms" class="section level3">
<h3>Comparison with GAMMs</h3>
<p>Visualise the GAMM intercepts with the lmer intercepts</p>
<pre class="r"><code>lmer_intercepts.tmp_F1 &lt;- lmer_intercepts.tmp %&gt;%
  select(Speaker, contains(&quot;F1&quot;)) %&gt;%
  pivot_longer(-Speaker, names_to = &quot;F_variable&quot;, values_to = &quot;F1_lmer_intercept&quot;) %&gt;%
  mutate(Vowel = gsub(&quot;F1_&quot;, &quot;&quot;, F_variable))

gam_intercepts.tmp_F1 &lt;- gam_intercepts.tmp %&gt;%
  select(Speaker, contains(&quot;F1&quot;)) %&gt;%
  pivot_longer(-Speaker, names_to = &quot;F_variable&quot;, values_to = &quot;F1_GAMM_intercept&quot;) %&gt;%
  mutate(Vowel = gsub(&quot;F1_&quot;, &quot;&quot;, F_variable))

gam_intercepts.tmp_F1 %&gt;%
  left_join(., lmer_intercepts.tmp_F1) %&gt;%
  ggplot(aes(x = F1_GAMM_intercept, y = F1_lmer_intercept, colour = Vowel)) +
  geom_point(size = 0.5, show.legend = FALSE) +
  facet_wrap(~Vowel) +
  theme_bw()</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-53-1.png" width="2100" /></p>
<pre class="r"><code>lmer_intercepts.tmp_F2 &lt;- lmer_intercepts.tmp %&gt;%
  select(Speaker, contains(&quot;F2&quot;)) %&gt;%
  pivot_longer(-Speaker, names_to = &quot;F_variable&quot;, values_to = &quot;F2_lmer_intercept&quot;) %&gt;%
  mutate(Vowel = gsub(&quot;F2_&quot;, &quot;&quot;, F_variable))

gam_intercepts.tmp_F2 &lt;- gam_intercepts.tmp %&gt;%
  select(Speaker, contains(&quot;F2&quot;)) %&gt;%
  pivot_longer(-Speaker, names_to = &quot;F_variable&quot;, values_to = &quot;F2_GAMM_intercept&quot;) %&gt;%
  mutate(Vowel = gsub(&quot;F2_&quot;, &quot;&quot;, F_variable))

gam_intercepts.tmp_F2 %&gt;%
  left_join(., lmer_intercepts.tmp_F2) %&gt;%
  ggplot(aes(x = F2_GAMM_intercept, y = F2_lmer_intercept, colour = Vowel)) +
  geom_point(size = 0.5, show.legend = FALSE) +
  facet_wrap(~Vowel) +
  theme_bw()</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-53-2.png" width="2100" /></p>
</div>
</div>
<div id="ploting-pca-by-loading" class="section level2">
<h2>Ploting PCA by loading</h2>
<p>An alternative to understanding how the variables contribute to each of the PCs is to look at the loadings. These are similiar to the % contribution values we present in the paper, they are widely used in PCA and the larger the absolute value (i.e. either positive or negative) then the more that variable contributes to the PC.</p>
<p>In the plots below, we present the absolute loading on the y axis, the red dashed line (which is located through y = square root of 0.05, approximately 0.224) gives the baseline where all loadings would be if they contributed equally to the PC.</p>
<pre class="r"><code>PC1_loadings_plot &lt;- ggplot(PC1_contrib, aes(x=reorder(Variable, Loading_abs), y=Loading_abs)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC1_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC1_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC1 loading (absolute)&quot;) +
  geom_hline(yintercept = sqrt(0.05), color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_y_continuous(breaks = seq(0, 0.4, 0.1), limits = c(0, 0.4)) +
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC1_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC2_loadings_plot &lt;- ggplot(PC2_contrib, aes(x=reorder(Variable, Loading_abs), y=Loading_abs)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC2_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC2_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC2 loading (absolute)&quot;) +
  geom_hline(yintercept = sqrt(0.05), color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_y_continuous(breaks = seq(0, 0.4, 0.1), limits = c(0, 0.4)) +
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC2_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC3_loadings_plot &lt;- ggplot(PC3_contrib, aes(x=reorder(Variable, Loading_abs), y=Loading_abs)) + #have the variable name on the x axis and loading value on the y
  geom_text(aes(alpha = highlight, label=ifelse(PC3_contrib$direction==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;)), colour = PC3_contrib$direction, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  xlab(&quot;&quot;) + #remove the x axis title
  ylab(&quot;PC3 loading (absolute)&quot;) +
  geom_hline(yintercept = sqrt(0.05), color = &quot;red&quot;, linetype = &quot;dashed&quot;) + #add a red dashed line to identify the 0.2 cut off
  scale_y_continuous(breaks = seq(0, 0.4, 0.1), limits = c(0, 0.4)) +
  scale_alpha_manual(values=c(1, 0.3)) +
  theme_bw() + #set the aesthetics of the plot
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC3_contrib$highlight, size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;),
        axis.title = element_text(size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

#combine the 3 separate PC plots in to one
PC_loadings &lt;- plot_grid(NULL, PC1_loadings_plot, PC2_loadings_plot, PC3_loadings_plot, labels = c(&quot;&quot;, &quot;PC1 (17.2% variance)&quot;, &quot;PC2 (15.8% variance)&quot;, &quot;PC3 (10.1% variance)&quot;), label_y = 1.04, rel_heights = c(0.1, 1, 1, 1), nrow = 4)

#view the plot
PC_loadings</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-54-1.png" width="1500" /></p>
<pre class="r"><code>ggsave(plot = plot_grid(NULL, PC1_loadings_plot, PC2_loadings_plot, PC3_loadings_plot, labels = c(&quot;&quot;, &quot;PC1 (17.2% variance)&quot;, &quot;PC2 (15.8% variance)&quot;, &quot;PC3 (10.1% variance)&quot;), label_x = -0.17, label_y = 1.05, rel_heights = c(0.1, 1, 1, 1), nrow = 4), filename = &quot;Figures/PC_loadings.png&quot;, dpi = 600, height = 12, width = 5)</code></pre>
</div>
<div id="pcs-by-cumulative-contribution" class="section level2">
<h2>PCs by cumulative contribution</h2>
<p>Another, more clear way to visualise how the variables contribute to the PCs is to show the cumulative proportions as the y axis variable. This is done to highlight that only a certain number of variables actually contribute a large amount of the explained variance. We will take a 50% cumulative contribution baseline to show which variables actually contribute a lot to each of the PCs.</p>
<pre class="r"><code>PC1_loadings_contrib1 &lt;- PC_loadings_contrib %&gt;%
  filter(PC == &quot;Loading.PC1&quot;) %&gt;%
  arrange(Contribution.PC1) %&gt;%
  # group_by(Variable) %&gt;%
  mutate(cumsum_PC1 = round(cumsum(Contribution.PC1), 4),
         highlight = ifelse(cumsum_PC1 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC1 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))

PC1_loadings_contrib1_plot &lt;- PC1_loadings_contrib1 %&gt;%
  ggplot(aes(x = fct_reorder(Variable, cumsum_PC1), y = cumsum_PC1, label=direction_lab, colour = direction1)) +
  # geom_point() +
  geom_text(alpha = PC1_loadings_contrib1$highlight1, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) +
  geom_vline(xintercept = 16.5, colour = &quot;red&quot;, linetype = 2) +
  xlab(&quot;&quot;) +
  ylab(&quot;Cumulative sum contribution %\n(PC1)&quot;) +
  # facet_grid(PC~.) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC1_loadings_contrib1$highlight, size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC2_loadings_contrib1 &lt;- PC_loadings_contrib %&gt;%
  filter(PC == &quot;Loading.PC2&quot;) %&gt;%
  arrange(Contribution.PC2) %&gt;%
  # group_by(Variable) %&gt;%
  mutate(cumsum_PC2 = round(cumsum(Contribution.PC2), 4),
         highlight = ifelse(cumsum_PC2 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC2 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))

PC2_loadings_contrib1_plot &lt;- PC2_loadings_contrib1 %&gt;%
  ggplot(aes(x = fct_reorder(Variable, cumsum_PC2), y = cumsum_PC2, label=direction_lab, colour = direction1)) +
  # geom_point() +
  geom_text(alpha = PC2_loadings_contrib1$highlight1, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) +
  geom_vline(xintercept = 14.5, colour = &quot;red&quot;, linetype = 2) +
  xlab(&quot;&quot;) +
  ylab(&quot;Cumulative sum contribution %\n(PC2)&quot;) +
  # facet_grid(PC~.) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC2_loadings_contrib1$highlight, size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC3_loadings_contrib1 &lt;- PC_loadings_contrib %&gt;%
  filter(PC == &quot;Loading.PC3&quot;) %&gt;%
  arrange(Contribution.PC3) %&gt;%
  # group_by(Variable) %&gt;%
  mutate(cumsum_PC3 = round(cumsum(Contribution.PC3), 4),
         highlight = ifelse(cumsum_PC3 &lt; 50, &quot;grey&quot;, &quot;black&quot;),
         highlight1 = ifelse(cumsum_PC3 &lt; 50, 0.5, 1),
         direction1 = direction,
         direction_lab = ifelse(direction1==&quot;red&quot;,&quot;–&quot;, &quot;+&quot;))

PC3_loadings_contrib1_plot &lt;- PC3_loadings_contrib1 %&gt;%
  ggplot(aes(x = fct_reorder(Variable, cumsum_PC3), y = cumsum_PC3, label=direction_lab, colour = direction1)) +
  # geom_point() +
  geom_text(alpha = PC3_loadings_contrib1$highlight1, size = 6, fontface=&quot;bold&quot;, show.legend = FALSE) +
  scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) +
  geom_vline(xintercept = 16.5, colour = &quot;red&quot;, linetype = 2) +
  xlab(&quot;&quot;) +
  ylab(&quot;Cumulative sum contribution %\n(PC3)&quot;) +
  # facet_grid(PC~.) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, colour = PC3_loadings_contrib1$highlight, size = 14, face = &quot;bold&quot;)) #modify the x axis variable names so they are rotated and highlighted

PC_loadings_contrib1 &lt;- plot_grid(NULL, PC1_loadings_contrib1_plot, NULL, PC2_loadings_contrib1_plot, NULL, PC3_loadings_contrib1_plot, labels = c(&quot;PC1&quot;, &quot;&quot;, &quot;PC2&quot;, &quot;&quot;, &quot;PC3&quot;, &quot;&quot;), rel_heights = c(0.2, 1, 0.2, 1, 0.2, 1), label_size = 14, nrow = 6)

PC_loadings_contrib1</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-55-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC_loadings_contrib1, filename = &quot;Figures/PC_loadings_contrib1.png&quot;, width = 6, height = 14, dpi = 300)</code></pre>
</div>
</div>
<div id="previous-pc-scores-analysis" class="section level1">
<h1>Previous PC scores analysis</h1>
<p>Originally we modelled the PC scores based on GAMM models, where F1 and F2 values were predicted by the PC scores for each of the 3 PCs. We chose not to focus on this approach in the manuscript as PCA finds linear relationships, not non-linear relationships that GAMM models are suited to. We inlcude the following section for reference. The patterns are similar to the ones reported in the manuscript.</p>
<div id="pc1" class="section level2">
<h2>PC1</h2>
<div id="gamm-modelling-1" class="section level3">
<h3>GAMM modelling</h3>
<p>We will predict the F1 and F2 of each of the vowels again using GAMMs, with <code>Comp.1</code> (the PCA scores for PC1) included as a smooth term. There are also random effects for <code>Speaker</code> and <code>word</code>.</p>
<p>These models are saved in the <code>model_summaries</code> folder for efficiency.</p>
<pre class="r"><code>#loop through the vowels
for (i in levels(factor(vowels_all$Vowel))) {

  #F1 modelling
  cat(paste0(&quot;F1_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to for F1, as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F1 for FLEECE
  gam.F1 &lt;- bam(F1_lobanov_2.0 ~
                  s(Comp.1, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F1_&quot;, i), gam.F1)

  #save the model summary
  saveRDS(gam.F1, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC1/gam_F1_&quot;, i, &quot;.rds&quot;))

  #F2 modelling
  cat(paste0(&quot;F2_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;)) #print the vowel the loop is up to for F2 , as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F2 for FLEECE
  gam.F2 &lt;- bam(F2_lobanov_2.0 ~
                  s(Comp.1, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F2_&quot;, i), gam.F2)

  #save the model summary
  saveRDS(gam.F2, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC1/gam_F2_&quot;, i, &quot;.rds&quot;))

}</code></pre>
</div>
<div id="visualisation-by-gam-smooth-1" class="section level3">
<h3>Visualisation by GAM smooth</h3>
<ul>
<li><p>x axis = PCA score</p></li>
<li><p>y axis = normalised F1/F2</p></li>
<li><p>smoothed lines = GAM fit</p></li>
</ul>
<pre class="r"><code>mod_pred_PC1_values &lt;- readRDS(&quot;Data/Models/mod_pred_PC1_values.rds&quot;)</code></pre>
<pre class="r"><code>#get means for each speaker per vowel and formant
PC1_change_summary &lt;- vowels_all %&gt;%
  group_by(Speaker, Comp.1, Vowel) %&gt;%
  dplyr::summarise(n = n(),
                   F1 = mean(F1_lobanov_2.0),
                   F2 = mean(F2_lobanov_2.0),
                   sd_F1 = sd(F1_lobanov_2.0),
                   sd_F2 = sd(F2_lobanov_2.0)) %&gt;%
  ungroup() %&gt;%
  pivot_longer(F1:F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;)

#plot the gam smooths predicting F1/F2 per vowel and add the per speaker mean values
PC1_plot_smooth &lt;- mod_pred_PC1_values %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = -Comp.1, y = fit, colour = Formant, fill = Formant)) +
  geom_point(data = PC1_change_summary %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), size = 0.25, alpha = 0.1) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.2, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4)) +
  xlab(&quot;PC1 score&quot;) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

PC1_plot_smooth</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-59-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC1_plot_smooth, filename = &quot;Figures/PC1_plot_gam.png&quot;, width = 10, height = 5, dpi = 300)</code></pre>
</div>
<div id="visualisation-in-f1f2-space-2" class="section level3">
<h3>Visualisation in F1/F2 space</h3>
<ul>
<li><p>x axis = F2</p></li>
<li><p>y axis = F1</p></li>
<li><p>colours = lexical set of vowel</p></li>
<li><p>lines = trajectory of the F1/F2 in terms of PCA score (-5.5 to 6.5)</p></li>
<li><p>vowel labels = start point of the vowel trajectory (smallest PCA score: -5.5)</p></li>
<li><p>vowel label size = magnitude of variable loading, this is calculated from the dot plots from the original PCA, as there are 2 possible loadings (one for F1 and one for F2), the largest value is taken to represent the size</p></li>
<li><p>arrows = end point of the trajectory (largest PCA score: 6.5)</p></li>
</ul>
<pre class="r"><code>#transform data so there are separate columns for F1 and F2
PC1_plot_data &lt;- mod_pred_PC1_values %&gt;%
  select(Comp.1, fit, Vowel, Formant) %&gt;%
  mutate(Comp.1 = -Comp.1) %&gt;%
  pivot_wider(names_from = Formant, values_from = fit) %&gt;% #transform the data to wide format so there are separate F1 and F2 variables
  left_join(., PC1_loadings %&gt;%
  group_by(Vowel) %&gt;%
  filter(PC1_loadings_abs == max(PC1_loadings_abs)))

#make data frame to plot starting point, this will give the vowel labels based on the smallest PCA scores
PC1_change_labels1 &lt;- PC1_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  filter(Comp.1 == min(Comp.1))

#make data frame to plot end point, this will give the arrow at the end of the paths based on the largest year of birth coordinates
PC1_change_labels2 &lt;- PC1_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  top_n(wt = Comp.1, n = 2)

#plot
PC1_change_plot &lt;- PC1_plot_data %&gt;%
  mutate(PC1_loadings_abs = PC1_loadings_abs) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, alpha = Comp.1, group = Vowel)) +
  #plot the vowel labels
  geom_text(data = PC1_change_labels1, aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel, size = PC1_loadings_abs), inherit.aes = FALSE, show.legend = FALSE) +
  #add year of birth change trajectories
  geom_path(size = 0.5, show.legend = FALSE) +
  #add end points (this gives the arrows)
  geom_path(data = PC1_change_labels2, aes(x = F2, y = F1, colour = Vowel, group = Vowel),
            arrow = arrow(ends = &quot;first&quot;, type = &quot;closed&quot;, length = unit(0.2, &quot;cm&quot;)),
            inherit.aes = FALSE, show.legend = FALSE) +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #scale the size so the path is not too wide
  scale_size_continuous(range = c(1,5)) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2.5), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #add a title
  # labs(title = &quot;B) Change in PC1\n     variance explained = 17.1%&quot;) +
  #set the theme
  theme_bw() +
  #make title bold
  theme(plot.title = element_text(face=&quot;bold&quot;))

PC1_change_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-60-1.png" width="1200" /></p>
<pre class="r"><code># ggsave(plot = PC1_change_plot, filename = &quot;Figures/PC1_plot_static.png&quot;, width = 5.5, height = 5.5, dpi = 300)</code></pre>
</div>
<div id="visualisation-by-animation-1" class="section level3">
<h3>Visualisation by animation</h3>
<ul>
<li><p>x axis = F2</p></li>
<li><p>y axis = F1</p></li>
<li><p>colours = lexical set of vowel</p></li>
<li><p>movement = trajectory of the F1/F2 in terms PCA score</p></li>
<li><p>trails = the previous positions of the vowels</p></li>
</ul>
<pre class="r"><code>PC1_plot_animation &lt;- PC1_plot_data %&gt;%
  arrange(Comp.1) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel)) +
  geom_text(aes(size = PC1_loadings_abs, fontface = 2), show.legend = FALSE) +
  # geom_point() +
  geom_path() +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2.8), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #set the label size
  scale_size_continuous(range = c(1,5)) +
  #add a title
  labs(caption = &#39;PC1 score: {round(frame_along, 2)}&#39;) +
  #set the theme
  theme_bw() +
  #make text more visible
  theme(axis.title = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.x = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;, angle = 270),
        axis.ticks = element_blank(),
        plot.caption = element_text(size = 30, hjust = 0),
        legend.position = &quot;none&quot;) +
  #set the variable for the animation transition i.e. the time dimension
  transition_reveal(Comp.1)

animate(PC1_plot_animation, nframes = 200, fps = 5, rewind = FALSE, start_pause = 10, end_pause = 10, duration = 20)

# anim_save(&quot;Figures/PC1_animation.gif&quot;)

PC1_plot_animation</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-61-1.gif" /><!-- --></p>
</div>
</div>
<div id="pc2" class="section level2">
<h2>PC2</h2>
<div id="gamm-modelling-2" class="section level3">
<h3>GAMM modelling</h3>
<pre class="r"><code>#loop through the vowels
for (i in levels(factor(vowels_all$Vowel))) {

  #F1 modelling
  cat(paste0(&quot;F1_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to for F1, as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F1 for FLEECE
  gam.F1 &lt;- bam(F1_lobanov_2.0 ~
                  s(Comp.2, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F1_&quot;, i), gam.F1)

  #save the model summary
  saveRDS(gam.F1, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC2/gam_F1_&quot;, i, &quot;.rds&quot;))

  #F2 modelling
  cat(paste0(&quot;F2_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to for F2 , as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F2 for FLEECE
  gam.F2 &lt;- bam(F2_lobanov_2.0 ~
                  s(Comp.2, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F2_&quot;, i), gam.F2)

  #save the model summary
  saveRDS(gam.F2, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC2/gam_F2_&quot;, i, &quot;.rds&quot;))

}</code></pre>
</div>
<div id="visualisation-by-gam-smooth-2" class="section level3">
<h3>Visualisation by GAM smooth</h3>
<pre class="r"><code>mod_pred_PC2_values &lt;- readRDS(&quot;Data/Models/mod_pred_PC2_values.rds&quot;)</code></pre>
<pre class="r"><code>#get means for each speaker per vowel and formant
PC2_change_summary &lt;- vowels_all %&gt;%
  group_by(Speaker, Comp.2, Vowel) %&gt;%
  dplyr::summarise(n = n(),
                   F1 = mean(F1_lobanov_2.0),
                   F2 = mean(F2_lobanov_2.0),
                   sd_F1 = sd(F1_lobanov_2.0),
                   sd_F2 = sd(F2_lobanov_2.0)) %&gt;%
  ungroup() %&gt;%
  pivot_longer(F1:F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;)

#plot the gam smooths predicting F1/F2 per vowel and add the per speaker mean values
PC2_plot_smooth &lt;- mod_pred_PC2_values %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = -Comp.2, y = fit, colour = Formant, fill = Formant)) +
  geom_point(data = PC2_change_summary %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), size = 0.25, alpha = 0.1) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.2, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4)) +
  xlab(&quot;PC2 score&quot;) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

PC2_plot_smooth</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-65-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC2_plot_smooth, filename = &quot;Figures/PC2_plot_gam.png&quot;, width = 10, height = 5, dpi = 300)</code></pre>
</div>
<div id="visualisation-in-f1f2-space-3" class="section level3">
<h3>Visualisation in F1/F2 space</h3>
<pre class="r"><code>#transform data so there are separate columns for F1 and F2
PC2_plot_data &lt;- mod_pred_PC2_values %&gt;%
  select(Comp.2, fit, Vowel, Formant) %&gt;%
  mutate(Comp.2 = -Comp.2) %&gt;%
  pivot_wider(names_from = Formant, values_from = fit) %&gt;% #transform the data to wide format so there are separate F1 and F2 variables
  left_join(., PC2_loadings %&gt;%
  group_by(Vowel) %&gt;%
  filter(PC2_loadings_abs == max(PC2_loadings_abs)))

#make data frame to plot starting point, this will give the vowel labels based on the smallest PCA scores
PC2_change_labels1 &lt;- PC2_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  filter(Comp.2 == min(Comp.2))

#make data frame to plot end point, this will give the arrow at the end of the paths based on the largest year of birth coordinates
PC2_change_labels2 &lt;- PC2_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  top_n(wt = Comp.2, n = 2)

#plot
PC2_change_plot &lt;- PC2_plot_data %&gt;%
  mutate(PC2_loadings_abs = PC2_loadings_abs) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, alpha = Comp.2, group = Vowel)) +
  #plot the vowel labels
  geom_text(data = PC2_change_labels1, aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel, size = PC2_loadings_abs), inherit.aes = FALSE, show.legend = FALSE) +
  #add year of birth change trajectories
  geom_path(size = 0.5, show.legend = FALSE) +
  #add end points (this gives the arrows)
  geom_path(data = PC2_change_labels2, aes(x = F2, y = F1, colour = Vowel, group = Vowel),
            arrow = arrow(ends = &quot;first&quot;, type = &quot;closed&quot;, length = unit(0.2, &quot;cm&quot;)),
            inherit.aes = FALSE, show.legend = FALSE) +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #scale the size so the path is not too wide
  scale_size_continuous(range = c(1,5)) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2.5), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #add a title
  # labs(title = &quot;B) Change in PC2\n     variance explained = 17.1%&quot;) +
  #set the theme
  theme_bw() +
  #make title bold
  theme(plot.title = element_text(face=&quot;bold&quot;))

PC2_change_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-66-1.png" width="1200" /></p>
<pre class="r"><code># ggsave(plot = PC2_change_plot, filename = &quot;Figures/PC2_plot_static.png&quot;, width = 5.5, height = 5.5, dpi = 300)</code></pre>
</div>
<div id="visualisation-by-animation-2" class="section level3">
<h3>Visualisation by animation</h3>
<pre class="r"><code>PC2_plot_animation &lt;- PC2_plot_data %&gt;%
  arrange(Comp.2) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel)) +
  geom_text(aes(fontface = 2, size = PC2_loadings_abs), show.legend = FALSE) +
  geom_step() +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #set the label size
  scale_size_continuous(range = c(1,5)) +
  #add a title
  labs(caption = &#39;PC2 score: {round(frame_along, 2)}&#39;) +
  #set the theme
  theme_bw() +
  #make text more visible
  theme(axis.title = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.x = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;, angle = 270),
        axis.ticks = element_blank(),
        plot.caption = element_text(size = 30, hjust = 0),
        legend.position = &quot;none&quot;) +
  #set the variable for the animation transition i.e. the time dimension
  transition_reveal(Comp.2) +
  #add in a trail to see the path
  # shadow_trail(max_frames = 100, alpha = 0.1) +
  ease_aes(&#39;linear&#39;)

animate(PC2_plot_animation, nframes = 200, fps = 5, rewind = FALSE, start_pause = 10, end_pause = 10, duration = 20)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-67-1.gif" /><!-- --></p>
<pre class="r"><code># anim_save(&quot;Figures/PC2_animation.gif&quot;)</code></pre>
</div>
</div>
<div id="pc3" class="section level2">
<h2>PC3</h2>
<div id="gamm-modelling-3" class="section level3">
<h3>GAMM modelling</h3>
<pre class="r"><code>for (i in levels(factor(vowels_all$Vowel))) {

  #F1 modelling
  cat(paste0(&quot;F1_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to for F1, as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F1 for FLEECE
  gam.F1 &lt;- bam(F1_lobanov_2.0 ~
                  s(Comp.3, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F1_&quot;, i), gam.F1)

  #save the model summary
  saveRDS(gam.F1, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC3/gam_F1_&quot;, i, &quot;.rds&quot;))

  #F2 modelling
  cat(paste0(&quot;F2_&quot;, i, &quot;: &quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;), &quot; ✅\n&quot;))  #print the vowel the loop is up to for F2 , as well as the start time for the model

  #run the mixed-effects model on the vowel, i.e. if i = FLEECE this will model F2 for FLEECE
  gam.F2 &lt;- bam(F2_lobanov_2.0 ~
                  s(Comp.3, k = 10) +
                  s(Speaker, bs=&quot;re&quot;) +
                  s(Word, bs=&quot;re&quot;),
                data=vowels_all %&gt;% filter(Vowel == i),
                discrete=T, nthreads=2)

  #store the model
  assign(paste0(&quot;gam_F2_&quot;, i), gam.F2)

  #save the model summary
  saveRDS(gam.F2, file = paste0(&quot;/Users/james/Documents/GitHub/model_summaries/PC3/gam_F2_&quot;, i, &quot;.rds&quot;))

}</code></pre>
</div>
<div id="visualisation-by-gam-smooth-3" class="section level3">
<h3>Visualisation by GAM smooth</h3>
<pre class="r"><code>mod_pred_PC3_values &lt;-  readRDS(&quot;Data/Models/mod_pred_PC3_values.rds&quot;)</code></pre>
<pre class="r"><code>#get means for each speaker per vowel and formant
PC3_change_summary &lt;- vowels_all %&gt;%
  group_by(Speaker, Comp.3, Vowel) %&gt;%
  dplyr::summarise(n = n(),
                   F1 = mean(F1_lobanov_2.0),
                   F2 = mean(F2_lobanov_2.0),
                   sd_F1 = sd(F1_lobanov_2.0),
                   sd_F2 = sd(F2_lobanov_2.0)) %&gt;%
  ungroup() %&gt;%
  pivot_longer(F1:F2, names_to = &quot;Formant&quot;, values_to = &quot;fit&quot;)

#plot the gam smooths predicting F1/F2 per vowel and add the per speaker mean values
PC3_plot_smooth &lt;- mod_pred_PC3_values %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = -Comp.3, y = fit, colour = Formant, fill = Formant)) +
  geom_point(data = PC3_change_summary %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), size = 0.25, alpha = 0.1) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.2, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4)) +
  xlab(&quot;PC3 score&quot;) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;))

PC3_plot_smooth</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-71-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC3_plot_smooth, filename = &quot;Figures/PC3_plot_gam.png&quot;, width = 10, height = 5, dpi = 300)</code></pre>
</div>
<div id="visualisation-in-f1f2-space-4" class="section level3">
<h3>Visualisation in F1/F2 space</h3>
<pre class="r"><code>#extract the smoothed values from the plot and store them
#transform data so there are separate columns for F1 and F2
PC3_plot_data &lt;- mod_pred_PC3_values %&gt;%
  select(Comp.3, fit, Vowel, Formant) %&gt;%
  mutate(Comp.3 = -Comp.3) %&gt;%
  pivot_wider(names_from = Formant, values_from = fit) %&gt;% #transform the data to wide format so there are separate F1 and F2 variables
  left_join(., PC3_loadings %&gt;%
  group_by(Vowel) %&gt;%
  filter(PC3_loadings_abs == max(PC3_loadings_abs)))

#make data frame to plot starting point, this will give the vowel labels based on the smallest PCA scores
PC3_change_labels1 &lt;- PC3_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  filter(Comp.3 == min(Comp.3))

#make data frame to plot end point, this will give the arrow at the end of the paths based on the largest year of birth coordinates
PC3_change_labels2 &lt;- PC3_plot_data %&gt;%
  group_by(Vowel) %&gt;%
  top_n(wt = Comp.3, n = 2)

#plot
PC3_change_plot &lt;- PC3_plot_data %&gt;%
  mutate(PC3_loadings_abs = PC3_loadings_abs) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, alpha = Comp.3, group = Vowel)) +
  #plot the vowel labels
  geom_text(data = PC3_change_labels1, aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel, size = PC3_loadings_abs), inherit.aes = FALSE, show.legend = FALSE) +
  #add year of birth change trajectories
  geom_path(size = 0.5, show.legend = FALSE) +
  #add end points (this gives the arrows)
  geom_path(data = PC3_change_labels2, aes(x = F2, y = F1, colour = Vowel, group = Vowel),
            arrow = arrow(ends = &quot;first&quot;, type = &quot;closed&quot;, length = unit(0.2, &quot;cm&quot;)),
            inherit.aes = FALSE, show.legend = FALSE) +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #scale the size so the path is not too wide
  scale_size_continuous(range = c(1,5)) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2.5), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #add a title
  # labs(title = &quot;B) Change in PC3\n     variance explained = 17.1%&quot;) +
  #set the theme
  theme_bw() +
  #make title bold
  theme(plot.title = element_text(face=&quot;bold&quot;))

PC3_change_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-72-1.png" width="1200" /></p>
<pre class="r"><code># ggsave(plot = PC3_change_plot, filename = &quot;Figures/PC3_plot_static.png&quot;, width = 5.5, height = 5.5, dpi = 300)</code></pre>
<p><strong>Visualisation by animation</strong></p>
<pre class="r"><code>PC3_plot_animation &lt;- PC3_plot_data %&gt;%
  arrange(Comp.3) %&gt;%
  #set general aesthetics
  ggplot(aes(x = F2, y = F1, colour = Vowel, group = Vowel, label = Vowel)) +
  geom_text(aes(fontface = 2, size = PC3_loadings_abs), show.legend = FALSE) +
  geom_path() +
  #label the axes
  xlab(&quot;F2 (normalised)&quot;) +
  ylab(&quot;F1 (normalised)&quot;) +
  #reverse the axes to follow conventional vowel plotting
  scale_x_reverse(limits = c(2,-2), position = &quot;top&quot;) +
  scale_y_reverse(limits = c(2.3,-2), position = &quot;right&quot;) +
  #set the colours
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                 &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  #set the label size
  scale_size_continuous(range = c(1,5)) +
  #add a title
  labs(caption = &#39;PC3 score: {round(frame_along, 2)}&#39;) +
  #set the theme
  theme_bw() +
  #make text more visible
  theme(axis.title = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.x = element_text(size = 14, face = &quot;bold&quot;),
        axis.text.y = element_text(size = 14, face = &quot;bold&quot;, angle = 270),
        axis.ticks = element_blank(),
        plot.caption = element_text(size = 30, hjust = 0),
        legend.position = &quot;none&quot;) +
  #set the variable for the animation transition i.e. the time dimension
  transition_reveal(Comp.3) +
  #add in a trail to see the path
  # shadow_trail(max_frames = 100, alpha = 0.1) +
  ease_aes(&#39;linear&#39;)

animate(PC3_plot_animation, nframes = 200, fps = 5, rewind = FALSE, start_pause = 10, end_pause = 10, duration = 20)</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-73-1.gif" /><!-- --></p>
<pre class="r"><code># anim_save(&quot;Figures/PC3_animation.gif&quot;)</code></pre>
</div>
</div>
<div id="comparison-with-sound-change" class="section level2">
<h2>Comparison with sound change</h2>
<p>We can also compare the smooths for the key variables (i.e. contributing &gt; 50% variation) for each PC to the sound change smooths. These plots will use the GAMMs predicting F1/F2 by the PCA scores again,</p>
<p>To do this, we first select the key variables for each PC, filtering the data so only those key variables are visualised.</p>
<p>We then need to take the smooths from the initial GAMMs (i.e. those used to extract the speaker intercepts).</p>
<p>Note, it is important to scale the <code>year_of_birth</code> variable from these models so a comparison can be made with the PC scores. This is done by scaling to a range based on the PC scores, so the earliest year of birth represents the smallest score, whereas the most recent year of birth represents the highest score. This preseves the data and the smooths can be compared, but it simply makes visualisation easier.</p>
<p><strong>PC1</strong></p>
<pre class="r"><code>#select the key vairables from the PCA
mod_pred_PC1_values1 &lt;- mod_pred_PC1_values %&gt;%
  select(Comp.1, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Comp.1 = -Comp.1,
         Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;PC1&quot;,
         participant_year_of_birth = rescale(Comp.1, to = range(mod_pred_PC1_values$participant_year_of_birth))) #rescale the year of birth variable

PC1_contrib &lt;- PC1_contrib %&gt;%
  mutate(Formant = substr(Variable, 1, 2),
         x = ifelse(Formant == &quot;F1&quot;, -3.2, 2.8),
         y = -2.75,
         x1 = ifelse(Vowel != &quot;THOUGHT&quot;, (min(mod_pred_PC1_values1$Comp.1)+max(mod_pred_PC1_values1$Comp.1))/2, x)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC1_max = max(Contribution.PC1)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC1_max)]), ordered=TRUE)) %&gt;%
  group_by(Vowel)

#match the data to the year of birth smooths
mod_pred_yob_values1 &lt;- mod_pred_yob_values %&gt;%
  select(participant_year_of_birth, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;yob&quot;,
         #rescale the year of birth variable
         Comp.1 = rescale(participant_year_of_birth, to = range(mod_pred_PC1_values1$Comp.1))) %&gt;%
  filter(Variable %in% mod_pred_PC1_values1$Variable) %&gt;%
  rbind(mod_pred_PC1_values1) %&gt;% #combine with the PCA scores data
  left_join(., PC1_contrib %&gt;% select(Variable, Contribution.PC1)) %&gt;% #get contribution values
  mutate(Contribution.PC1a = paste0(round(Contribution.PC1, 1), &quot;%&quot;)) %&gt;%
  #reorder the Vowel factor so it is ordered by contribution
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC1_max = max(Contribution.PC1)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC1_max)]), ordered=TRUE)) %&gt;%
  left_join(PC1_contrib %&gt;% select(Variable, cumsum_PC1, highlight))

#plot all model smooths facetted by vowel
PC1_plot_smooth1 &lt;- mod_pred_yob_values1 %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = Comp.1, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() + #smooth line
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) + #confidence intervals
  scale_x_continuous(breaks = c(-4, 0, 4),
                     sec.axis = dup_axis(breaks = c(-2.80243, 2.071311), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC1 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) + #revese the axis so it follows convention
  scale_linetype(name = NULL) + #remove the name (var) from the legend
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(Formant~Vowel) +
  geom_label(data = PC1_contrib %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), aes(x = 0, y = y, label = paste0(round(Contribution.PC1, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw()  +
  theme(legend.position = &quot;top&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC1_plot_smooth1</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-74-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC1_plot_smooth1, filename = &quot;Figures/PC1_yob.png&quot;, width = 11, height = 5, dpi = 300)</code></pre>
<pre class="r"><code>#plot all model smooths facetted by vowel
PC1_plot_smooth_important &lt;- mod_pred_yob_values1 %&gt;%
  filter(highlight == &quot;black&quot;) %&gt;%
  mutate(Vowel = ifelse(Vowel == &quot;THOUGHT&quot;, paste0(Vowel, &quot; (&quot;, Formant, &quot;)&quot;), as.character(Vowel))) %&gt;%
  ggplot(aes(x = Comp.1, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() + #smooth line
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) + #confidence intervals
  scale_x_continuous(breaks = c(-4, 0, 4),
                     sec.axis = dup_axis(breaks = c(-2.80243, 2.071311), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC1 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) + #revese the axis so it follows convention
  scale_linetype(name = NULL) + #remove the name (var) from the legend
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  facet_grid(~Vowel) +
  geom_label(data = PC1_contrib %&gt;% ungroup() %&gt;% filter(highlight == &quot;black&quot;) %&gt;%
  mutate(Vowel = ifelse(Vowel == &quot;THOUGHT&quot;, paste0(Vowel, &quot; (&quot;, Formant, &quot;)&quot;), as.character(Vowel))), aes(x = 0, y = y, label = paste0(round(Contribution.PC1, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw() +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC1_plot_smooth_important</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-75-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC1_plot_smooth_important, filename = &quot;Figures/PC1_yob_important.png&quot;, width = 5, height = 5, dpi = 300)</code></pre>
<p><strong>PC2</strong></p>
<pre class="r"><code>mod_pred_PC2_values2 &lt;- mod_pred_PC2_values %&gt;%
  select(Comp.2, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Comp.2 = -Comp.2,
         Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;PC2&quot;,
         participant_year_of_birth = rescale(Comp.2, to = range(mod_pred_yob_values$participant_year_of_birth)))

PC2_contrib &lt;- PC2_contrib %&gt;%
  mutate(Formant = substr(Variable, 1, 2),
         x = ifelse(Formant == &quot;F1&quot;, -3, 3),
         y = -2.75) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC2_max = max(Contribution.PC2)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC2_max)]), ordered=TRUE)) %&gt;%
  group_by(Vowel)

mod_pred_yob_values2 &lt;- mod_pred_yob_values %&gt;%
  select(participant_year_of_birth, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;yob&quot;,
         Comp.2 = rescale(participant_year_of_birth, to = range(mod_pred_PC2_values2$Comp.2))) %&gt;%
  filter(Variable %in% mod_pred_PC2_values2$Variable) %&gt;%
  rbind(mod_pred_PC2_values2) %&gt;%
  left_join(., PC2_contrib %&gt;% select(Variable, Contribution.PC2)) %&gt;%
  mutate(Contribution.PC2a = paste0(round(Contribution.PC2, 1), &quot;%&quot;)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC2_max = max(Contribution.PC2)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC2_max)]), ordered=TRUE)) %&gt;%
  left_join(PC2_contrib %&gt;% select(Variable, cumsum_PC2, highlight))

#plot all model smooths facetted by vowel
PC2_plot_smooth1 &lt;- mod_pred_yob_values2 %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = Comp.2, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4),
                     sec.axis = dup_axis(breaks = c(-2.103943, 3.018724), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC2 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  scale_linetype(name = NULL) +
  facet_grid(Formant~Vowel) +
  geom_label(data = PC2_contrib %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), aes(x = 0, y = y, label = paste0(round(Contribution.PC2, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw() +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC2_plot_smooth1</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-76-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC2_plot_smooth1, filename = &quot;Figures/PC2_yob.png&quot;, width = 11, height = 5)</code></pre>
<pre class="r"><code>#plot all model smooths facetted by vowel
PC2_plot_smooth1_important &lt;- mod_pred_yob_values2 %&gt;%
  filter(highlight == &quot;black&quot;) %&gt;%
  ggplot(aes(x = Comp.2, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4),
                     sec.axis = dup_axis(breaks = c(-2.103943, 3.018724), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC2 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) +
  ylab(&quot;Predicted model fit (Lobanov 2.0)&quot;) +
  scale_linetype(name = NULL) +
  facet_grid(~Vowel) +
  geom_label(data = PC2_contrib %&gt;% filter(highlight == &quot;black&quot;), aes(x = 0, y = y, label = paste0(round(Contribution.PC2, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw() +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC2_plot_smooth1_important</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-77-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC2_plot_smooth1_important, filename = &quot;Figures/PC2_yob_important.png&quot;, width = 7, height = 5)</code></pre>
<p><strong>PC3</strong></p>
<pre class="r"><code>mod_pred_PC3_values3 &lt;- mod_pred_PC3_values %&gt;%
  select(Comp.3, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Comp.3 = -Comp.3,
         Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;PC3&quot;,
         participant_year_of_birth = rescale(Comp.3, to = range(mod_pred_yob_values$participant_year_of_birth)))

PC3_contrib &lt;- PC3_contrib %&gt;%
  mutate(Formant = substr(Variable, 1, 2),
         x = ifelse(Formant == &quot;F1&quot;, -2.7, 2.7),
         y = -2.75) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC3_max = max(Contribution.PC3)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC3_max)]), ordered=TRUE)) %&gt;%
  group_by(Vowel)

mod_pred_yob_values3 &lt;- mod_pred_yob_values %&gt;%
  select(participant_year_of_birth, fit, ul, ll, Vowel, Formant) %&gt;%
  mutate(Variable = paste0(Formant, &quot;_&quot;, Vowel),
         var = &quot;yob&quot;,
         Comp.3 = rescale(participant_year_of_birth, to = range(mod_pred_PC3_values3$Comp.3))) %&gt;%
  filter(Variable %in% mod_pred_PC3_values3$Variable) %&gt;%
  rbind(mod_pred_PC3_values3) %&gt;%
  left_join(., PC3_contrib %&gt;% select(Variable, Contribution.PC3)) %&gt;%
  mutate(Contribution.PC3a = paste0(round(Contribution.PC3, 1), &quot;%&quot;),
         colour1 = ifelse(grepl(&quot;F1&quot;, Variable), &quot;#F8766D&quot;, &quot;#00BFC4&quot;)) %&gt;%
  group_by(Vowel) %&gt;%
  mutate(Contribution.PC3_max = max(Contribution.PC3)) %&gt;%
  ungroup() %&gt;%
  mutate(Vowel = factor(.$Vowel, levels=unique(.$Vowel[order(.$Contribution.PC3_max)]), ordered=TRUE)) %&gt;%
  left_join(PC3_contrib %&gt;% select(Variable, cumsum_PC3, highlight))

#plot all model smooths facetted by vowel
PC3_plot_smooth1 &lt;- mod_pred_yob_values3 %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))) %&gt;%
  ggplot(aes(x = Comp.3, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4),
                     limits = c(-5, 5),
                     sec.axis = dup_axis(breaks = c(-1.71819, 2.261738), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC3 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) + #revese the axis so it follows convention
  scale_linetype(name = NULL) +
  xlab(&quot;PC3 score&quot;) +
  facet_grid(Formant~Vowel) +
  geom_label(data = PC3_contrib %&gt;%
  mutate(Formant = factor(Formant, levels = c(&quot;F2&quot;, &quot;F1&quot;))), aes(x = 0, y = y, label = paste0(round(Contribution.PC3, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw() +
  theme(legend.position = &quot;top&quot;, axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC3_plot_smooth1</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-78-1.png" width="3000" /></p>
<pre class="r"><code># ggsave(plot = PC3_plot_smooth1, filename = &quot;Figures/PC3_yob.png&quot;, width = 11, height = 5)</code></pre>
<pre class="r"><code>#plot all model smooths facetted by vowel
PC3_plot_smooth1_important &lt;- mod_pred_yob_values3 %&gt;%
  filter(highlight == &quot;black&quot;) %&gt;%
  ggplot(aes(x = Comp.3, y = fit, colour = Formant, fill = Formant, linetype = var)) +
  geom_line() +
  geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 0.1, colour = NA) +
  scale_x_continuous(breaks = c(-4, 0, 4),
                     limits = c(-5, 5),
                     sec.axis = dup_axis(breaks = c(-1.71819, 2.261738), labels = c(1900, 1950), name = &quot;Participant year of birth&quot;),  #add secondary axis for year of birth, this is done by rescaling the loading values to scale of year of birth
                     name = &quot;PC3 score&quot;
                     ) +
  scale_y_reverse(breaks = seq(-2, 2, 1), limits = c(2.5, -2.9)) + #revese the axis so it follows convention
  scale_linetype(name = NULL) +
  xlab(&quot;PC3 score&quot;) +
  facet_grid(~Vowel) +
  geom_label(data = PC3_contrib %&gt;% filter(highlight == &quot;black&quot;), aes(x = 0, y = y, label = paste0(round(Contribution.PC3, 1), &quot;%&quot;), colour = Formant), size = 3, inherit.aes = FALSE, show.legend = FALSE) +
  theme_bw() +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = &quot;bold&quot;), strip.text = element_text(size = 12, face = &quot;bold&quot;)) +
  guides(linetype=guide_legend(override.aes=list(fill=NA)))

PC3_plot_smooth1_important</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-79-1.png" width="2100" /></p>
<pre class="r"><code># ggsave(plot = PC3_plot_smooth1_important, filename = &quot;Figures/PC3_yob_important.png&quot;, width = 6, height = 5)</code></pre>
<div id="combined" class="section level3">
<h3>Combined</h3>
<p>To inspect the variables easily in one plot, we will now put the sound change plots and the PC plots together. This will reproduce <strong>Figure XX</strong>.</p>
<pre class="r"><code>vowel_plots_combined &lt;- plot_grid(sound_change_plot, PC1_change_plot, PC2_change_plot, PC3_change_plot, nrow = 1)

vowel_plots_combined1 &lt;- plot_grid(NULL, NULL, NULL, NULL, nrow = 1, labels=c(&quot;A) Sound change&quot;, &quot;B) PC1: var = 17.2%&quot;, &quot;C) PC2: var = 15.8%&quot;, &quot;D) PC3: var = 10.1%&quot;), hjust = 0, label_size = 20)

vowel_plots_combined &lt;- plot_grid(vowel_plots_combined1, vowel_plots_combined, nrow = 2, rel_heights = c(0.07, 1))

vowel_plots_combined</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-80-1.png" width="5400" /></p>
<pre class="r"><code># ggsave(plot = vowel_plots_combined, filename = &quot;Figures/vowel_plots_combined.png&quot;, width = 20, height = 6, dpi = 300)</code></pre>
</div>
</div>
</div>
<div id="example-speakers" class="section level1">
<h1>Example speakers</h1>
<p>To get an idea of how the vowel spaces of the speakers on the margins differ, i.e. those with the largest absolute PC socres, we can inspect the 12 speakers who have either the largest/smallest PC scores.</p>
<p>First, we will filter the data to focus on these 24 speakers.</p>
<pre class="r"><code>PC_example_test &lt;- vowels_all %&gt;%
  group_by(Speaker, participant_year_of_birth, Gender, Vowel) %&gt;%
  dplyr::summarise(F1_mean = mean(F1_lobanov_2.0),
            F2_mean = mean(F2_lobanov_2.0)) %&gt;%
  left_join(PC_speaker_loadings %&gt;% select(Speaker, Comp.1:Comp.3)) %&gt;%
  left_join(PC1_change_labels1 %&gt;% select(Vowel, PC1_loadings_abs)) %&gt;%
  left_join(PC2_change_labels1 %&gt;% select(Vowel, PC2_loadings_abs)) %&gt;%
  left_join(PC3_change_labels1 %&gt;% select(Vowel, PC3_loadings_abs)) %&gt;%
  ungroup() %&gt;%
  mutate(example_speaker = paste0(Speaker, &quot; (&quot;, participant_year_of_birth, &quot;)&quot;),
         example1_PC1 = ifelse(dense_rank(Comp.1) &lt;= 12, &quot;high&quot;,
                               ifelse(dense_rank(-Comp.1) &lt;= 12, &quot;low&quot;, &quot;normal&quot;)),
         example1_PC2 = ifelse(dense_rank(Comp.2) &lt;= 12, &quot;high&quot;,
                               ifelse(dense_rank(-Comp.2) &lt;= 12, &quot;low&quot;, &quot;normal&quot;)),
         example1_PC3 = ifelse(dense_rank(Comp.3) &lt;= 12, &quot;high&quot;,
                               ifelse(dense_rank(-Comp.3) &lt;= 12, &quot;low&quot;, &quot;normal&quot;)))</code></pre>
<p><strong>PC1</strong></p>
<pre class="r"><code>PC1_example_test_low &lt;- PC_example_test %&gt;%
  filter(example1_PC1 == &quot;low&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC1_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.4, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

PC1_example_test_high &lt;- PC_example_test %&gt;%
  filter(example1_PC1 == &quot;high&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC1_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.4, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

# ggsave(plot = PC1_example_test_low, filename = &quot;Figures/PC1_examples_low.png&quot;, width = 15, height = 15, dpi = 300)
# 
# ggsave(plot = PC1_example_test_high, filename = &quot;Figures/PC1_examples_high.png&quot;, width = 15, height = 15, dpi = 300)

PC1_example_test_high</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-82-1.png" width="4500" /></p>
<pre class="r"><code>PC1_example_test_low</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-82-2.png" width="4500" /></p>
<p><strong>PC2</strong></p>
<pre class="r"><code>PC2_example_test_low &lt;- PC_example_test %&gt;%
  filter(example1_PC2 == &quot;low&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC2_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.4, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

PC2_example_test_high &lt;- PC_example_test %&gt;%
  filter(example1_PC2 == &quot;high&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC2_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.4, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

# ggsave(plot = PC2_example_test_low, filename = &quot;Figures/PC2_examples_low.png&quot;, width = 15, height = 15, dpi = 300)
# 
# ggsave(plot = PC2_example_test_high, filename = &quot;Figures/PC2_examples_high.png&quot;, width = 15, height = 15, dpi = 300)

PC2_example_test_high</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-83-1.png" width="4500" /></p>
<pre class="r"><code>PC2_example_test_low</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-83-2.png" width="4500" /></p>
<p><strong>PC3</strong></p>
<pre class="r"><code>PC3_example_test_low &lt;- PC_example_test %&gt;%
  filter(example1_PC3 == &quot;low&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC3_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.4, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

PC3_example_test_high &lt;- PC_example_test %&gt;%
  filter(example1_PC3 == &quot;high&quot;) %&gt;%
  mutate(example_speaker = factor(.$example_speaker, levels=unique(.$example_speaker[order(.$participant_year_of_birth)]), ordered=TRUE)) %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
  scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
  scale_size_continuous(range = c(2,5)) +
  geom_text(aes(size = PC3_loadings_abs), show.legend = FALSE) +
  scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(2.4, -2.4)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(2.6, -2.4)) +
  theme(plot.title = element_text(size = 20, face = &quot;italic&quot;)) +
  facet_wrap(~factor(example_speaker)) +
  theme_bw()

# ggsave(plot = PC3_example_test_low, filename = &quot;Figures/PC3_examples_low.png&quot;, width = 15, height = 15, dpi = 300)
# 
# ggsave(plot = PC3_example_test_high, filename = &quot;Figures/PC3_examples_high.png&quot;, width = 15, height = 15, dpi = 300)

PC3_example_test_high</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-84-1.png" width="4500" /></p>
<pre class="r"><code>PC3_example_test_low</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-84-2.png" width="4500" /></p>
<div id="speaker-comparisons" class="section level2">
<h2>Speaker comparisons</h2>
<p>To give an impression of how speaker’s with high/low loadings compare in terms of their vowel spaces, we can take 2 examples from each of the PCs. These examples were chosen based on the Shiny app, importantly they are chosen on the basis that they have similar year of birth and the same gender. This shows that irrespective of their demographic information, we can find contrasting speakers in our dataset who exhibit co-variation of the vocalic variables in each of the PCs.</p>
<pre class="r"><code>#make a data frame of the example speakers mean F1 and F2 for each vowel, add in additional information such as PC loading and PCA score
PC_example_data &lt;- vowels_all %&gt;%
  group_by(Speaker, participant_year_of_birth, Gender, Vowel) %&gt;%
  dplyr::summarise(F1_mean = mean(F1_lobanov_2.0),
            F2_mean = mean(F2_lobanov_2.0)) %&gt;%
  left_join(PC_speaker_loadings %&gt;% select(Speaker, Comp.1:Comp.3)) %&gt;%
  left_join(PC1_change_labels1 %&gt;% select(Vowel, PC1_loadings_abs)) %&gt;%
  left_join(PC2_change_labels1 %&gt;% select(Vowel, PC2_loadings_abs)) %&gt;%
  left_join(PC3_change_labels1 %&gt;% select(Vowel, PC3_loadings_abs)) %&gt;%
  ungroup()

PC_example_plot &lt;- PC_example_data %&gt;%
  ggplot(aes(x = F2_mean, y = F1_mean, label = Vowel, colour = Vowel)) +
        scale_color_manual(values = c(&quot;#9590FF&quot;, &quot;#D89000&quot;, &quot;#A3A500&quot;, &quot;#39B600&quot;, &quot;#00BF7D&quot;,
                                      &quot;#00BFC4&quot;, &quot;#00B0F6&quot;, &quot;#F8766D&quot;, &quot;#E76BF3&quot;, &quot;#FF62BC&quot;)) +
        scale_size_continuous(range = c(2,5)) +
        scale_x_reverse(position = &quot;top&quot;, name = &quot;F2 (normalised)&quot;, limits = c(max(PC_example_data$F2_mean) + 0.2, min(PC_example_data$F2_mean) - 0.3)) +
        scale_y_reverse(position = &quot;right&quot;, name = &quot;F1 (normalised)&quot;, limits = c(max(PC_example_data$F1_mean), min(PC_example_data$F1_mean))) +
        xlab(&quot;F2 (normalised&quot;) +
        ylab(&quot;F1 (normalised&quot;) +
        theme_bw() +
        theme(strip.text = element_text(size = 14))</code></pre>
<pre class="r"><code>PC1_example_old &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;IA_f_099&quot;), aes(size = PC1_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;A. Older&quot;, subtitle = &quot;yob: 1922, PC1 score: -0.43&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC1_example_old, filename = &quot;Figures/PC1_example_old.png&quot;, dpi = 300, width = 5, height = 5)

PC1_example_small &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_f_391&quot;), aes(size = PC1_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;A. Low&quot;, subtitle = &quot;yob: 1942, PC1 score: -5.26&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC1_example_small, filename = &quot;Figures/PC1_example_small.png&quot;, dpi = 300, width = 5, height = 5)

PC1_example_large &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_f_052&quot;), aes(size = PC1_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;B. High&quot;, subtitle = &quot;yob: 1942, PC1 score: 3.55&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC1_example_large, filename = &quot;Figures/PC1_example_large.png&quot;, dpi = 300, width = 5, height = 5)

PC1_example_young &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;Darfield_f_612&quot;), aes(size = PC1_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;D. Younger&quot;, subtitle = &quot;yob: 1961, PC1 score: -0.53&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC1_example_young, filename = &quot;Figures/PC1_example_young.png&quot;, dpi = 300, width = 5, height = 5)

PC1_example_speakers_all &lt;- plot_grid(PC1_example_old, PC1_example_small, PC1_example_large, PC1_example_young, nrow = 1)</code></pre>
<pre class="r"><code>PC2_example_old &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;IA_m_077&quot;), aes(size = PC2_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;A. Older&quot;, subtitle = &quot;yob: 1914, PC2 score: 0.58&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC2_example_old, filename = &quot;Figures/PC2_example_old.png&quot;, dpi = 300, width = 5, height = 5)

PC2_example_small &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_m_139&quot;), aes(size = PC2_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;B. Lagger&quot;, subtitle = &quot;yob: 1933, PC2 score: -3.16&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC2_example_small, filename = &quot;Figures/PC2_example_small.png&quot;, dpi = 300, width = 5, height = 5)

PC2_example_large &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_m_406&quot;), aes(size = PC2_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;C. Leader&quot;, subtitle = &quot;yob: 1934, PC2 score: 3.79&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC2_example_large, filename = &quot;Figures/PC2_example_large.png&quot;, dpi = 300, width = 5, height = 5)

PC2_example_young &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_m_461&quot;), aes(size = PC2_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;D. Younger&quot;, subtitle = &quot;yob: 1953, PC2 score: 0.54&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC2_example_young, filename = &quot;Figures/PC2_example_young.png&quot;, dpi = 300, width = 5, height = 5)

PC2_example_speakers_all &lt;- plot_grid(PC2_example_old, PC2_example_small, PC2_example_large, PC2_example_young, nrow = 1)</code></pre>
<pre class="r"><code>PC3_example_old &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;IA_f_333&quot;), aes(size = PC3_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;A. Older&quot;, subtitle = &quot;yob: 1931, PC3 score: 1.23&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC3_example_old, filename = &quot;Figures/PC3_example_old.png&quot;, dpi = 300, width = 5, height = 5)

PC3_example_small &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_f_215&quot;), aes(size = PC3_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;A. Low&quot;, subtitle = &quot;yob: 1950, PC3 score: -3.41&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC3_example_small, filename = &quot;Figures/PC3_example_small.png&quot;, dpi = 300, width = 5, height = 5)

PC3_example_large &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_f_330&quot;), aes(size = PC3_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;B. High&quot;, subtitle = &quot;yob: 1952, PC3 score: 3.26&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC3_example_large, filename = &quot;Figures/PC3_example_large.png&quot;, dpi = 300, width = 5, height = 5)

PC3_example_young &lt;- PC_example_plot +
  geom_text(data = PC_example_data %&gt;%
  filter(Speaker == &quot;CC_f_343&quot;), aes(size = PC3_loadings_abs), show.legend = FALSE) +
  ggtitle(label = &quot;D. Younger&quot;, subtitle = &quot;yob: 1971, PC3 score: -0.11&quot;) +
  theme(plot.title = element_text(size = 20, face = &quot;bold&quot;), plot.subtitle = element_text(size = 15))

# ggsave(plot = PC3_example_young, filename = &quot;Figures/PC3_example_young.png&quot;, dpi = 300, width = 5, height = 5)

PC3_example_speakers_all &lt;- plot_grid(PC3_example_old, PC3_example_small, PC3_example_large, PC3_example_young, nrow = 1)</code></pre>
<p>PCA score plot combined with the example speakers</p>
<pre class="r"><code>#PC1
PC1_speaker_loadings_example_plot1 &lt;- ggdraw(PC1_speaker_loadings +
    # geom_point(aes(x = 1922, y = -0.43), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1942, y = -5.26), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1942, y = 3.55), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE)
    # +
    # geom_point(aes(x = 1961, y = -0.53), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE)
    )

PC1_speaker_loadings_example_plot &lt;- plot_grid(PC1_speaker_loadings_example_plot1, plot_grid(
  # PC1_example_old,
  plot_grid(NULL,
  PC1_example_small,
  PC1_example_large,
  NULL, rel_widths = c(0.5, 1, 1, 0.5), nrow = 1),
  # PC1_example_young,
          nrow = 1),
          nrow = 2)

PC1_speaker_loadings_example_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-89-1.png" width="3600" /></p>
<pre class="r"><code>ggsave(plot = PC1_speaker_loadings_example_plot, filename = &quot;Figures/PC1_speaker_loadings_example.png&quot;, dpi = 300, width = 14, height = 9)

#PC2
PC2_speaker_loadings_example_plot1 &lt;- ggdraw(PC2_speaker_loadings +
    geom_point(aes(x = 1914, y = 0.58), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1933, y = -3.2), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1934, y = 3.8), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1953, y = 0.54), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE))

PC2_speaker_loadings_example_plot &lt;- plot_grid(PC2_speaker_loadings_example_plot1, plot_grid(PC2_example_old, PC2_example_small, PC2_example_large, PC2_example_young,
          nrow = 1),
          nrow = 2)

PC2_speaker_loadings_example_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-89-2.png" width="3600" /></p>
<pre class="r"><code>ggsave(plot = PC2_speaker_loadings_example_plot, filename = &quot;Figures/PC2_speaker_loadings_example.png&quot;, dpi = 300, width = 14, height = 9)

#PC3
PC3_speaker_loadings_example_plot1 &lt;- ggdraw(PC3_speaker_loadings +
    # geom_point(aes(x = 1931, y = 1.23), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1950, y = -3.41), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE) +
    geom_point(aes(x = 1952, y = 3.26), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE)
    # +
    # geom_point(aes(x = 1971, y = -0.11), colour = &quot;red&quot;, size = 7, shape = 1, stroke = 2, show.legend = FALSE)
    )

PC3_speaker_loadings_example_plot &lt;- plot_grid(PC3_speaker_loadings_example_plot1, plot_grid(
  # PC3_example_old,
  plot_grid(NULL,
  PC3_example_small,
  PC3_example_large,
  NULL, rel_widths = c(0.5, 1, 1, 0.5), nrow = 1),
  # PC3_example_young,
          nrow = 1),
          nrow = 2)

PC3_speaker_loadings_example_plot</code></pre>
<p><img src="Covariation_monophthongs_analysis_files/figure-html/unnamed-chunk-89-3.png" width="3600" /></p>
<pre class="r"><code>ggsave(plot = PC3_speaker_loadings_example_plot, filename = &quot;Figures/PC3_speaker_loadings_example.png&quot;, dpi = 300, width = 14, height = 9)</code></pre>
</div>
</div>
<div id="sound-change-gamm-summaries" class="section level1">
<h1>Sound change GAMM summaries</h1>
<p>For reference, the output below gives the GAMM model summaries for the initial GAMM modelling (i.e. predicting the normalised F1/F2 values by year of birth, gender and speech). These models are resource heavy and take up a lot of memory (including the PC models, all 80 GAMM files run in this script take up just under 13GB on my computer), but to obtain a smaller and more efficient summary output, the covariation matricies are dropped, which reduces the file size considerably, but retains the basic summary information.</p>
<pre class="r"><code>#make vector containing all .rds filenames from model_summaries folder
model_summary_files = list.files(pattern=&quot;*.rds&quot;, path = &quot;/Users/james/Documents/GitHub/model_summaries/&quot;)

#load each of the files with for loop
for (i in model_summary_files) {
  print(i)
  assign(gsub(&quot;.rds&quot;, &quot;&quot;, i), readRDS(paste0(&quot;/Users/james/Documents/GitHub/model_summaries/&quot;, i)))

  yob_model_summary &lt;- summary.gam(get(gsub(&quot;.rds&quot;, &quot;&quot;, i)), re.test = FALSE)

  yob_model_summary$cov.unscaled &lt;- c()
  yob_model_summary$cov.scaled &lt;- c()

  saveRDS(object = yob_model_summary, file = paste0(&quot;Data/Models/Summaries/trimmed_&quot;, i))
}</code></pre>
<pre class="r"><code>#make vector containing all .rds filenames from model_summaries folder
model_summary_files = list.files(pattern=&quot;*.rds&quot;, path = &quot;Data/Models/Summaries/&quot;)

for (i in model_summary_files) {
  cat(&quot;\n------------------------&quot;)
  cat(paste0(&quot;\n&quot;, i, &quot;\n------------------------&quot;))
  model_summary &lt;- readRDS(paste0(&quot;Data/Models/Summaries/&quot;, i))
  print(model_summary)
  cat(&quot;\n\n&quot;)
}</code></pre>
<pre><code>## 
## ------------------------
## trimmed_gam_F1_DRESS.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_FLEECE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_GOOSE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_KIT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_LOT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_NURSE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_START.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_STRUT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_THOUGHT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F1_TRAP.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_DRESS.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_FLEECE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_GOOSE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_KIT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_LOT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_NURSE.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_START.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_STRUT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_THOUGHT.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284
## 
## 
## 
## ------------------------
## trimmed_gam_F2_TRAP.rds
## ------------------------
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## F2_lobanov_2.0 ~ s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;, 
##     by = Gender) + s(participant_year_of_birth, k = 10, bs = &quot;ad&quot;) + 
##     Gender + s(Speech_rate) + s(Speaker, bs = &quot;re&quot;) + s(Word, 
##     bs = &quot;re&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.78515    0.02040  38.490   &lt;2e-16 ***
## GenderM     -0.01534    0.02344  -0.655    0.513    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##                                        edf Ref.df      F  p-value    
## s(participant_year_of_birth):GenderM 1.767  1.846  6.196  0.00271 ** 
## s(participant_year_of_birth)         3.407  3.532 16.545 6.63e-12 ***
## s(Speech_rate)                       1.001  1.002  3.737  0.05314 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.178   Deviance explained = 20.7%
## fREML =  35260  Scale est. = 0.48792   n = 32284</code></pre>
</div>
<div id="shiny-app-data" class="section level1">
<h1>Shiny app data</h1>
<pre class="r"><code>#create data containing means for each speaker and vowel as well as the speaker and variable loadings
Speaker_vowel_means &lt;- vowels_all %&gt;%
  group_by(Speaker, Corpus, Gender, participant_year_of_birth, Vowel) %&gt;%
  summarise(F1_mean = mean(F1_lobanov_2.0),
            F2_mean = mean(F2_lobanov_2.0),
            F1_mean_raw = mean(F1_50),
            F2_mean_raw = mean(F2_50)) %&gt;%
  left_join(PC_speaker_loadings %&gt;% select(Speaker, Comp.1:Comp.3)) %&gt;%
  left_join(PC1_change_labels1 %&gt;% select(Vowel, PC1_loadings_abs)) %&gt;%
  left_join(PC2_change_labels1 %&gt;% select(Vowel, PC2_loadings_abs)) %&gt;%
  left_join(PC3_change_labels1 %&gt;% select(Vowel, PC3_loadings_abs)) %&gt;%
  ungroup()

#save the file in the shiny app folder
saveRDS(Speaker_vowel_means, &quot;Covariation_shiny/ONZE_summary.rds&quot;)

#model prediction values for sound change, PC1, PC2 and PC3
mod_pred_data &lt;- sound_change_plot_data %&gt;%
  dplyr::rename(F1_yob = F1,
                F2_yob = F2)

# %&gt;%
#   cbind(mod_pred_PC1_values %&gt;%
#           select(Comp.1, Vowel, Formant, intercepts1) %&gt;%
#           pivot_wider(names_from = Formant, values_from = intercepts1) %&gt;%
#           dplyr::rename(F1_PC1 = F1,
#                 F2_PC1 = F2)) %&gt;%
#           # mutate(Comp.1 = ifelse(Comp.1 &gt;= 0, as.numeric(as.character(substr(Comp.1, 1, 5))),
#           #                        as.numeric(as.character(substr(Comp.1, 1, 6)))))) %&gt;%
#   cbind(mod_pred_PC2_values %&gt;%
#           select(Comp.2, Vowel, Formant, intercepts1) %&gt;%
#           pivot_wider(names_from = Formant, values_from = intercepts1) %&gt;%
#           dplyr::rename(F1_PC2 = F1,
#                 F2_PC2 = F2)) %&gt;%
#           # mutate(Comp.2 = ifelse(Comp.2 &gt;= 0, as.numeric(as.character(substr(Comp.2, 1, 5))),
#           #                        as.numeric(as.character(substr(Comp.2, 1, 6)))))) %&gt;%
#   cbind(mod_pred_PC3_values %&gt;%
#           select(Comp.3, Vowel, Formant, intercepts1) %&gt;%
#           pivot_wider(names_from = Formant, values_from = intercepts1) %&gt;%
#           dplyr::rename(F1_PC3 = F1,
#                 F2_PC3 = F2)) %&gt;%
#           # mutate(Comp.3 = ifelse(Comp.3 &gt;= 0, as.numeric(as.character(substr(Comp.3, 1, 5))),
#           #                        as.numeric(as.character(substr(Comp.3, 1, 6)))))) %&gt;%
#   left_join(PC1_change_labels1 %&gt;% select(Vowel, PC1_loadings_abs)) %&gt;%
#   left_join(PC2_change_labels1 %&gt;% select(Vowel, PC2_loadings_abs)) %&gt;%
#   left_join(PC3_change_labels1 %&gt;% select(Vowel, PC3_loadings_abs))

saveRDS(mod_pred_data, &quot;Covariation_shiny/mod_pred_data.rds&quot;)

saveRDS(mod_pred_PC_values, &quot;Covariation_shiny/mod_pred_PC_values_data.rds&quot;)</code></pre>
<pre class="r"><code>cat(paste0(&quot;End time:\n&quot;, format(Sys.time(), &quot;%d %B %Y, %r&quot;)))</code></pre>
<pre><code>## End time:
## 28 August 2020, 07:08:20 pm</code></pre>
<pre class="r"><code>end_time &lt;- Sys.time()

cat(paste0(&quot;\n---------------\nTotal time to compile:\n&quot;, as.numeric(end_time - start_time), &quot; minutes\n---------------\n&quot;))</code></pre>
<pre><code>## 
## ---------------
## Total time to compile:
## 11.2796084483465 minutes
## ---------------</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
